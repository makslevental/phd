

% \subsubsection{Pushforwards and Pullbacks}\label{subsubsec:diffgeo}

\newcommand{\gln}{\operatorname{GL}(n, \R)}
\section{Differential Geometry}\label{sec:dg}
\localtableofcontents

\subsection{Directional Derivative}

Elements of the \newterm{tangent space} \(T_p (\mathbb{R}^n)\) anchored at a point \(p = (p^1, \dots, p^n) \in \mathbb{R}^n\) can be visualized as arrows emanating from \(p\).
%
These arrows are called \newterm{tangent vectors} and represented by column vectors:
%
\begin{equation}
    \bm{v}
    =
    \begin{bmatrix}
        v^1 \\ \vdots \\ v^n
    \end{bmatrix}
    % =
    % \begin{bmatrix}
    %     v^1, \dots, v^n    
    % \end{bmatrix}
\end{equation}
%
The line through a point \(p\) with direction \(\bm{v}\) has parameterization
%
\begin{equation}
    c(t) = \left( p^1 + t v^1, \dots, p^n + t v^n \right)
\end{equation}
%
If \(f \in C^\infty\) in a neighborhood of \(p\) and \(\bm{v}\) is a tangent vector at \(p\), the \newterm{directional derivative} of \(f\) in the direction of \(\bm{v}\) at \(p\) is defined
%
\begin{equation}
    D_{\bm{v}} f
    =
    \lim_{t\rightarrow 0}\, \frac{f(c(t)) - f(p)}{t}
    =
    \evalat[\bigg]{\dv{}{t} f(c(t))}{t=0}
\end{equation}
%
By the chain rule
%
\begin{align}
    D_{\bm{v}} f & = \sum_{i=1}^{n} \evalat[\bigg]{\pdv{f}{x^i}}{p} \evalat[\bigg]{\dv{c^i}{t}}{t=0} \\
                 & = \sum_{i=1}^{n} \evalat[\bigg]{\dv{c^i}{t}}{t=0} \evalat[\bigg]{\pdv{f}{x^i}}{p} \\
                 & = \sum_{i=1}^{n} v^i \evalat[\bigg]{\pdv{f}{x^i}}{p}\label{eqn:chainrule}         \\
\end{align}
%
The directional derivative operator at \(p\) is defined
%
\begin{equation}
    D_{\bm{v}} = \sum_{i=1}^{n} v^i \evalat[\bigg]{\pdv{}{x^i}}{p}
\end{equation}
%
The association \(\bm{v} \mapsto D_{\bm{v}}\) offers a way to \newterm{isomorphically} identify tangent vectors with operators on functions.
%
The following makes this rigorous.

\subsection{Derivations}

For each tangent vector \(\bm{v}\) at a point \(p \in \mathbb{R}^n\), the directional derivative at \(p\) gives a map of vector spaces
%
\begin{equation*}
    D_{\bm{v}} \colon C_p^\infty \rightarrow \mathbb{R}
\end{equation*}
%
\(D_{\bm{v}}\) is a linear map that satisfies the \newterm{Leibniz rule}
%
\begin{equation}
    D_{\bm{v}}(fg) = (D_{\bm{v}}f)g(p) + f(p) (D_{\bm{v}}g)
\end{equation}
%
because the partial derivative satisfy the product rule.
%
In general, any linear map \(L\colon C_p^\infty \rightarrow \mathbb{R}\) that satisfies the Leibniz rule is called a \newterm{derivation} at \(p\).
% or a \textit{point derivation} of \(C_p^\infty\). 
%
Denote the set of all derivations at \(p\) by \(\mathcal{D}_p(\mathbb{R}^n)\).
%
\textbf{This set is also a real vector space}.
%

So far we know directional derivatives \(D_{\bm{v}}\) at \(p\) are derivations at \(p\).
%
Thus, there is a map
\begin{align*}
    \phi\colon T_p(\mathbb{R}^n) & \rightarrow \mathcal{D}_p (\mathbb{R}^n) \\
    \bm{v}                       & \mapsto D_{\bm{v}}
\end{align*}
%
\begin{theorem}{}{}
    The linear map \(\phi\) is an isomorphism of vector spaces.
\end{theorem}
%
\noindent The implication is that we may identify tangent vectors at \(p\) with derivations at \(p\) (by way of directional derivatives against germs).
%
Under this isomorphism \(T_p(\mathbb{R}^n) \simeq \mathcal{D}_p(\mathbb{R}^n)\), the standard basis \(\left\{ e_1, \dots, e_n \right\}\) for \(T_p(\mathbb{R}^n)\) maps to
%
\begin{equation}
    \left\{\evalat[\bigg]{\pdv{}{x^1}}{p}, \dots, \evalat[\bigg]{\pdv{}{x^n}}{p}  \right\}\label{eqn:tangentbasis}
\end{equation}
%
Therefore from now on we write a tangent vector as
%
\begin{equation}
    \bm{v} = \sum_{i=1}^{n} v^i \evalat[\bigg]{\pdv{}{x^i}}{p}
\end{equation}
%
The point being that, while not as geometrically intuitive as arrows, \(\mathcal{D}_p (\mathbb{R}^n)\) generalizes to manifolds.

\subsection{Vector Fields}

A \newterm{vector field} \(X\) on an open \(U \subset \mathbb{R}^n\) is function that assigns to \(p \in U\) a tangent vector \(X_p \in T_p(\mathbb{R}^n)\).
%
Notice, carefully, that the vector field assigns at each point a vector in the tangent space anchored at that point.
%
Using the tangent basis (eqn.~\eqref{eqn:tangentbasis})
%
\begin{equation}
    X\colon p \mapsto \sum_i a^i(p) \evalat[\bigg]{\pdv{}{x^i}}{p}
\end{equation}
%
Note that both the coefficients \textbf{and} the partial derivatives are evaluated at \(p\).
%
Having said that, we often omit \(p\) in the specification of a vector field when it clear from context.
%
\begin{example}{}{}
    On \(\mathbb{R}^n - \{\bm{0}\}\), let \(p = (x,y)\). Then
    \begin{align*}
        X & = \frac{-y}{\sqrt{x^2+y^2}} \pdv{}{x} + \frac{x}{\sqrt{x^2+y^2}} \pdv{}{y} \\
          & = \begin{bmatrix}
            \frac{-y}{\sqrt{x^2+y^2}} \\ \frac{x}{\sqrt{x^2+y^2}}
        \end{bmatrix}                                               \\
          & = \begin{bmatrix}
            \frac{-y}{\sqrt{x^2+y^2}} & \frac{x}{\sqrt{x^2+y^2}}
        \end{bmatrix}^T
    \end{align*}
\end{example}
%
See figure~\ref{fig:vectorfields}
% \loadfig{vecfields}

In general we can identify vector fields with parameterized column vectors
%
\begin{equation}
    X = \sum_i a^i(p) \evalat[\bigg]{\pdv{}{x^i}}{p}
    \leftrightarrow
    \begin{bmatrix}
        a^1(p) \\ \vdots \\ a^n(p)
    \end{bmatrix}
\end{equation}

\subsection{Dual Space}

\newcommand{\pdx}[1]{\partial_{x_{#1}}}
\newcommand*{\vwedge}{V^\wedge }
\newcommand*{\vx}{X = \sum a^i \partial_{x_i}}

The \newterm{dual space} \(\vwedge\) of \(V\) is the set of all real-valued linear functions on \(V\) i.e. all \(f \colon V \rightarrow \R\).
%
Elements of \(\vwedge\) are called \newterm{covectors}.

Assume \(V\) is finite dimensional and let \(\{e_1, \dots, e_n\}\) be a basis \(V\).
%
Recall that \(e_i \coloneqq \partial_{x_i}\).
%
Then \(\vx\) for all \(X \in T_p\).
%
Let \(\alpha^i \colon V \rightarrow \mathbb{R}\) be the linear function that picks out the \(i\)th coordinate of a \textbf{vector}, i.e. \(\alpha^i(X) = a^i(p)\).
%
Note that
%
\begin{align}
    \alpha^i(\partial_j) & = \alpha^i(1\cdot \partial_j) \\
                         & = \begin{cases}
        1 \text{ if } i = j \\
        0 \text{ if } i \neq j
    \end{cases}  \\
                         & =\delta_j^i
\end{align}
%
Note that position of indices is important -- upper indices are for covectors.
%
\begin{proposition}{}{}
    \(\{\alpha^i\}\) form a basis for \(\vwedge\).
\end{proposition}
%
\begin{proof}
    %
    We first prove that \(\{\alpha^i\}\) span \(\vwedge\). If \(f \in V^\wedge\) and \(\vx \in V\), then
    %
    \begin{align}
        f(X) & = \sum a^i f(\pdx{i})          \\
             & = \sum \alpha^i(X) f(\pdx{i})  \\
             & = \sum f(\pdx{i}) \alpha^i (X)
    \end{align}
    %
    which shows that any \(f\) can be expanded as a linear sum of \(\alpha^i\).
    %
    To show linear independence, suppose \(\sum c_i \alpha^i = 0\) with at least one \(c_i\) non-zero. Applying this to an arbitrary \(\pdx{i}\) gives
    %
    \begin{equation}
        0 = \left(\sum_i c_i \alpha^i   \right)(\pdx{i}) = \sum_i c_i \alpha^i(\pdx{i}) = \sum_i c_i \delta_j^i = c_j
    \end{equation}
    %
    which is a contradiction. Hence \(\alpha^i\) are linearly independent.
    %
\end{proof}
%
This basis \(\{\alpha^i\}\) for \(\vwedge\) is said to be \textit{dual} to the basis \(\{\pdx{i}\}\) for \(V\).
%
\begin{example}{Coordinate functions}{}
    %
    With respect to a basis \(\{\pdx{i}\}\) for \(V\), every \(X \in V\) can be written uniquely as a linear combination \(\vx\) with \(a^i \in \R\). Let \(\{\alpha^i\}\) be the dual basis (i.e. the basis for \(\vwedge\)).
    %
    Then
    %
    \begin{align*}
        \alpha^i(X) & = \alpha^i \left( \sum_j a^j \pdx{j} \right) \\
                    & = \sum_j a^j \alpha^i(\pdx{j})               \\
                    & = \sum_j a^j \delta_j^i                      \\
                    & = a^i
    \end{align*}
    %
    Thus, the dual basis \(\{\alpha^i\}\) to \(\{\pdx{i}\}\) is the set of coordinate functions.
    %
    The sense here is that since tangent vectors are directional derivatives (i.e.\ operators on functions) and the dual space is a mapping from those operators to \(\R\), then a mapping from operators to scalars means hitting an operator with a function (or vice-versa). \textbf{And} the coordinate functions are constant with respect to each other coordinate (and hence partials wrt them are naturally zero).
\end{example}

\subsection{Differential Forms on \(\R^n\)}

A differential \(k\)-form assigns a \(k\)-covector from the dual space at each point \(p\).
%
The wedge product (alternation of tensor product) of differential forms is defined pointwise (as the wedge product of multi-covectors).
%
Differential forms exist on an open set (why?) there is a notion of differentiation (called exterior derivative).
%
Exterior derivative is coordinate independent and intrinsic to a manifold; it is the abstraction of gradient, curl, divergence to arbitrary manifolds.
%
Differential forms extend Grassmann's exterior algebra (graded algebra of multi-covectors) from the tangent space at a point globally, i.e. to the entire manifold (how? bundles?).

\subsubsection{Differential of a Function}

\newcommand{\cotsp}[1]{T_p^*(\R^{#1})}
\newcommand{\tsp}[1]{T_p(\R^{#1})}
\newcommand{\w}{\omega}

\begin{definition}{Cotangent Space}{}
    The \newterm{cotangent space} to \(\R^n\) at \(p\), denoted \(\cotsp{n}\), is defined to be the dual space \((\tsp{n})^\vee\) of the tangent space \(\tsp{n}\).
\end{definition}
%
Thus, an element of the cotangent space \(\cotsp{n}\) is a \textbf{covector of linear functional on tangent space}.
%
\begin{definition}{Differential 1-form}{}
    A \newterm{covector field} or a \newterm{differential 1-form} on an open subset \(U\) of \(\R^n\) is a function \(\w\) that assigns at each point \(p\) in \(U\) a covector \(\w_p \in \cotsp{n}\)
    %
    \begin{splitenv}
        \w \colon U &\rightarrow \bigcup_{p \in U} \cotsp{n} \\
        p &\mapsto \w_p \in \cotsp{n}
    \end{splitenv}
    We call a differential 1-form a \newterm{1-form} for short.
\end{definition}
%
\begin{definition}{Differential}{}
    From any \(C^\infty\) function \(f\colon U \rightarrow \R\), we can construct the 1-form \(\dif f\), called the \newterm{differential} of \(f\), as follows: for \(p \in U\) and \(X_p \in T_p(U)\)
    \begin{equation}
        (\dif f)_p (X_p) \coloneqq X_p f
    \end{equation}
    In words the differential of \(f\) is the application of \(X_p\) to \(f\) or \textbf{the directional derivative of \(f\) in the direction of the tangent vector defined by the coefficients of \(X_p\)}.
\end{definition}

Let \(x^1, \dots, x^n\) be the standard coordinates on \(\R\), \(\{(\dif x^1)_p, \dots, (\dif x^n)_p\}\) their differentials defined
\[
    (\dif x^i)_p (X_p) \coloneqq (X_p)(x^i)
\]
%
and
%
\[
    \left\{\evalat[\bigg]{\pdv{}{x^1}}{p}, \dots,  \evalat[\bigg]{\pdv{}{x^n}}{p}  \right\}
\]
%
be the standard basis for \(\tsp{n}\).
%
\begin{proposition}{}{dfbasis}
    \(\{(\dif x^1)_p, \dots, (\dif x^n)_p\}\) is the basis for \(\cotsp{n}\) dual to the coordinate basis for \(\tsp{n}\).
\end{proposition}
%
\begin{proof}
    By definition,
    \[
        (\dif x^i)_p \left( \evalat[\bigg]{\pdv{}{x^j}}{p} \right) = \evalat[\bigg]{\pdv{x^i}{x^j}}{p} = \delta_j^i
    \]
\end{proof}

If \(\w\) is a 1-form on \(U \in \R^n\) then by proposition~\eqref{prop:dfbasis}, at each point \(p \in U\)
%
\[
    \w_p = \sum a_i(p)(dx^i)_p
\]
%
Note the lower index on \(a_i(p)\) as opposed to the upper index on \(X_p = \sum a^i(p)\evalat[\big]{\partial_{x_i}}{p}\).
%
If \(x \coloneqq x^1,y\coloneqq x^2,z \coloneqq x^3\), then \(\dif x, \dif y, \dif z\).
%
\begin{proposition}{\(\dif f\) in terms of coordinates}{}
    If \(f\colon U \rightarrow \R\), then
    \begin{equation}
        \dif f = \sum \pdv{f}{x^i}\dif x^i
    \end{equation}
\end{proposition}
%
\begin{proof}
    \[(\dif f)_p = \sum a_i(p) (\dif x^i)_p\]
    %
    for some real numbers \(a_i(p)\) depending on \(p\). Thus
    %
    \begin{splitenv}
        \dif f \left(\pdv{}{x^j} \right) &= \sum_i a_i \dif x^i \left(\pdv{}{x^j} \right) \\
        &= \sum_i a_i \delta_j^i = a_j
    \end{splitenv}
    %
    On the other hand, by the definition of the differential
    %
    \begin{equation}
        \dif f =  \left(\pdv{}{x^j} \right) = \pdv{f}{x^j}
    \end{equation}
    %
    Therefore
    \begin{equation}
        a_j = \pdv{f}{x^j}
    \end{equation}
    and hence
    \[(\dif f)_p = \evalat[\bigg]{\pdv{f}{x^i}}{p} (\dif x^i)_p\]
\end{proof}

\subsubsection{Differential \(k\)-forms}

\newcommand{\twoform}[2]{\dif #1 \wedge \dif #2}
\newcommand{\threeform}[3]{\dif #1 \wedge \dif #2 \wedge \dif #3}
\newcommand{\cinf}{C^\infty}

\begin{definition}{Differential \(k\)-forms}{}
    More generally, a \newterm{differential form \(\w\) of degree \(k\)} is a function that at each point assigns an alternating \(k\)-linear function on \(\tsp{n}\), i.e. \(\w_p \in A^k(\tsp{n})\).
\end{definition}
%
A basis for \(A^k(\tsp{n})\) is
\begin{equation}
    (\dif x^I)_p \coloneqq (\dif x^{i_1})_p \wedge \cdots \wedge (\dif x^{i_k})_p
\end{equation}
%
where \(1 \leq i_1 < \cdots < i_k \leq n \).
%

\textbf{What is the nuance here?}

Therefore, at each point \(p \in U\), \(\w_p\) is a linear combination
%
\begin{splitenv}
    \w_p = \sum_I a_I(p) (\dif x^I)_p \\ 1 \leq i_1 < \cdots < i_k \leq n
\end{splitenv}
%
and a \(k\)-form \(\w\) on open \(U\) is a linear combination
%
\begin{equation}
    \w = \sum_I a_I \dif x^I
\end{equation}
%
with function coefficients \(a_I \colon U \rightarrow \R\).
%
We say that a \(k\)-form \(\w\) is \(C^\infty\) on \(U\) if all of the coefficients \(a_I\) are \(C^\infty\) functions on \(U\).
%
Denote \(\Omega^k(U)\) the vector space of \(k\)-forms on \(U\).
%
A 0-form on \(U\) assigns to each point \(p\) an element of \(A^0(\tsp{n}) \coloneqq \R\); thus, a 0-form on \(U\) is a constant function.
%
Note there are no nonzero differential forms of degree \(>n\) on \(U\) since if \(\deg \dif x^I > n\) then at least two of the component 1-forms of \(dx^I\) must be the same and therefore \(dx^I = 0\).

\begin{definition}{Wedge product of forms}{}
    The \newterm{wedge product of a \(k\)-form \(\w\) and \(\ell\)-form \(\tau\)} is defined pointwise
    %
    \begin{splitenv}
        (\w \wedge \tau)_p &\coloneqq \w_p \wedge \tau_p \\
        \w \wedge \tau &= \sum_{I,J}(a_I b_J) \dif x^I \wedge \dif x^J
    \end{splitenv}
    %
    where \(I \cap J = \emptyset\).
    %
\end{definition}
%
Hence the wedge product is bilinear
%
\begin{equation}
    \wedge \colon \Omega^k (U) \times \Omega^\ell \rightarrow \Omega^{k+\ell} (U)
\end{equation}
%
The wedge product of forms is also anticommutative and associate (owing to the associativity and anticommutativity of the wedge product on multi-covectors) as therefore induces a graded algebra on \(\Omega(U) \coloneqq \bigoplus_k \Omega^k(U)\).

\begin{example}{}{}
    In the case of
    %
    \[
        \wedge \colon \Omega^0(U) \times \Omega^\ell(U) \rightarrow \Omega^\ell
    \]
    %
    we have the pointwise multiplication of a \(C^\infty\) function and a \(C^\infty\) \(\ell\)-form
    %
    \[
        (f \wedge \w)_p = f(p) \wedge \w_p = f(p)\w_p
    \]
    %
    Let \(x,y,z\) be the coordinates on \(\R^3\). Then, the 1-forms are
    %
    \[
        f \dif x + g \dif y + h \dif z
    \]
    %
    the 2-forms are
    %
    \[
        f \dif y \wedge \dif z + g \dif x \wedge \dif z + h \dif x \wedge \dif y
    \]
    %
    and the 3-forms are
    %
    \[
        f \dif x \wedge \dif y \wedge \dif z
    \]
\end{example}

\subsubsection{Differential Forms as Multilinear Functions on Vector Fields}

If \(\w\) is a 1-form and \(X\) is a vector field then
%
\begin{splitenv}
    \evalat[]{\w(X)}{p} &\coloneqq \w_p (X_p) \\
    \w &\,= \sum a_i \dif x^i \quad X = \sum b^i \pdv{}{x^j} \\
    \w(X) &\,= \left( \sum a_i \dif x^i \right) \left( \sum b^j \pdv{}{x^j}\right) \\
    &\,= \sum a_i b^i
\end{splitenv}

\subsubsection{Exterior Derivative}

\begin{definition}{Exterior Derivative}{}
    The exterior derivative of a function \(f \in C^\infty(U)\) is defined to be its differential \(\dif f\)
    %
    \[
        \dif f = \sum \pdv{f}{x^i} \dif x^i
    \]
    %
    For \(k \geq 1\), if \(\w = \sum_I a_I \dif x^I\) is a \(k\)-form, then
    %
    \begin{splitenv}
        \dif \w &\coloneqq \sum_I \dif a_I \wedge \dif x^I \\
        &\,= \sum_I \left( \sum_j \pdv{a_I}{x^j} \dif x^j \right) \wedge \dif x^I
    \end{splitenv}
\end{definition}
%
\begin{example}
    Let \(\w\) be the 1-form \(f \dif x + g \dif y\) on \(R^2\). Then
    \begin{align}
        \dif \omega & = \dif f \wedge \dif x + \dif g \wedge \dif y                                              \\
                    & \,= \begin{multlined}[t]
            \left( \pdv{f}{x}\dif x + \pdv{f}{y}\dif y \right) \wedge \dif x \\
            + \left( \pdv{g}{x}\dif x + \pdv{g}{y}\dif y \right) \wedge \dif y
        \end{multlined}                                                             \\
                    & \,= \left(\pdv{g}{x} - \pdv{f}{y} \right)\dif x \wedge \dif y \label{exa:exteriordif1form}
    \end{align}
    where we use that \(\dif x \wedge \dif y = - \dif y \wedge \dif x\) and \(\dif x \wedge \dif x = 0\).
\end{example}

\begin{definition}{Antiderivation}
    %
    Let \(A = \bigoplus_k A^k\) be a graded algebra over a field \(K\). An \newterm{antiderivation of the graded algebra} A is a \(k\)-linear map \(D \colon A \rightarrow A\) such that for \(a \in A^k, b \in A^\ell\)
    %
    \begin{equation}
        D(ab) = (Da)b + (-1)^kaDb
    \end{equation}
    %
    If there is an integer \(m\) such that \(D\) sends \(A^k\) to \(A^{k+m}\) for all \(k\), then the antiderivation is of \textit{degree m}.
\end{definition}
%
\begin{proposition}{Properties of exterior differentiation}{exterioranti}
    \begin{enumerate}
        \item exterior differentiation is an antiderivation of degree 1:
              \[\dif\, (\w \wedge \tau) = (\dif \w) \wedge \tau + (-1)^{\deg \omega} \omega \wedge \dif \tau\]
        \item \(\dif^2 = 0\)
    \end{enumerate}
\end{proposition}
%
\begin{proposition}{Characterization of the exterior derivative}{}
    The properties of proposition~\eqref{prop:exterioranti} completely characterize exterior differentiation.
\end{proposition}

\subsubsection{Closed and Exact Forms}

A \(k\)-form \(\w\) is a \newterm{closed form} if \(\dif \w = 0\).
%
\(\w\) is an \newterm{exact form} if there is a \(k-1\)-form \(\tau\) such that \(\w = \dif \tau\).
%
Since \(\dif (\dif \tau) = 0\), every exact form is closed.

\begin{example}{A closed 1-form on the punctured plane}{}
    Define \(\w\) on the manifold \(\R^2-\{\bm{0}\}\) by
    \[
        \omega(x,y) = \frac{-y}{x^2+y^2}\dif x + \frac{x}{x^2+y^2}\dif y
    \]
    To show that \(\w\) is closed we take the exterior derivative using example~\eqref{exa:exteriordif1form}:
    \begin{splitenv}
        \dif \w &= \left( \frac{y^2-x^2}{\left(x^2+y^2\right)^2} - \frac{y^2-x^2}{\left(x^2+y^2\right)^2} \right) \dif x \wedge \dif y \\
        &= 0
    \end{splitenv}
\end{example}

\begin{definition}{Differential Complex}{}
    A collection of vector spaces \(\{V^0, V^1, \dots\}\) with linear maps \(d_k \colon V^k \rightarrow V^{k+1}\) such that \(d_{k+1} \circ d_k = 0\) is called a \newterm{differential complex} or a \newterm{cochain complex}. For any open subset \(U \subset \R^3\), the exterior derivative makes the vector space \(\Omega^*(U)\) of \(C^\infty\) forms on \(U\) into a cochain complex, called the \newterm{de Rham complex of \(U\)}:
    \[
        0 \rightarrow \Omega^0(U) \xrightarrow{\text{ d }} \Omega^1(U) \xrightarrow{\text{ d }} \Omega^2(U) \xrightarrow{\text{ d }} \cdots
    \]
    The closed forms are the elements of the kernel of d and the exact forms are the elements of the image of d.
\end{definition}

\subsubsection{Applications to Vector Calculus}

Recall the three operators grad, curl, div (\(\grad, \curl, \div\)) on scalar fields and vector fields (i.e. scalar valued functions and vector valued functions) over \(\R^3\):
\begin{gather}
    \begin{split}
        \grad{f} &=
        \begin{bmatrix}
            \pdv{f}{x} \\
            \pdv{f}{y} \\
            \pdv{f}{z} \\
        \end{bmatrix} \\
        \curl{\begin{bmatrix}
                P \\ Q \\ R
            \end{bmatrix}} &=
        \begin{bmatrix}
            \pdv{}{x} \\
            \pdv{}{y} \\
            \pdv{}{z} \\
        \end{bmatrix} \times
        \begin{bmatrix}
            P \\ Q \\ R
        \end{bmatrix}
        =
        \begin{bmatrix}
            \pdv{R}{y} - \pdv{Q}{z}                 \\
            -\left( \pdv{R}{x} - \pdv{P}{z} \right) \\
            \pdv{Q}{x} - \pdv{P}{y}                 \\
        \end{bmatrix} \\
        \div{\begin{bmatrix}
                P \\ Q \\ R
            \end{bmatrix}} &=
        \begin{bmatrix}
            \pdv{}{x} \\
            \pdv{}{y} \\
            \pdv{}{z} \\
        \end{bmatrix} \cdot
        \begin{bmatrix}
            P \\ Q \\ R
        \end{bmatrix}
        =
        \pdv{P}{x} + \pdv{Q}{y} + \pdv{R}{z}
    \end{split}
\end{gather}
%
Note we can identity 1-forms with vector fields:
\[
    P \dif x + Q \dif y + R \dif z \longleftrightarrow \begin{bmatrix}
        P \\ Q \\ R
    \end{bmatrix}
\]
%
Similarly 2-forms on \(\R^3\)
\[
    P \twoform{x}{y}  + Q \twoform{z}{x} + R \twoform{x}{y} \longleftrightarrow \begin{bmatrix}
        P \\ Q \\ R
    \end{bmatrix}
\]
%
and 3-forms on \(U\) can be identified with functions \(U\)
%
\[
    f \threeform{x}{y}{z} \longleftrightarrow f
\]
%
In terms of these identifications the exterior derivative of 0-form \(f\) is the 1-form \(\dif f\) or \(\grad{f}\):
\[
    \dif f = \pdv{f}{x} \dif x + \pdv{f}{y} \dif y  + \pdv{f}{z} \dif z \longleftrightarrow
    \begin{bmatrix}
        \pdv{f}{x} \\
        \pdv{f}{y} \\
        \pdv{f}{z} \\
    \end{bmatrix} = \grad{f}
\]
%
the exterior derivative of a vector field \(\irow{P\; Q\; R}^T\) (i.e. 1-form) is the 2-form \(\curl{\irow{P\; Q\; R}^T}\)
%
\begin{splitenv}
    \dif \left( P\dif x + Q \dif y + R \dif z \right) = \\
    + \left( \pdv{R}{y} - \pdv{Q}{z} \right) \twoform{y}{z} \\
    - \left( \pdv{R}{x} - \pdv{P}{z} \right) \twoform{z}{x} \\
    + \left( \pdv{Q}{x} - \pdv{P}{y} \right) \twoform{x}{y}  \\ \longleftrightarrow \\ \curl{\begin{bmatrix}
            P \\ Q \\ R
        \end{bmatrix}}
\end{splitenv}
%
and the exterior derivative of a 2-form is
%
\begin{splitenv}
    \dif \left( P \twoform{x}{y}  + Q \twoform{z}{x} + R \twoform{x}{y} \right) = \\
    \left( \pdv{P}{x} \dif x + \pdv{Q}{y} \dif y  + \pdv{R}{z} \dif z \right) \threeform{x}{y}{z} \\
    \longleftrightarrow \div{\begin{bmatrix}
            P \\ Q \\ R
        \end{bmatrix}}
\end{splitenv}
%
Thus, the exterior derivatives on 0-forms (functions) is the grad operator, on 1-forms is the curl operator, and on 2-forms is the divergence operator.
%
\[
    \begin{tikzcd}
        \Omega^0(U) \arrow{r}{\dif} \arrow[swap]{d}{\cong} & \Omega^1(U) \arrow{r}{\dif} \arrow[swap]{d}{\cong} & \Omega^2(U) \arrow{r}{\dif} \arrow[swap]{d}{\cong} & \Omega^3(U) \arrow[swap]{d}{\cong}  \\
        C^\infty(U) \arrow[swap]{r}{\grad} & \mathfrak{X}(U) \arrow[swap]{r}{\curl} & \mathfrak{X}(U) \arrow[swap]{r}{\div} & C^\infty(U)
    \end{tikzcd}
\]
%
where \(\mathfrak{X}(U)\) is the \newterm{Lie algebra} of \(C^\infty\) vector fields on \(U\).
%
\begin{proposition}{grad, curl, div properties}{}
    \begin{enumerate}
        \item\label{prop1} \( \curl{\grad{f}} = 0 \)
        \item\label{prop2} \(\div(\curl{\irow{P \; Q \; R}^T}) = 0\)
        \item\label{prop3} On \(\R^3\), a vector field \textbf{F} is the gradient of some scalar function iff \(\curl{\textbf{F}}=0\)
    \end{enumerate}
\end{proposition}
%
Properties~(\ref{prop1},\ref{prop2}) express that \(\operatorname{d}^2 = 0\)
%
Property~\eqref{prop3} expresses the fact that a 1-form on \(\R^3\) is exact iff it is closed; it need not be true on a region other than \(\R^3\).
%
It turns out that whether proposition~\eqref{prop3} is true depends on the topology of \(U\).
%
One measure of the failure of a closed \(k\)-form to be exact is the quotient vector space
%
\begin{equation}
    H^k(U) \coloneqq \frac{\{\text{closed \(k\)-forms on } U\}}{\{\text{exact \(k\)-forms on }U\}}
\end{equation}
%
called the \(k\)th \newterm{de Rham cohomolgy} of U.
%
The generalization of proposition~\eqref{prop3} to any differential on \(\R^n\) is called the \newterm{Poincare lemma}: for \(k \geq 1\), every closed \(k\)-form on \(\R^n\) is exact.
%
This is equivalent to the vanishing of the \(k\)th de Rham cohomology \(H^k(\R^n)\) for \(k \geq 1\).

\subsubsection{Convention on Subscripts and Superscripts}

Vector fields \(e_1, e_2, \dots\)have subscripts and differential forms \(\w^1, \w^2, \dots\) have superscripts.
%
Coordinate functions \(x^1, x^2, \dots\), being 0-forms, have superscripts.
%
Their differentials \(\dif x^i\) should also.
%
Coordinate vector fields \(\pdv{}{x^i}\) are considered to have subscripts because the index is in the denominator.
%
Coefficient functions have subscripts or subscripts depending on whether they're coefficients functions for vector fields or forms.
%
This allows for ``conservation of indices'': if \(X = \sum a^i \partial_{x^i}\) and \(\w = \sum b_j \dif x^j\) then
\[
    \w(X) = \left( \sum b_j \dif x^j \right) \left( \sum a^i \pdv{}{x^i} \right) = \sum b_i a^i
\]

\subsection{Manifolds}

\begin{definition}{Locally Euclidean}{}
    A topological space \(M\) is \newterm{locally Euclidean of dimension \(n\)} if for every \(p \in M\) there exists a neighborhood \(U\) such that there is a \newterm{homeomorphism}\tablefootnote{A homeomorphism is a continuous function between topological spaces that has a continuous inverse function.} \(\phi\) from \(U\) \textbf{onto} an opensubset of \(\R^n\).
    %
    The pair \(\left( U,\phi \colon U \rightarrow \R^n \right)\) is called a \newterm{chart}, with \(U\) being the \newterm{coordinate neighborhood} and \(\phi\) the \newterm{coordinate system}.
\end{definition}

\begin{definition}{Topological Manifold}{}
    A \newterm{topological manifold} is a \newterm{Hausdorff}\tablefootnote{A Hausdorff space, separated space space is a topological space where for any two distinct points there exists a neighbourhood of each which is disjoint from the neighbourhood of the other. }, \newterm{second countable}\tablefootnote{A topological space \(T\) is second-countable if there exists some countable collection ${\displaystyle {\mathcal {U}}=\{U_{i}\}_{i=1}^{\infty }}$ of open subsets of $T$ such that any open subset of $T$ can be written as a union of elements of some subfamily of ${\mathcal {U}}$.}, locally Euclidean space.
\end{definition}

\subsubsection{Compatible Charts}

Suppose \(\left( U,\phi \colon U \rightarrow \R^n \right)\) and \(\left( V,\psi \colon V \rightarrow \R^n \right)\) are two charts of a topological manifold; since \(U \cap V\) is open and \(\phi\) is a homeomorphism onto an open subset, the image \(\phi(U \cap V)\) is also an open subset (similarly \(\psi(U \cap V)\)).

\begin{definition}{Charts}{}
    Two charts \(\left( U,\phi \colon U \rightarrow \R^n \right)\) and \(\left( V,\psi \colon V \rightarrow \R^n \right)\) of a topological manifold are \newterm{\(C^\infty\)-compatible} if the two composed maps
    %
    \begin{splitenv}
        \phi \circ \psi^{-1}\colon \psi(U \cap V) \rightarrow \phi(U \cap V) \\
        \psi \circ \phi^{-1}\colon \phi(U \cap V) \rightarrow \psi(U \cap V)
    \end{splitenv}
    %
    See figure~\ref{fig:compatcoordcharts}.
    %
    These two maps \(\phi \circ \psi^{-1}\) and \(\psi \circ \phi^{-1}\) are called the \newterm{transition functions} between the charts;
    \begin{splitenv}
        \phi \circ \psi^{-1}\colon \R^n \rightarrow U \cap V \rightarrow \R^n \\
        \psi \circ \phi^{-1}\colon \R^n \rightarrow U \cap V \rightarrow \R^n
    \end{splitenv}
\end{definition}
% \loadfig{coordinatechart}
\begin{definition}{Atlas}{}
    A \(C^\infty\) \newterm{atlas} on a topological manifold \(M\) is a collection \(\mathfrak{U} \coloneqq \{(U_i, \phi_i)\}\) of pairwise \(C^\infty\)-compatible charts that \textit{cover} \(M\), i.e. such that \(M = \bigcup_i U_i\).
\end{definition}
\begin{example}{A \(C^\infty\) atlas on a circle}{}
    The unit circle \(S^1\) in the complex plane \(\mathbb{C}\) maybe described as
    \[
        \{e^\iu \in \C | 0 \leq t \leq 2\pi\}
    \]
    Let \(U_1, U_2\) be
    \begin{splitenv}
        U_1 &\coloneqq \{e^{\iu t} \in \C | -\pi < t < \pi\}    \\
        U_2 &\coloneqq \{e^{\iu t} \in \C | 0 < t < 2\pi\}
    \end{splitenv}
    and define
    \begin{splitenv}
        \phi_1(e^{\iu t}) &= t \quad -\pi < t < \pi \\
        \phi_2(e^{\iu t}) &= t \quad 0 < t < 2\pi \\
    \end{splitenv}
    See figure~\ref{fig:chartsoncircle}.
    %
    Both \(\phi_1, \phi_2\) are homemorphisms onto their respective images; thus, \(U_1, \phi_1\) and \(U_2, \phi_2\) are charts on \(S^1\).
    %
    The intersection \(U_1 \cap U_2\) consists of two disjoint connected components
    \begin{splitenv}
        A &\coloneqq \{e^{\iu t} \in \C | -\pi < t < 0\}    \\
        B &\coloneqq \{e^{\iu t} \in \C | 0 < t < \pi\}
    \end{splitenv}
    with
    \begin{splitenv}
        \phi_1(U_1 \cap U_2) &= \phi_1 (A \sqcup B) = \phi_1(A) \sqcup \phi_2(B) = (-\pi,0) \sqcup (0, \pi) \\
        \phi_2(U_1 \cap U_2) &= \phi_1 (B \sqcup A) = \phi_1(B) \sqcup \phi_2(A) = (0, \pi)\sqcup(\pi, 2\pi)\\
    \end{splitenv}
    where \(\sqcup\) means disjoint union.
    %
    The transition function
    \[
        \left( \phi_2 \circ \phi_1^{-1} \right)(t) = \begin{cases}
            t+2\pi & \text{ for } t\in (-\pi, 0) \\
            t      & \text{ for } t\in (0, \pi)
        \end{cases}
    \]
    and similarly
    \[
        \left( \phi_1 \circ \phi_2^{-1} \right)(t) = \begin{cases}
            t      & \text{ for } t\in (0, \pi)    \\
            t-2\pi & \text{ for } t\in (\pi, 2\pi)
        \end{cases}
    \]
    Therefore, since the transition functions are \(C^\infty\), the charts are \(C^\infty\) compatible and form an atlas on \(S^1\).
\end{example}
% \loadfig{circlatlas}

Although compatibility is reflexive and symmetric it is not transitive because we don't know anything about mutual intersections.
%
On the otherhand
%
\begin{lemma}{}{}
    Let \(\{(U_i, \phi_i)\}\) be an atlas for a topological manifold. If two other charts (not in the atlas) \((V, \psi), (U, \phi)\) are both compatible with the atlas (i.e. with all charts in the atlas), then they are mutually compatible.
\end{lemma}

\subsubsection{Smooth Manifolds}

An atlas \(\mathfrak{M}\) on a topological manifold is said to be \newterm{maximal} if it is not strictly contained in another atlas.
\begin{definition}{Smooth Manifold}{}
    A \newterm{smooth \(C^\infty\) manifold} is a topological manifold \(M\) together with a maximal atlas.
    %
    The maximal atlas is called a \newterm{differentiable structure} on \(M\).
    %
    \(M\) is said to have dimension \(n\) if all of its connected components have dimension \(n\).
    %
    A 1-dimensional manifold is called a \newterm{curve}, a 2-dimensional manifold is called a \newterm{surface}, and an \(n\)-dimensional manifold is called an \(n\)-manifold.
\end{definition}

In the context of manifolds, we denote the standard coordinates on \(\R^n\) by \(r^1, \dots, r^n\).
%
If \((U, \phi)\) is a chart of a manifold, we let \(x^i = r^i \circ \phi\) be the \(i\)th component of \(\phi\) and write \(\phi = (x^1, \dots, x^n)\).
%
Thus, \(x^i(p) \coloneqq (r^i \circ \phi)(p)\) is a point in \(\R^n\).
%
The functions \(x^i\) are called the \newterm{local coordinates on U}.
%
The sense here is that \(x^i\) tell you where you are on the manifold in a standardized way, given some intrinsic description of where you are on the manifold.
Think of how lat/lon tell you where you are on the globe given some intrinsic identification of where you are on the globe.
This understanding gives sense to the words chart and atlas.
%
Abusing notation, sometimes \((x^1, \dots, x^n)\) (sans \(p\)) stands for both the coordinates on \(U\) or for a point in \(\R^n\).

\subsubsection{Examples of Smooth Manifolds}

\begin{example}{Graph of a Smooth Function}{}
    For a subset \(A \subset \R^n\) and a function \(f \colon A \rightarrow \R^m\) the \newterm{graph of f} is defined
    \[
        \Gamma(f) = \{(x, f(x)) \in A \times \R^m\}
    \]
    If \(U\) is an open subset \(\R^n\) and \(f \colon U \rightarrow \R^n\) is \(C^\infty\), then the two maps
    \begin{align*}
        \phi \colon \Gamma(f) \rightarrow U \quad (x, f(x)) \mapsto x \\
        (1, f) \colon \rightarrow \Gamma(f) \quad x \mapsto (x, f(x))
    \end{align*}
    constitute a homemorphism. Hence, \(\Gamma(f)\) has an atlas with a single \((\Gamma(f), \phi)\) and is therefore a \(C^\infty\) manifold.
\end{example}

\begin{example}{General Linear group}{}
    Let \(\R^{m \times n}\) be the vector space of all \(m \times n\) matrices.
    Since \(\R^{m \times n}\) is isomorphic to \(\R^{mn}\), we give it the topology of \(\R^{mn}\).
    The \newterm{general linear group \(\gln\)} is defined
    \begin{splitenv}
        \gln &\coloneqq \{A \in \R^{n\times n} | \det(A) \neq 0\}  \\
        &\;= \operatorname{det}^{-1} (\R - \{0\})
    \end{splitenv}
    Since the determinant function \(\det \colon \R^{n\times n}\rightarrow \R\) is continuous, \(\gln\) is an open subset of \(\R^{n \times n}\cong \R^{n^2} \) is therefore a manifold.
\end{example}

\begin{example}{Unit circle in the \(xy\)-plane}
    Take \(S^1\) as the unit circle in the real plane \(\R^2\) defined by \(x^2+y^2=1\).
    We can cover \(S^1\) by four open sets: the upper and lower semicircles \(U_1, U_2\) and the left and right semicircles \(U_3, U_4\)
    (see figure~\ref{fig:xychartsoncircle}).
    On \(U_1, U_2\) the coordinate function \(x\) is a homeomorphism onto the open interval \((-1,1)\) on the \(x\)-axis.
    Thus, \(\phi_i(x,y) \coloneqq x\). Similarly, on \(U_3, U_4\), \(y\) is a homeomorphism onto the open interval \((-1,1)\) on the \(y\)-axis, and so \(\phi_i(x,y) \coloneqq y\).
    You can check that on \(U_i \cap U_j\), the transition function \(\phi_j \circ \phi_i^{-1}\) is \(C^\infty\).
    For example, on \(U_1 \cap U_3\)
    \[
        (\phi_3 \circ \phi_1^{-1})(x) = \phi_3 (x, \sqrt{1-x^2}) = \sqrt{1-x^2}
    \]
    while on \(U_2 \cap U_4\)
    \[
        (\phi_4 \circ \phi_2^{-1})(x) = \phi_4 (x, -\sqrt{1-x^2}) = -\sqrt{1-x^2}
    \]
    Thus, \(\{(U_i, \phi_i)\}_{i=1}^4\) is a \(C^\infty\) atlas on \(S^1\).
\end{example}
% \loadfig{chartsoncirc}

\begin{proposition}{An atlas for a product manifold}{}
    If \(\{(U_i, \phi_i)\}\) and \(\{(V_i, \psi_i)\}\) are \(C^\infty\) atlases for the manifolds \(M,N\) of dimensions, respectively, then the collection
    \begin{equation}
        \{ (U_i \times V_j, (\phi_i, \phi_j)) \colon U_i \times V_j \rightarrow \R^m \times \R^n \}
    \end{equation}
    is a \(C^\infty\) atlas on \(M \times N\). Therefore \(M \times N\) is a \(C^\infty\) manifold of dimension \(m+n\).
\end{proposition}

There \(n\)-dimensional torus \(S^1 \times \cdots \times S^1\) is a manifold.

\subsubsection{Smooths Maps on a Manifold}

\begin{definition}{Smooth at a point to \(\R\)}{}
    Let \(M\) be a smooth manifold of dimension \(n\). A function \(f\colon M \rightarrow \R\) is said to be \(C^\infty\) or \newterm{smooth a point p} in \(M\) if there is a chart \((U, \phi)\) containing \(p\) such that \(f \circ \phi^{-1}\), a function defined on the open subset \(\phi(U) \subset \R^n\), is \(C^\infty\) at \(\phi(p)\).
    To summarize \(f\) is \(C^\infty\) if
    \[
        f \circ \phi^{-1} \colon \phi(U) \rightarrow \R
    \]

    See figure~\ref{fig:smoothatapoint}.
\end{definition}
% \loadfig{smoothatapoint}
\begin{definition}{Pullback}{}
    Let \(F \colon N \rightarrow M\) be a map and \(h\) a function \(M\).
    The \newterm{pullback} of \(h\) by \(F\), denoted \(F^*h\), is the composite function \(h \circ F\).
\end{definition}

Thus, a function \(f\) on \(M\) is \(C^\infty\) on a chart \((U, \phi)\) iff \((\phi^{-1})^* f \equiv f \circ \phi^{-1}\) is \(C^\infty\) on \(\phi(U)\).

\begin{definition}{Smooth at a point}{}
    Let \(M,N\) be manifolds of dimension \(m,n\). A continuous map \(F\colon N \rightarrow M\) is \(C^\infty\) at a point \(p \in N\) if there are charts \((V, \psi), (U, \phi)\) about \(F(p) \in M\) and \(p \in N\) such that \(\psi \circ F \psi \phi^{-1}\) is \(C^\infty\) at \(\phi(p)\).
    To summarize \(F\) is \(C^\infty\) if
    \[
        \psi \circ F \circ \phi^{-1} \colon \phi(F^{-1}(V) \cap U) \subset \R^n \rightarrow \R^m
    \]
    See figure~\ref{fig:smoothf}.
\end{definition}

% \loadfig{smoothf}

\begin{proposition}{Composition of \(C^\infty\) maps}{}
    If \(F \colon N \rightarrow M\) and \(G \colon M \rightarrow P\) are both \(C^\infty\) maps of manifolds, then the composite \(G \circ F \colon N \rightarrow P\) is \(C^\infty\).
\end{proposition}

\begin{definition}{Diffeomorphism}{}
    A \newterm{diffeomorphism} of manifolds is a bjiective \(C^\infty\) map \(F \colon N \rightarrow M\) whose inverse \(F^{-1}\) is also \(C^\infty\).
\end{definition}

\begin{proposition}{}{}
    If \((U, \phi)\) is a chart on a manifold \(M\) of dimension \(n\), then the coordinate map \(\phi \colon U \rightarrow \phi(U)\) is a diffeomorphism.
\end{proposition}

\begin{definition}{Lie group}{}
    A \newterm{Lie group} is a \(C^\infty\) manifold \(G\) having a group structure such that the multiplication map
    \[
        \mu \colon G \times G \rightarrow G
    \]
    and the inverse map
    \[
        \iota \colon G \rightarrow G \quad \iota(x) \coloneqq x^{-1}
    \]
    are both \(C^\infty\).
    Similarly, a \newterm{topological group} is a topological space having a group structure such that multiplication and inverse maps are both continuous.
\end{definition}

\begin{example}
    Recall the definition of \(\gln\).
    As an open subset of \(\R^{n \times n}\), it is a manifold.
    Since the \((i,j)\)-entry of the product of two matrices \(A, B\) in \(\gln\)
    \[
        (AB)_{ij} = \sum_{k=1}^n a_{ik}b_{kj}
    \]
    is a polynomial in the coordinates of \(A\) and \(B\).
    Therefore matrix multiplication
    \[
        \mu \colon \gln \times \gln \rightarrow \gln
    \]
    is a \(C^\infty\) map.
    Furthermore, by Cramer's rule
    \[
        (A^{-1})_{ij} = \frac{(-1)^{i+j}}{\det A} ((j,i)-\text{minor of }A)
    \]
    which is a \(C^\infty\) function of the \(a_{ij}\)s provided \(\det A \neq 0\).
    Therefore, \(\gln\) is a Lie group.
\end{example}

\subsubsection{Partial Derivatives}

Let \((U, \phi)\) be a chart and \(f\) a \(\cinf\) function on the manifold.
As a function into \(\R^n\), \(\phi\) has \(n\) components \(x^1, \dots, x^n\).
Therefore, if \(r^1, \dots, r^n\) are the standard coordinates on \(\R^n\), then
\[
    x^i = r^i \circ \phi
\]
What this means is \(\phi\) maps to some point \((\phi^1(p), \dots, \phi^n(p))\) in \(R^n\). The projection to the \(i\)th standard coordinate on \(\R^n\) is \(r^i \circ \phi\), i.e. just pick out the component of \((\phi^1(p), \dots, \phi^n(p))\). This direct path from \(U\) to the \(i\)th standard coordinate of \(\R^n\) is called a local coordinate for \(U\) (since it's only valid in a small neighborhood of \(p\)). Then the collection \((x^1, \dots, x^n)\) are the local coordinates on \(U\) (but don't forget that the coordinates map from \(U \rightarrow \R^n\)).

\begin{definition}{Partial derivative}{}
    For \(p \in U\), we define the \newterm{partial derivative \( \frac{\partial f}{\partial x^i} \) of \(f\) with respect to \(x^i\) at \(p\)}
    \begin{splitenv}
        \evalat[\bigg]{\pdv{}{x^i}}{p} f &\coloneqq \evalat[\bigg]{\pdv{f}{x^i}}{p} \\
        &\coloneqq \evalat[\bigg]{\pdv{(f \circ \phi^{-1})}{r^i}}{\phi(p)}  \\
        &\coloneqq \evalat[\bigg]{\pdv{}{r^i}}{\phi(p)} (f \circ \phi^{-1})
    \end{splitenv}
    Thus, as functions on \(\phi(U)\) (and in terms of the local coordinates on \(U\))
    \begin{equation}
        \pdv{f}{x^i} \circ \phi^{-1} = \pdv{f \circ \phi^{-1}}{r^i}
    \end{equation}
    and therefore the partial derivative \(\partial f/ \partial x^i\) is \(\cinf\) on \(U\) because its pullback
    \[
        (\phi^{-1})^* \pdv{f}{x^i}
    \]
    is \(\cinf\).
\end{definition}

\begin{proposition}{Partial derivatives are dual}{}
    Suppose \(U, x^1, \dots, x^n\) (with local coordinates \(x^1, \dots, x^n\)) is a chart on a manifold. Then \(\partial x^i / \partial x^j = \delta_j^i\).
\end{proposition}

\begin{proof}
    At a point \(p \in U\), by the above definition of \(\evalat[\big]{\partial / \partial x^j}{p}\)
    \begin{splitenv}
        \evalat[\bigg]{\pdv{x^i}{x^j}}{p} &= \evalat[\bigg]{\pdv{x^i \circ \phi^{-1}}{r^j}}{\phi(p)} \\
        &= \evalat[\bigg]{\pdv{(r^i \circ \phi \circ \phi^{-1})}{r^j}}{\phi(p)} \\
        &= \evalat[\bigg]{\pdv{r^i}{r^j}}{\phi(p)} = \delta_j^i
    \end{splitenv}
\end{proof}

\begin{definition}{Jacobian}{}
    Let \(F \colon N \rightarrow M\) be a smooth map, and let \((U, \phi) \equiv (U, x^1, \dots, x^n)\) and \((V, \psi) \equiv (U, y^1, \dots, y^n)\) be charts on \(N, M\) respectively such that \(F(U) \subset V\).
    Denote by
    \[
        (F_i \coloneqq y^i \circ F \equiv r^i \circ \psi \circ F) \colon U \rightarrow \R
    \]
    the \(i\)th component of \(F\) in the chart \(V, \psi\).
    Then the matrix \(\left[ \pdv{F^i}{x^j} \right]\) is called the \newterm{Jacobian matrix of \(F\)} relative to the charts \(U, \phi\) and \((V, \psi)\).
\end{definition}

A diffeomorphism \(F \colon U \rightarrow F(U) \subset \R^n\) may be thought of as coordinate system on \(U\).
We say that a \(\cinf\) map \(F \colon N \rightarrow M\) is \newterm{locally invertible} or a \newterm{local diffeomorphism} at \(p \in N\) if \(p\) has a neighborhood \(U\) on which \(F\) is a diffeomorphism.
Given \(n\) smooth functions \(F^1, \dots, F^n\) in a neighborhood of \(p\) one would like to know whether they form a coordinate system.
This is equivalent to whether \(F = (F^1, \dots, F^n)\) is a local diffeomorphism at \(p\).
\begin{theorem}{Inverse function theorem \(\R^n\)}{}
    Let \(F \colon W \rightarrow \R^n\) be a \(\cinf\) map defined on an open subset \(W \subset \R^n\).
    For any point \(p \in W\), the map \(F\) is locally invertible iff the determinant of the Jacobian \[\det \left[ \evalat[\bigg]{\pdv{F^i}{r^j}}{p}   \right]\] is not zero.
\end{theorem}
\begin{theorem}{Inverse function theorem for manifolds}{}
    Let \(F \colon N \rightarrow M\) be a \(\cinf\) map between manifolds of the same dimension, and \(p \in N\).
    Suppose for some charts \((U, \phi) = (U, x^1, \dots, x^n)\), \((V, \psi) = (U, y^1, \dots, y^n)\) about \(p\) and \(F(p)\) respectively and \(F(U) \subset V\).
    Set \(F^i = y^i \circ F\).
    Then \(F\) is locally invertible at \(p\) iff
    \[\det \left[ \evalat[\bigg]{\pdv{F^i}{x^j}}{p}   \right]\]
    is not zero.
\end{theorem}
\begin{corollary}{}{}
    Let \(N\) be a manifold of dimension \(n\). A set of smooth functions \(F^1, \dots, F^n\) defined on a coordinate neighborhood \(U, x^1, \dots, x^n\) of a point \(p \in N\) forms a coordinate system about \(p\) iff the Jacobian determinant
    \[\det \left[ \evalat[\bigg]{\pdv{F^i}{x^j}}{p}   \right]\]
    is not zero.
\end{corollary}

\subsection{Tangent Space}

The tangent space to a manifold at a point is the vector space of derivations (germs/directional derivatives) at the point.
A smooth map of manifolds induces a linear map, called its differential, of tangent spaces at corresponding points.
In local coordinates, the differential is represented by the Jacobian.
In this sense, the differential of a map is the generalization of the derivative between Euclidean spaces.

A basic theme in manifold theory is linearization, according to which a manifold can be approximated by its tangent space and a smooth map can be approximated by the differential of that map.
The differential further categorizes maps as either immersions or submersions (depending on whether the differential is injective or surjective).

The collection of tangent spaces to a manifold can be given the structure of a \newterm{vector bundle}; it is thus called the \newterm{tangent bundle}.
Vector fields, which manifest themselves in the physical world as velocity, force, electricity, and magnetism, maybe viewed as sections of the tangent bundle.

\subsubsection{The Tangent Space at a Point}

\begin{definition}{Tangent vector}{}
    The germ of a \(\cinf\) function \(p \in M\) to be an equivalence class of \(\cinf\) functions defined in a neighborhood of \(p \in M\), with equivalence defined as agreement on a (possibly smaller) neighborhood of \(p\).
    The set of germs of \(\cinf\) real-valued functions is denoted \(\cinf_p(M)\).
    Addition and multiplication of functions induces a ring structure on \(\cinf_p(M)\); with scalar multiplication by real numbers \(\cinf_p(M)\) becomes an algebra over \(\R\).
    A derivation at a point in \(M\) is a linear map \(D \colon \cinf_p(M) \rightarrow \R\) such that
    \[
        D(fg) = (Df)g + f(p)Dg
    \]
    A tangent vector at a point \(p\) is a derivation at \(p\).
\end{definition}

Given a coordinate neighborhood \((U, \phi) = (U, x^1, \dots, x^n)\) and \((r^1, \dots, r^n)\) the standard coordinates on \(\R^n\) and
\[
    x^i = r^i \circ \phi \colon U \rightarrow \R
\]
If \(f\) is a smooth function in a neighborhood of \(p\)
\[
    \evalat[\bigg]{\pdv{}{x^i}}{p} f = \evalat[\bigg]{\pdv{}{r^i}}{\phi(p)} (f \circ \phi^{-1})
\]
The partial derivatives satisfy the derivation property and therefore qualify as tangent vectors.

\subsubsection{The Differential of a Map}

Let \(F \colon N \rightarrow M\) be a \(\cinf\) map between two manifolds.
At each point \(p \in N\), the map \(F\) induces a linear map of tangent spaces, called its \newterm{differential at \(p\)}
\[
    F_* \colon T_p N \rightarrow T_{F(p)}M
\]
defined as follows: if \(X_p \in T_p N\), then \(F_* (X_p)\) is the tangent vector in \(T_{F(p)}M\) according to
\[
    (F_* (X_p))f = X_p (f \circ F)
\]
for \(f \in \cinf_{F(p)}(M)\) a germ (or representative of the germ).
Vectors \newterm{pushforward} through \(F\).

\begin{example}{Differential of a map between Euclidean spaces}{}
    Suppose \(F \colon \R^n \rightarrow \R^m\) is smooth and \(p \in \R^n\).
    Let \(x^1, \dots, x^n\) be coordinates on \(\R^n\) and \(y^1, \dots, y^m\) be coordinates on \(\R^m\).
    Then
    \[
        \left\{ \evalat[\bigg]{\pdv{}{x^1}}{p}, \dots,  \evalat[\bigg]{\pdv{}{x^n}}{p}\right\}
    \]
    form a basis for the tangent space \(T_p(\R^n)\) and
    \[
        \left\{ \evalat[\bigg]{\pdv{}{y^1}}{F(p)}, \dots,  \evalat[\bigg]{\pdv{}{y^m}}{F(p)}\right\}
    \]
    form a basis for the tangent space \(T_{F(p)}(\R^m)\).
    The linear map
    \[
        F_* \colon T_p(\R^n) \rightarrow T_{F(p)}(\R^m)
    \]
    (the differential of \(F\)) is described by a matrix \(\left[ a_j^i \right]\) relative to these two bases:
    \[
        F_* \left( \evalat[\bigg]{\pdv{}{x^j}}{p} \right) = \sum_k a_j^k \evalat[\bigg]{\pdv{}{y^k}}{F(p)}
    \]
    Let \(F^i = y^ \circ F\) be the \(i\)th component of \(F\); we can find \(a_j^i\) by evaluating the right-hand side and left-hand side on \(y^i\)
    \begin{splitenv}
        \text{RHS} &= \sum_k a_j^k \evalat[\bigg]{\pdv{}{y^k}}{F(p)} y^i = \sum_k a_j^k \delta_k^i = a_j^i \\
        \text{LHS} &=  F_* \left( \evalat[\bigg]{\pdv{}{x^j}}{p} \right) y^i = \evalat[\bigg]{\pdv{}{x^j}}{p} (y^i \circ F) = \evalat[\bigg]{\pdv{F^i}{x^j}}{p}
    \end{splitenv}
    where we've used the fact that \(F^i = y^i \circ F\).
    Thus, \(F_*\) relative to the bases is the Jacobian
    \[
        \left[  \evalat[\bigg]{\pdv{F^i}{x^j}}{p}  \right]
    \]
    and hence the differential generalizes the derivative of a map between Euclidean spaces (because in this instance the Jacobian is the derivative and in abstract manifolds we use the same \(F_*\)).
    Note this means
    \[
        F_* \iff \text{Jacobian} \iff \text{differential} \iff \text{pushforward}
    \]
\end{example}

\begin{example}
    Define a diffeomorphism \(F\) such that
    \begin{equation}
        F\colon (r, \theta) \mapsto (r \cos \theta, r \sin \theta)
    \end{equation}
    The Jacobian of \(F\)
    \begin{equation}
        \operatorname{J}
        =
        \begin{bmatrix}
            \pdv{F_1}{r} & \pdv{F_1}{\theta} \\
            \pdv{F_2}{r} & \pdv{F_2}{\theta}
        \end{bmatrix}
        =
        \begin{bmatrix}
            \cos \theta & -r \sin \theta \\
            \sin \theta & r \cos \theta
        \end{bmatrix}
    \end{equation}
    where \((r, \theta) \equiv (x_1, x_2)\) and
    \[
        (x, y) \equiv (y_1, y_2) \equiv (F_1, F_2) \equiv (r \cos \theta, r \sin \theta)
    \]
    %
    Note that \(\det \operatorname{J} = r\) and so \(F\) is a diffeomorphism iff \(r \neq 0\).
    %
    Given a vector field
    %
    \begin{equation}
        X_p = a(r, \theta) \partial_r + b(r, \theta)\partial_\theta \coloneqq a(r, \theta) \pdv{}{r} + b(r, \theta)\pdv{}{\theta}
    \end{equation}
    %
    we can compute the pushforward \(F_*\) wrt the \(\partial_x, \partial_y\) basis
    \begin{equation}
        F_* (X_p)
        =
        \begin{bmatrix}
            \cos (\theta) & -r \sin (\theta) \\
            \sin (\theta) & r \cos (\theta)
        \end{bmatrix}
        \cdot
        \begin{pmatrix}
            a \\ b
        \end{pmatrix}
        =
        \begin{pmatrix}
            a \cos (\theta) - br \sin (\theta) \\
            a\sin (\theta) + br \cos (\theta)
        \end{pmatrix}
    \end{equation}
    Hence, explicitly
    \begin{equation}
        F_* (X_p) = (a \cos (\theta) - br \sin (\theta))\partial_x + (a\sin (\theta) + br \cos (\theta))\partial_y
    \end{equation}

    Since \(\operatorname{J}\) is invertible we can investigate which vector fields map to \(\partial_x\)
    %
    \begin{equation}
        F_* X_p = \partial_x  \iff X_p = F_{*}^{-1} \partial_x
    \end{equation}
    %
    Let \(X_p = a \partial_r + b \partial_\theta\).
    %
    Then
    \begin{equation}
        X_p
        =
        \begin{bmatrix}
            \cos (\theta)            & \sin (\theta)           \\
            -\frac{\sin (\theta)}{r} & \frac{\cos (\theta)}{r} \\
        \end{bmatrix}
        \cdot
        \begin{pmatrix}
            1 \\ 0
        \end{pmatrix} \\
        =
        \begin{pmatrix}
            \cos(\theta) \\ -\frac{\sin (\theta)}{r}
        \end{pmatrix}
    \end{equation}
    However we need to write \(r, \theta\) in terms of \(x, y\)
    \begin{equation}
        F_{*}^{-1} \partial_x = \frac{x}{\sqrt{x^2+y^2}}\partial_r + \frac{y}{x^2 + y^2} \partial_\theta
    \end{equation}
    %
    \(F_{*}^{-1}\) is called the pullback \(F^*\) of the vector field \(\partial_x\) along \(F\).
\end{example}

Let \(F \colon N \rightarrow M\) and \(G \colon M \rightarrow P\) be smooth maps of manifolds, and \(p \in N\).
The differentials of \(F\) at \(p\) and \(G\) at \(F(p)\) are linear maps
\[
    T_p N \xrightarrow{F_{*,p}} T_{F(p)} M \xrightarrow{G_{*, F(p)}} T_{G(F(p))}P
\]
\begin{theorem}{Chain rule}{}
    If \(F \colon N \rightarrow M\) and \(G \colon M \rightarrow P\) are smooth maps of and \(p \in N\), then
    \[
        (G \circ F)_{*, p} = G_{*, F(p)} \circ F_{*,p}
    \]
\end{theorem}
\begin{proof}
    Let \(X_p \in T_p N\) and let \(f\) be \(\cinf\) at \(G(F(p)) \in P\).
    Then
    \[
        ((G \circ F)_* X_p) f = X_p (f \circ G \circ F)
    \]
    and
    \begin{splitenv}
        ((G_* \circ F_*) X_p) f &= (G_* (F_* X_p)) f \\
        &= (F_* X_p)(f \circ G) \\
        &= X_p (f \circ G \circ F)
    \end{splitenv}
\end{proof}
\begin{example}{Chain rule in Calculus notation}{}
    Suppose \(w = G(x,y,z)\) is a \(\cinf\) function \(\R^3 \rightarrow \R\) and \((x,y,z) = F(t)\) is a \(\cinf\) function \(\R \rightarrow \R^3\).
    Under composition
    \[
        w = (G \circ F)(t) = G(x(t), y(t), z(t))
    \]
    becomes a \(\cinf\) function \(\R \rightarrow \R\).
    The differentials
    \begin{splitenv}
        F_* &= \begin{bmatrix}
            \dv{x}{t} \\ \dv{y}{t} \\ \dv{z}{t}
        \end{bmatrix} \\
        G_* &= \begin{bmatrix}
            \pdv{w}{x} \; \pdv{w}{y} \; \pdv{w}{z}
        \end{bmatrix} \\
        (G \circ F)_* &= \dv{w}{t}
    \end{splitenv}
    and since composition of linear maps is matrix multiplication
    \begin{splitenv}
        (G \circ F)_* &= G_* \circ F_*  \\
        &= \begin{bmatrix}
            \pdv{w}{x} \; \pdv{w}{y} \; \pdv{w}{z}
        \end{bmatrix} \cdot \begin{bmatrix}
            \dv{x}{t} \\ \dv{y}{t} \\ \dv{z}{t}
        \end{bmatrix} \\
        &= \pdv{w}{x}\dv{x}{t} + \pdv{w}{y}\dv{y}{t} + \pdv{w}{z}\dv{z}{t}
    \end{splitenv}
\end{example}

\begin{proposition}{}{}
    If \(F \colon N \rightarrow M\) is a diffeomorphism of manifolds then
    \[
        F_* \colon T_p N \rightarrow T_{F(p)} M
    \]
    is an isomorphism of vector spaces.
\end{proposition}

Recall \(r^i\) the standard coordinates on \(R^n\), \((U, \phi)\) a chart about \(p \in M\) (\(M\) dimension \(n\)), and \(x^i = r^i \circ \phi\).
Since \(\phi\) is a diffeomorphism onto its image, the differential (pushforward) \(\phi*\) is a vector space isomorphism and

\begin{proposition}{}{}
    Let \((U, \phi) = (U, x^1, \dots, x^n)\). Then
    \begin{equation}
        \phi_* \left( \evalat[\bigg]{\pdv{}{x^i}}{p} \right) = \evalat[\bigg]{\pdv{}{r^i}}{\phi(p)}
    \end{equation}
\end{proposition}
\begin{proposition}{}{}
    Let \((U, \phi) = (U, x^1, \dots, x^n)\). Then \(T_p M\) has basis
    \[
        \left\{ \evalat[\bigg]{\pdv{}{x^1}}{p}, \dots, \evalat[\bigg]{\pdv{}{x^n}}{p} \right\}
    \]
\end{proposition}
\begin{proposition}{Transition matrix for coordinate vectors}{}
    Suppose \((U, \phi) = (U, x^1, \dots, x^n)\) and \((V, \psi) = (U, y^1, \dots, y^n)\).
    Then
    \[
        \pdv{x^j} = \sum_{i=1}^n \pdv{y^i}{x^j}\pdv{y^i}
    \]
    on \(U \cap V\).
\end{proposition}

Given \(F \colon N \rightarrow M\) and \(G \colon M \rightarrow P\) are smooth maps of and \(p \in N, F(p) \in M\).
We will find a local expression for the differential
\[
    F_{*,p} \colon T_p N \rightarrow T_{F(p)} M
\]
relative to the two charts.
Using the local coordinate bases (induced by the charts) \(F_* \equiv F_{*,p}\), is completely determined by \(a_j^i\) such that
\begin{equation}
    F_* \left( \evalat[\bigg]{\pdv{x^j}}{p} \right) = \sum_{k=1}^m a_j^k \evalat[\bigg]{\pdv{y^k}}{F(p)}
\end{equation}
Applying \(y^i\), we find that
\begin{splitenv}
    a_j^i &= \left( \sum_{k=1}^m a_j^k \evalat[\bigg]{\pdv{y^k}}{F(p)} \right) y^i \\
    &= F_* \left( \evalat[\bigg]{\pdv{x^j}}{p} \right) y^i \\
    &= \evalat[\bigg]{\pdv{x^j}}{p} (y^i \circ F) \\
    &= \evalat[\bigg]{\pdv{F^i}{x^j}}{p}
\end{splitenv}
We restate as a proposition
\begin{proposition}{}{}
    Given \(F \colon N \rightarrow M\) and \(G \colon M \rightarrow P\) are smooth maps of and \(p \in N, F(p) \in M\).
    Relative to bases \(\evalat{\prt{}{x^j}}{p}\) for \(T_p N\) and \(\evalat{\prt{}{y^i}}{F(p)}\) for \(T_{F(p)} M\) the differential \(F_{*, p} \colon T_p \rightarrow T_{F(p)} M\) is represented by the matrix
    \begin{equation}
        \begin{bmatrix}
            \evalat[\bigg]{\pdv{F^1}{x^1}}{p} & \cdots & \evalat[\bigg]{\pdv{F^1}{x^n}}{p} \\
            \vdots                            & \ddots & \vdots                            \\
            \evalat[\bigg]{\pdv{F^m}{x^1}}{p} & \cdots & \evalat[\bigg]{\pdv{F^m}{x^n}}{p}
        \end{bmatrix}
    \end{equation}
\end{proposition}

\subsubsection{Curves in a Manifold}

A \newterm{smooth curve} is a smooth map \(c \colon (a,b) \rightarrow M\) with \(0 \in (a,b)\) and we say that \(c\) is a curve starting at \(p\) if \(c(0) = p\).
The \newterm{velocity vector} \(c'(t_0)\) at time \(t_0\) is
\[
    c'(t_0) \coloneqq c_* \left( \evalat[\bigg]{\dv{t}}{t_0} \right) \in T_{c(t_0)}M
\]
\begin{proposition}{Velocity of a curve in local coordinates}{}
    Let \(c \colon (a,b) \rightarrow M\) be a smooth curve and let \(U, x^1, \dots, x^n\) be a coordinate chart about \(c(t)\).
    Write \(c^i = x^i \circ c\) for the \(i\)th component of \(c\) in the chart.
    Then \(c'(t)\) is given by
    \[
        c'(t) = \sum_{i=1}^n \dot{c}^i(t) \evalat[\bigg]{\pdv{x^i}}{c(t)}
    \]
    where \(\dot{c}\) is the scalar deriviatve of the \(i\)th component.
    Thus, relative to the basis \(\{\evalat{\prt{}{x^j}}{p}\}\) for \(T_{c(t)}M\), the velocity \(c'(t)\) is represented by the column vector
    \[
        \begin{bmatrix}
            \dot{c}^1(t) \\
            \vdots       \\
            \dot{c}^n(t)
        \end{bmatrix}
    \]
\end{proposition}
Every smooth curve \(c\) at \(p\) in a manifold \(M\) gives rise to a tangent vector \(c'(0)\) in \(T_p M\).
Conversely, one can show that every tangent vector \(X_p \in T_p M\) is the velocity vector of some curve at \(p\)
\begin{proposition}{Existence of a curve with a given initial vector}{}
    For any point \(p\) in a manifold \(M\) and any tangent vector \(X_p \in T_p M\), there are \(\varepsilon > 0\) and a smooth curve \((-\varepsilon, \varepsilon) \rightarrow M\) such that \(c(0) = p\) and \(c'(0) = X_p\).
\end{proposition}
\loadfig{curvevec}
\begin{proof}
    Let \((U, \phi) = (U, x^1, \dots, x^n)\) be a chart centered at \(p\) i.e. \(\phi(p) = \bm{0} \in \R^n\).
    Suppose \(X_p = \sum a^i \evalat[\big]{\prt{}{x^i}}{p}\) and let \(r^1, \dots, r^n\) be the standard coordinates on \(\R^n\), with \(x^i = r^i \circ \phi\).
    To find a curve \(c\) at \(p\) with \(c'(0)= X_p\), start with a curve \(\alpha \in \R^n\) with \(\alpha(0) = \bm{0}\) and \(\alpha'(0) = \sum a^i \evalat[\big]{\prt{}{r^i}}{\bm{0}}\).
    We then map \(\alpha\) to \(M\) via \(\phi^{-1}\) (see figure~\ref{fig:curvevec}).
    Let
    \[
        \alpha(t) \coloneqq (a^1 t, \dots, a^n t) \quad t \in (-\varepsilon, \varepsilon)
    \]
    with \(\varepsilon\) small enough such that \(\alpha(t) \in \phi(U)\).
    Then define \(c = \phi^{-1} \circ \alpha \colon (-\varepsilon, \varepsilon) \rightarrow M\).
    Then \(c(0) = \phi^{-1}(\alpha(0)) = \phi^{-1}(\bm{0}) = p\)
    and
    \begin{splitenv}
        c'(0) &= (\phi^{-1})_* \alpha_* \left( \evalat[\bigg]{\dv{t}}{t=0} \right) \\
        &= (\phi^{-1})_* \left( \sum_i a^i \evalat[\bigg]{\pdv{r^i}}{\bm{0}}  \right) \\
        &= \sum_i a^i \evalat[\bigg]{\pdv{x^i}}{p} = X_p
    \end{splitenv}
\end{proof}
This gives us a geometrical perspective on tangent vectors as directional derivatives
\begin{proposition}{Directional Derivatives}{}
    Suppose \(X_p\) is a tangent vector at a point \(p \in M\) and \(f \in C_p^\infty(M)\).
    If \(c \in (-\varepsilon, \varepsilon) \rightarrow M\) is a smooth curve starting at \(p\) with \(c'(0) = X_p\), then
    \[
        X_p f = \evalat[\bigg]{\dv{t}}{0} (f \circ c)
    \]
\end{proposition}

\begin{proposition}{}{}
    Let \(F \colon N \rightarrow M\) be a smooth map of manifolds, \(p \in N, X_p \in T_p N\).
    If \(c\) is a smooth curve starting at \(p \in N\) with velocity \(X_p\) at \(p\),
    \begin{equation}
        F_{*, p} (X_p) = \evalat[\bigg]{\dv{t}}{0} (F \circ c)(t)
    \end{equation}
\end{proposition}
\begin{example}{Differential of left multiplication}{}
    If \(g \in \gln\), let \(\ell_g \colon \gln \rightarrow \gln\) be left multiplication by \(g\) i.e. \(\ell_g (B) = g B\).
    Since \(\gln \subset \R^{n \times n}\) the tangent space \(T_g (\operatorname{GL}(n,\R))\) can be identified with \(\R^{n \times n}\).
    We show that with this identification the differential at the identity
    \[
        (\ell_g)_{*, \iota} \colon T_\iota (\gln) \rightarrow T_g (\gln)
    \]
    is also left multiplication by \(g\).

    Let \(X \in T_\iota (\gln) = \R^{n \times n}\).
    To compute \((\ell_g)_{*,\iota} (X)\), choose a curve \(c(t) \in \gln\) with \(c(0) = \iota\) and \(c'(0) = X\).
    Then \(\ell_g (c(t)) = g\cdot c(t)\) is simply matrix multiplication.
    Then
    \begin{splitenv}
        (\ell_g)_{*, \iota} (X) &= \evalat[\bigg]{\dv{t}}{t=0} \ell_g(c(t)) \\
        &= \evalat[\bigg]{\dv{t}}{t=0} g c(t) \\
        &= g c'(0) = gX
    \end{splitenv}
\end{example}

\subsection{Tangent Bundle}

A \newterm{smooth vector bundle} over a smooth manifold \(M\) is a smooth varying family of vector spaces, parameterized by \(M\), that locally looks like a product (of the manifold (base space) and the tangent spaces (fibers)).
The collection of tangent spaces to a manifold has the structure of a vector bundle, called the \newterm{tangent bundle}.
A smooth map between manifolds induces, via its differential at each point, a bundle map of the corresponding tangent bundles.
The tangent bundle is canonically associated to a manifold, hence invariants of the tangent bundle give rise to invariants of the manifold.
For example \newterm{Chern-Weil theory of characteristic classes} uses differential geometry to construct invariants for vector bundles; applied to the tangent bundle, characteristic classes lead to numerical diffeomorphism invariants of a manifold called \newterm{characteristic numbers} (which generalize the \newterm{Euler characteristic}).
A \newterm{section} of a vector bundle is a map that maps from each point of \(M\) into the \newterm{fiber} of the bundle over the point; both vector fields and differential forms on a manifold are sections of vector bundles.

\subsubsection{Topology of the Tangent Bundle}

Let \(M\) be a smooth manifold.
Recall that at each point \(p \in M\), the tangent space \(T_p M\) is the vector space of all point-derivations of \(\cinf_p (M)\) (itself the algebra of germs of \(\cinf\) functions at \(p\)).
The \newterm{tangent bundle} of \(M\) is the union of all the tangent spaces of \(M\)
\[
    TM \coloneqq \bigsqcup_{p \in M} T_p M
\]
There is a natural map (in the sense that it does not depend on choice of atlas or local coordinates) \(pi \colon TM \rightarrow M\) given by \(\pi(v) = p\) if \(v \in T_p M\).
As a matter of notation, we sometimes write a tangent vector \(v \in T_p M\) as a pair \((p, v)\).

As defined, \(TM\) is a set, with no topology or manifold structure.
We make it into a smooth manifold and show that it is a \(\cinf\) vector bundle over \(M\).
The first step is the topology.
If \((U, \phi) = (U, x^1, \dots, x^n)\) is a coordinate chart on \(M\), let
\[
    TU \coloneqq \bigsqcup_{p \in U} T_p U = \bigsqcup_{p \in U} T_p M
\]
where we've the fact that the algebra \(\cinf_p (U)\) of germs of \(\cinf\) functions in \(U\) at \(p\) is the same as \(\cinf_p (M)\) (since germ equivalence classes are determined by agreement in a neighborhood of \(p\)) and therefore \(T_p U = T_p M\).
At a point \(p \in U\) a tangent vector \(v \in T_p M\)
\[
    v = \sum_{i=1}^n c^i \evalat[\bigg]{\pdv{x^i}}{p}
\]
In this expression, \(c^i \equiv c^i(v)\) depend on \(v\) and so \textbf{therefore end up being functions on \(TU\)}.
%Let 
%\[ 
%    \bar{x}^i \coloneqq x^i \circ \pi \colon TM \rightarrow \R
%\]
% and 
Define \(\tilde{\phi} \colon TU \rightarrow \phi(U) \times \R^n\) by
\begin{gather}
    v \mapsto (x^1(p), \dots, x^n(p), c^1(v), \dots, c^n(v)) \\
    \iff \\
    \tilde{\phi}(v) = (\bar{x}^1 (v), \dots, \bar{x}^n(v), c^1(v), \dots, c^n (v)) \label{eqn:bundlechart}
\end{gather}
Then \(\bar{\phi}\) has an inverse (for a point \((x^1, \dots, x^n) = \phi(p)\))
\[
    \tilde{\phi}^{-1}(x^1(p), \dots, x^n(p), c^1(v), \dots, c^n(v)) = \sum c^i \evalat[\bigg]{\pdv{x^i}}{p}
\]
is therefore a bijection.
Therefore we use topology of \(\phi(U) \times \R^n\) to induce a topology on \(TU\): a set \(A \subset TU\) is open iff \(\tilde{\phi}(A)\) is open in \(\phi(U) \times \R^n\) (where \(\phi(U) \times \R^n\) has the standard topology as an open subset of \(\R^{2n}\)).
With this identification \(TU\) becomes homeomorphic to \(\phi(U) \times \R^n\).

\subsubsection{Manifold Structure on the Tangent Bundle}

Next we show that if \(\left\{ (U_i, \phi_i) \right\}\) is a \(\cinf\) atlas for \(M\), then \(\left\{  (TU_i, \tilde{\phi}_i) \right\}\) is a \(\cinf\) atlas for the tangent bundle \(TM\), where \(\tilde{\phi}_i\) is the map on \(TU_i\) induced by \(\phi_i\) as in~\eqref{eqn:bundlechart}.
It's immediately clear that \(TM = \bigcup_i TU_i\); remains to check that on \(TU_i \cap TU_j\), \(\tilde{\phi}_i, \tilde{\phi}_j\) are \(\cinf\) compatible.

Recall that if \((U, x^1, \dots, x^n), (V, y^1, \dots, y^n)\) are two charts on \(M\), then for any \(p \in U \cap V\) there are two bases and so any vector \(v \in T_p M\) has two representations
\[
    v = \sum_j a^j \evalat[\bigg]{\pdv{x^j}}{p} = \sum_i b^i \evalat[\bigg]{\pdv{y^i}}{p}
\]
Applying \(v\) to either of \(x^k, y^k\) we get that
\begin{equation}
    \begin{split}
        a^k &= \sum_i b^i \pdv{x^k}{y^i}  \\
        b^k &= \sum_j a^j \pdv{y^k}{x^j}
    \end{split}\label{eqn:twobases}
\end{equation}
Returning to the atlas \(\left\{ (U_i, \phi_i) \right\}\) and let \(\phi_\alpha = (x^1, \dots, x^n)\),  \(\phi_\beta = (y^1, \dots, y^n)\). Then
\[
    \tilde{\phi}_\beta \circ \tilde{\phi}_\alpha^{-1} \colon \phi_\alpha(U_\alpha \cap U_\beta) \times \R^n \rightarrow  \phi_\beta(U_\alpha \cap U_\beta) \times \R^n
\]
is given by (with \(\phi_\alpha(p) = (x^1(p), \dots, x^n(p))\))
\begin{splitenv}
    (\phi_\alpha(p), a^1(v), \dots, a^n(v)) &\mapsto \left( p, \sum_j a^j \evalat[\bigg]{\pdv{x^j}}{p} \right) \\
    &\mapsto ((\phi_\beta \circ \phi_\alpha^{-1})(\phi_\alpha(p)), b^1, \dots, b^n )
\end{splitenv}
where by~\eqref{eqn:twobases} and the Jacobian matrix of a transition map
\begin{splitenv}
    b^i &= \sum_j a^j \evalat[\bigg]{\pdv{y^i}{x^j}}{p}  \\ 
    &= \sum_j a^j \evalat[\bigg]{\pdv{(\phi_\beta \circ \phi_\alpha^{-1})}{r^j}}{\phi_\alpha(p)}
\end{splitenv}
By definition \(\phi_\beta \circ \phi_\alpha^{-1}\) is \(\cinf\) and therefore \(\tilde{\phi}_\beta \circ \tilde{\phi}_\alpha^{-1}\) is \(\cinf\) and thefore \(TM\) is a \(\cinf\) manifold, with \(\left\{ (TU_\alpha, \tilde{\phi}_\alpha) \right\}\) as a \(\cinf\) atlas.

\subsubsection{Vector Bundles}

On the tangent bundle \(TM\) of a smooth manifold \(M\), the natural projection map \(\pi \colon TM \rightarrow M\)
\[
    \pi(p, v)= p     
\]
makes \(TM\) into a \(\cinf\) \newterm{vector bundle} over \(M\) which we now define. 
Given any map \(\pi \colon E \rightarrow M\), where \(E\) is called the \newterm{total space} and \(M\)is called the \newterm{base space}, we call the inverse image \(\pi^{-1}(p) \coloneqq \pi^{-1}(\{p\})\) of a point \(p \in M\) the \newterm{fiber at \(p\)}.
The fiber at \(p\) is often written \(E_p\).
For any two maps 
\begin{splitenv}
    \pi &\colon E \rightarrow M  \\ 
    \pi' &\colon E' \rightarrow M 
\end{splitenv}
with the same target space \(M\), a map \(\phi \colon E \rightarrow E'\) is said to be \newterm{fiber-preserving} if \(\phi(E_p) \subset E_{p}'\) for all \(p \in M\).
\begin{example}{Fiber-preserving maps}{}
    Given two maps \(\pi, \pi'\), the map \(\phi\) is fiber-preserving iff the diagram
    \[
        \begin{tikzcd}
            E \arrow[swap]{rd}{\pi}\arrow{rr}{\phi} & & E' \arrow{ld}{\pi'} \\
            & M &
        \end{tikzcd}
    \]
    commutes.
\end{example}

\subsubsection{Smooth Sections}

A \newterm{section} of a vector bundle \(\pi \colon E \rightarrow M\) is a map \(s \colon M \rightarrow E\) such that \(\pi \circ s = \mathbf{1}_M\).
This just means that \(s\) maps \(p\) into the fiber \(E_p\) above \(p\) (see figure~\ref{fig:smoothsec}).
% \loadfig{smoothsec}

\begin{definition}{Vector field}{}
    A \newterm{vector field \(X\) on a manifold \(M\)} is a function that assigns a tangent vector \(X_p \in T_p M\) to each point \(p \in M\). In terms of the tangent bundle, a vector field on \(M\) is simply a section of the tangent bundle \(\pi \colon TM \rightarrow M\) and the vector field is smooth if it is a smooth as a map from \(M\) to \(TM\).
\end{definition}
% \loadfig{tangentbundle}
\begin{example}{}{}
    The formula
    \[
        X_{(x,y)} = \frac{1}{\sqrt{x^2+y^2}} \left( -y \pdv{x} + x \pdv{y} \right)  = \frac{1}{\sqrt{x^2+y^2}} \begin{bmatrix}
            -y \\ x
        \end{bmatrix}    
    \] 
    See figure~\ref{fig:vecfield}.
\end{example}
% \loadfig{vecfield}

\subsubsection{Smooth Frames}

A \newterm{frame} for a vector bundle \(\pi \colon E \rightarrow M\) over an open set \(U\) is a collection of sections \(s_1, \dots, s_r\) of \(E\) over \(U\) such that at each point \(p \in U\), the elements \(s_1(p), dots, s_r(p)\) form a basis for the fiber \(E_p \coloneqq \pi^{-1}(p)\).
A frame for the tangent bundle \(TM \rightarrow M\) over an open set \(U\) is simply called a \newterm{frame on \(U\)}.

\begin{example}{}{}
    The collection of vector fields \(\prt{}{x}, \prt{}{y}, \prt{}{z}\) is a smooth frame on \(\R^3\).
\end{example}

\begin{example}{}{}
    Let \(M\) be a manifold and \(e_1, \dots, e_r\) be the standard basis for \(\R^n\).
    Define \(\bar{e}_i \colon M \rightarrow M \times \R^r\) by \(\bar{e}_i (p) \coloneqq (p, e_i)\).
    Then \(\bar{e}_1, \dots \bar{e}_r\) is a \(\cinf\) frame for the product bundle \(M \times \R^r \rightarrow M\).
\end{example}

\subsection{Bump Functions and Partitions of Unity}

A partition of unity on a manifold is a collection of nonnegative functions that sum
to 1.

Usually one demands that the partition of unity should be \newterm{subordinate} to an open cover \(\{ U_\alpha \}_{\alpha \in A}\) i.e. the partition \(\{\rho_\alpha\}_{\alpha \in A}\) is indexed by the same set \(A\) and \(\rho_\alpha\) vanishes outside of \(U_\alpha\).

The existence of a \(\cinf\) partition of unity is one of the most important technical tools in the theory of \(\cinf\) manifolds.
It is the single feature that makes the behavior of \(\cinf\) manifolds so different from that of real-analytic or complex manifolds.
A partition of unity is used two ways:
\begin{enumerate}
    \item to decompose a global object on a manifold into a locally finite sum of local objects on the open sets \(U_\alpha\) of an open cover. 
    \item to patch together local objects on the open sets \(U_\alpha\) into a global object on the manifold.
\end{enumerate}

\subsubsection{\(\cinf\) Bump Functions}
\newcommand{\supp}{\operatorname{supp}}

The \newterm{support} of a real-valued function \(f\) on a manifold \(M\) is defined to be the closure in \(M\) of the subset on which \(f \neq 0\)
\begin{equation}
    \operatorname{supp} f = \operatorname{closure}\; \{ q \in M | f(q) \neq 0 \}
\end{equation}
Let \(q\) be a point in \(M\), and \(U\) a neighborhood of \(q\).
A \newterm{bump function at \(q\) supported in \(U\)} we mean any continuous nonnegative function \(\rho\) on \(M\) that is 1 in a neighborhood of \(q\) with \(\supp\; \rho \subset U\).
See figure~\ref{fig:bumpfunction}
% \loadfig{bumpfunction}

Define 
\begin{align}
    f(t) &= \begin{cases}
        e^{-1/t} &\text{for } t > 0 \\  
        0 &\text{for } t \leq 0 \\  
    \end{cases} \\
    g(t) &= \frac{f(t)}{f(t) + f(1-t)} \\ 
    h(x) &= g \left( \frac{x-a^2}{b^2 -a^2} \right) \\ 
    k(x) &= h(x^2) \\ 
    \rho(x) &= 1 - k(x)
\end{align}
See figure~\ref{fig:bumpfunction2}.
\loadfig{bumpfunction2}
It is easy to extend the construction \(\rho(x)\) to a bump function from \(\R\) to \(R^n\): to get a \(\cinf\) bump function at \(\bm{0} \in \R^n\) that is 1 on the closed ball \(\bar{B}(\bm{0}, a)\) and has support in the closed ball \(\bar{B}(\bm{0}, b)\)
\begin{equation}
    \sigma(x) \coloneqq \rho(\abs{x}) = 1 - g \left( \abs{x} \frac{r^2 - a^2}{b^2 -a^2} \right)
\end{equation}

In general, a \(\cinf\) on an open subset \(U\) of a manifold cannot be extended to a \(\cinf\) function on \(M\); an example is the function \(\sec (x)\) on the open interval \((-\pi/2, \pi/2) \subset \R\).
However, if we require that the global function on \(M\) agree with the given function only on some neighborhood of a point in \(U\), then a \(\cinf\) extension is possible.

\begin{proposition}{\(\cinf\) extension of a function}{}
    Suppose \(f\) is a \(\cinf\) function defined on a neighborhood \(U\) of a point \(p\) in a manifold \(M\).
    Then there is a \(\cinf\) function \(\tilde{f}\) on \(M\) that agrees with \(f\) in some possibly smaller neighborhood of \(p\).
\end{proposition}
\begin{proof}
    Choose a \(\cinf\) bump function \(\rho \colon M \rightarrow \R\) supported in \(U\) that is identically 1 in a neighborhood \(V\) of \(p\).
    Define 
    \[
        \tilde{f}(q) = \begin{cases}
            \rho(q)f(q) & \text{for } q \in U \\ 
            0 & \text{for } q \notin U
        \end{cases}
    \]
    As the product of two \(\cinf\) functions on \(U\), \(\tilde{f}\) is \(\cinf\) on \(U\).
    If \(q \notin U\), then \(q \notin \supp \rho\), and so there is an open set containing \(q\) on which \(\tilde{f}\) is 0, since \(\supp \rho\) is closed.
    Therefore, \(\tilde{f}\) is also \(\cinf\) at every point \(q \notin U\).
    Finally, since \(\rho = 1\) on \(V\), the function \(\tilde{f}\) agrees with \(f\) on \(V\).
\end{proof}

\subsubsection{Partitions of Unity}
 If \(\{U_i\}_{i \in I}\) is a finite open cover of \(M\), a \newterm{\(\cinf\) partition of unity subordinate to \(\{U_i\}_{i \in I}\)} is a collection of nonnegative \(\cinf\) functions \(\{\rho_i \colon M \rightarrow \R\}_{i \in I}\) such that \(\supp \rho_i \subset U_i\) and 
 \[
    \sum_i \rho_i =    1
 \]
 When the index set \(I\) is an infinite set, for the sum to make sense, we impose and additional \newterm{local finiteness} condition: a collection \(\{A_i\}\) of subsets of a topological space \(S\) is said to be \newterm{locally finite} if every point \(q \in S\) has a neighborhood that meets only finitely many of the sets \(A_i\). In particular, every \(q \in S\) is contained in only finitely many of the \(A_i\).

 \begin{example}{An open cover that is not locally finite}{}
    Let \(U_{r,n}\) be the open interval \(\left( r - \frac{1}{n}, r + \frac{1}{n} \right)\).
    The open cover \(\{ U_{r,n} | r \in \mathbb{Q}, n \in \mathbb{Z}^+ \}\) of \(\R\) is not locally finite.
 \end{example}
 \begin{definition}{\(\cinf\) partition of unity}{}
    A \newterm{\(\cinf\) partition of unity on a manifold} is a collection of nonnegative \(\cinf\) functions \(\{\rho_i \colon M \rightarrow \R\}_{i \in I}\) such that 
    \begin{enumerate}
        \item the collection of supports is locally finite
        \item \(\sum \rho_i = 1\)
    \end{enumerate}
 \end{definition}

 Suppose \(\{f_i\}\) is a collection of \(\cinf\) functions on a manifold \(M\) such that the collection of its supports is locally finite.
 Then every point \(q \in M\) has a neighborhood \(W_q\) that intersects \(\supp f_i\) for only finitely many \(i\). 
 Thus, on \(W_q\) the sum \(\sum_i f_i\) is a finite sum.
 This shows that \(f = \sum _i f_i\) is well defined and \(\cinf\) on the manifold \(M\).
 Such a sum is called a locally finite sum.

 \begin{theorem}{Existence of a \(\cinf\) partition of unity}{}
    Let \(\{U_i\}\) be an open cover of a manifold \(M\).
    Then 
    \begin{enumerate}
        \item there is a \(\cinf\) partition of unity \(\{ \phi_k \}_{k=1}^\infty\) having compact support such that for each \(k, \supp \phi_k \subset U_i\) for some \(i\).
        \item if we do not require compact support, then there is a \(\cinf\) partition of unity \(\{ \rho_i \}\) subordinate to \( \{ U_i \} \).
    \end{enumerate}
 \end{theorem}

 \subsection{Vector Fields}

 A vector field \(X\) on a manifold \(M\) is the assignment of a tangent vector \(X_p \in T_p M\) to each point \(p \in M\) (a section of the tangent bundle \(TM\) of M).
 Every smooth vector field may be viewed locally as the velocity vector field of a fluid flow; the path traced out by a point under this flow is called an \newterm{integral curve} of the vector field.
 \textbf{Integral curves are curves whose velocity vector field is the restriction of the manifold's vector field, to the curve}; finding an equation of an integral curve is equivalent to solving a system of first-order ODEs.
 The set \(\mathfrak{X}(M)\) of all \(\cinf\) vector fields on a manifold \(M\) has the structure of a vector space; the \newterm{Lie Bracket} \([\;,\;]\) makes it into a \newterm{Lie algebra}.

 \subsubsection{Integral Curves}

\begin{definition}{Integral Curves}{}
    Let \(X\) be a \(\cinf\) vector field on a manifold \(M\), and \(p \in M\). 
    An \newterm{integral curve} \(c \colon (a,b) \rightarrow M\) such that \(c'(t) = X_{c(t)}\) for all \(t \in (a,b)\).
    To show the dependence of an integral curve on its initial point \(p\), we write \(c_t(p)\).
\end{definition}

\begin{example}{}{}
    Recall the vector field \(X_{(x,y)} = \langle -y,x \rangle\) on \(\R^2\).
    The condition for \(c(t) = (x(t), y(t))\) to be an integral curve is \(c'(t) = X_{c(t)}\) or 
    \[
        \begin{bmatrix}
            \dot{x}(t) \\ \dot{y}(t)
        \end{bmatrix} = \begin{bmatrix}
            -y(t) \\ x(t)
        \end{bmatrix}   
    \]
    Hence we need to solve the system of first-order ODEs 
    \begin{splitenv}
        \dot{x} &= -y \\ 
        \dot{y} &= x
    \end{splitenv}
    with initial condition \((x(0), y(0)) = (1,0)\).
    Making substitutions we get 
    \[
        \ddot{x} = -x
    \]
    which has the solution 
    \[
        x = A \cos t + B \sin t    
    \]
    and therefore 
    \[
        y = -\dot{x} = A \sin t - B \cos t
    \]
    The initial condition forces \(A=1,B=0\) and hence \(c(t) = (\cos t, \sin t)\), which parameterizes the unit circle.
    More generally, if the initial point of the integral curve, corresponding to \(t = 0\), is \(p = (x_0, y_0)\), then 
    \[
        A = x_0 \quad B = -y_0    
    \]
    and 
    \begin{splitenv}
        x &= x_0 \cos t - y_0 \sin t \\ 
        y &= x_0 \sin t + y_0 \cos t
    \end{splitenv}
    which can be written in matrix notation 
    \begin{splitenv}
        c(t) &= \begin{bmatrix}
            x(t) \\ y(t)
        \end{bmatrix} \\ 
        & = 
        \begin{bmatrix}
            \cos t & - \sin t \\ 
            \sin t & \cos t
        \end{bmatrix} \begin{bmatrix}
            x_0 \\ y_0
        \end{bmatrix} \\
        &= 
        \begin{bmatrix}
            \cos t & - \sin t \\ 
            \sin t & \cos t
        \end{bmatrix} p
    \end{splitenv}
    This show that the integral curve of \(X\) starting at point \(p\) can be obtained by rotating point \(p\) counterclockwise about the origin through an angle \(t\).
    Note that 
    \[
        c_s(c_t(p)) = c_{s+t} (p)   
    \]
    and also that for each \(t \in \R\), \(c_t \colon \R^2 \rightarrow \R^2\) is a diffeomorphism with inverse \(c_{-t}\).
    Let \(operatorname{Diff}(M)\) be the group of diffeomorphisms of a manifold \(M\) to itself, with the group operation being composition.
    A homomorphism \(c \colon \R \rightarrow \operatorname{Diff}(M)\) is called a \newterm{one-parameter group of diffeomorphisms} of \(M\).
    \textbf{In this example the integral curves of the vector field \(X_{(x,y)} = \langle -y,x \rangle\) on \(\R^2\) give rise to a one-parameter group of diffeomorphisms of \(R^2\)}.
\end{example}

\subsubsection{Local Flows}

In general, if \(X\) is a smooth vector field on a manifold \(M\), to find an integral curve \(c(t)\) of \(X\) starting at \(p\), we first choose a coordinate chart \((U, \phi) = (U, x^1, \dots, x^n)\) about \(p\).
In terms of the local coordinates 
\[
    X_{c(t)} = \sum a^i(c(t)) \evalat[\bigg]{\pdv{x^i}}{c(t)}
\]
or 
\[
    c'(t) = \sum \dot{c}^i (t) \evalat[\bigg]{\pdv{x^i}}{c(t)}    
\]
where \(c^i(t) = x^i \circ c(t)\) is the \(i\)th component of \(c(t)\) in the chart \((U, \phi)\).
The condition \(c'(t) = X_{c(t)}\) is equivalent to 
\[
    \dot{c}^i (t) = a^i(c(t))
\]
This is a system of ODEs; by \newterm{Picard–Lindelöf theorem} such a system has a unique solution in the following sense 
\begin{theorem}{}{}
    Let \(V\) be an open subset of \(\R^n\), \(p_0 \in V\), and \(f \colon V \rightarrow \R^n\) a \(\cinf\) function. 
    Then the differential equation 
    \[
        \dv{y}{t} = f(y)   \quad y(0) = p_0
    \]
    has a unique \(\cinf\) solution \(y \colon (a(p_0), b(p_0)) \rightarrow V\).
\end{theorem}

Suppose \(s,t\) in the interval \((-\varepsilon, \varepsilon)\) are such that both \(F_t(F_s(q))\) and \(F_{t+s}(q)\) are defined.
Then both \(F_t(F_s(q))\) and \(F_{t+s}(q)\), as functions of \(t\), are integral curves of \(X\) with initial point \(F_s(q)\).
By uniqueness of the integral curve starting at a point 
\[
    F_t(F_s(q)) = F_{t+s}(q)   
\]
The map \(F\) is called a \newterm{local flow generated by the vector field \(X\)}.
For each \(q \in U\), the function \(F_t(q)\) of \(t\) is called a \newterm{flow line} of the local flow.
See figure~\ref{fig:localflow}.
% \loadfig{localflow}
Each flow line is an integral curve of \(X\); if a local flow \(F\) defined on \(\R \times M\), then it is called a \newterm{global flow} (every smooth vector field has a local flow, but not necessarily a global flow).
A vector field having a global flow is called a \newterm{complete vector field}.
If \(F\) is a global flow, then for every \(t \in \R\)
\[
    F_t \circ F_{-t} = F_{-t} \circ F_t = F_0 = \bm{1}_M
\]
so \(F_t \colon M \rightarrow M\) is a diffeomorphism.
Thus, a global flow on \(M\) gives rise to a one-parameter group of diffeomorphisms on \(M\).

\begin{definition}{Local Flow}{}
    A \newterm{local flow} about a point \(p\) in an open set \(U\) of a manifold is a \(\cinf\) function 
    \[
         F \colon   (-\varepsilon, \varepsilon) \times W \rightarrow U
    \]
    where \(\varepsilon > 0\) and \(W\) is a neighborhood of \(p\) and \(W \subset U\), such that writing \(F_t(q)\coloneqq F(t,q)\), we have 
    \begin{enumerate}
        \item \(F_0(q) = q\) for all \(q \in W\)
        \item \(F_t(F_s(q)) = F_{t+s}(q)\) whenever both sides are defined
    \end{enumerate}
\end{definition}

If \(F_t(q)\) is a local flow of the vector field \(X\) on \(U\), then 
\begin{splitenv}
    F(0, q) &= q \\ 
    \evalat[\bigg]{\pdv{F}{t}}{0,q} &= X_{F(0,q)} \\ 
    &= X_q
\end{splitenv}
Thus, one can recover the vector field from its flow.
\begin{example}{}{}
    The function \(F \colon \R \times \R^2 \rightarrow \R^2\) 
    \[
        F \left( t, \begin{bmatrix}
            x \\ y
        \end{bmatrix} \right) =         \begin{bmatrix}
            \cos t & - \sin t \\ 
            \sin t & \cos t
        \end{bmatrix} \begin{bmatrix}
            x \\ y
        \end{bmatrix}    
    \]
    is the global flow on \(\R^2\) generated by the vector field 
    \begin{splitenv}
        X_{(x,y)} &= \evalat[\bigg]{\pdv{F(t,(x,y))}{t}}{t=0} \\ 
        &= \begin{bmatrix}
            \cos t & - \sin t \\ 
            \sin t & \cos t
        \end{bmatrix} \evalat[\bigg]{\begin{bmatrix}
            x \\ y
        \end{bmatrix} }{t=0} \\ 
        &= \begin{bmatrix}
            0 & -1  \\ 
            1 & 0
        \end{bmatrix} \begin{bmatrix}
            x \\ y
        \end{bmatrix} = \begin{bmatrix}
            -y \\ x
        \end{bmatrix} \\ 
        &= -y \pdv{x} + x \pdv{y}
    \end{splitenv}
\end{example}

\subsubsection{The Lie Bracket}

Suppose \(X,Y\) are smooth vector fields on an open subset \(U\) of a manifold \(M\).
We view \(X,Y\) as derivations on the set of \(\cinf\) functions.
For a \(\cinf\) function \(f\) on \(U\), the function \(Yf\) is \(\cinf\) on \(U\), and the function \((XY)f \coloneqq X(Yf)\) is also \(\cinf\) on \(U\).
Moreover, because \(X,Y\) are both \(\R\)-linear maps from \(\cinf(U)\) to \(\cinf(U)\), the map \(XY \colon \cinf(U) \rightarrow \cinf(U)\) is \(\R\)-linear.
However, \(XY\) does not satisfy the derivation property: if \(f,g \in \cinf(U)\), then 
\begin{splitenv}
    XY(fg) &= X \left( (Yf)g + f Y g \right)  \\ 
    &= (XYf)g + (Yf)(Xg) + (Xf)(Yg) + f(XYg)
\end{splitenv}
Looking more closely we see that the two extra terms \((Yf)(Xg)\) and \((Xf)(Yg)\) that make \(XY\) not a derivation, are symmetric in \(X,Y\).
Thus is we compute \(YX(fg)\) and subtract it from \(XY(fg)\), the extra terms will disappear, and \(XY-YX\) will be a derivation of \(\cinf(U)\).
\begin{definition}{Lie Bracket}{}
    Given two smooth vector fields \(X,Y\) on \(U\) and with \(p \in U\), we define their \newterm{Lie Bracket} \(\left[X,Y\right]\) at \(p\)
    \begin{equation}
        \left[X,Y\right]_p f = (X_p Y - Y_p X)f
    \end{equation}
    for any germ \(f\) of a \(\cinf\) function at \(p\).
\end{definition}
By the same calculation as above, but now evaluated at \(p\), it is easy to check that \([X,Y]_p\) is a derivation of \(\cinf_p (U)\) and is therefore a tangent vector at \(p\).
As \(p\) varies over \(U\), \([X,Y]\) becomes a vector field on \(U\).
\begin{proposition}{}
    If \(X,Y\) are smooth vector fields on \(M\), then the vector field \([X,Y]\) is also smooth on \(M\).
\end{proposition}
From this, we see that the Lie bracket provides a product operation on the vector space \(\mathfrak{X}(M)\) of all smooth vector fields on \(M\).
Clearly
\[
    [Y,X] = -[X,Y]    
\]
\begin{example}{Jacobi identity}{}
    The \newterm{Jacobi identity} holds for the Lie bracket 
    \[\sum_{\text{cyclic}} \left[ X, [Y,Z] \right] = 0\]
    where 
    \[
        \sum_{\text{cyclic}} \left[ X, [Y,Z] \right] = [X, [Y,Z]] + [Y, [Z,X]] + [Z,[X,Y]]
    \]
\end{example}
\begin{definition}{Lie Algebra}{}
    Let \(K\) be a field. 
    A \newterm{Lie algebra} over \(K\) is a vector space \(V\) over \(K\) together with a product
    \[
        [\;, \;]  \rightarrow V \times V \rightarrow V
    \]
    called the \newterm{bracket}, satisfying the following properties: for all \(a,b \in K\) and \(X,Y,Z \in V\)
    \begin{enumerate}
        \item \textbf{bilinearity}: \begin{splitenv}
            [aX + bY, Z] &= a [X,Z] + b [Y,Z] \\ 
            [Z, aX + bY] &= a [Z,X] + b[Z,Y]
        \end{splitenv}
        \item \textbf{anticommutativity}: \[[Y,X] = -[X,Y]\]
        \item \textbf{Jacobi identity}: \[\sum_{\text{cyclic}} \left[ X, [Y,Z] \right] = 0\]
    \end{enumerate}
\end{definition}

\begin{example}{Abelian Lie algebra}{}
    On any vector space \(V\), define \([X,Y]=0\) for all \(X,Y \in V\). With this bracket, \(V\) becomes a Lie algebra, called an \newterm{abelian Lie algebra}.
\end{example}
\textbf{An abelian Lie algebra is trivially associative, but in general the bracket of a
Lie algebra need not be associative. So despite its name, a Lie algebra is in general
not an algebra.}

\begin{example}{}{}
    If \(M\) is a manifold, then the vector space \(\mathfrak{X}(M)\) of \(\cinf\) vector fields on \(M\) is a real Lie algebra with the Lie bracket \([,]\) as the bracket.
\end{example}

\begin{example}{}{}
    Let \(K^{n \times n}\) be the vector space of all \(n \times n\) matrices over a field \(K\).
    Define
    \[
        [X,Y] = XY - YX    
    \]
    where \(XY\) is the matrix product of \(X\) and \(Y\).
    With this bracket, \(K^{n \times n}\) becomes a Lie algebra.
    More generally, if \(A\) is any algebra over a field \(K\), then the product 
    \[
        [x,y] = xy - yx    
    \]
    for \(x,y \in A\) makes \(A\) into a Lie algebra over \(K\).
\end{example}
\begin{definition}{derivation}{}
    A \newterm{derivation of a Lie algebra \(V\)} over a field \(K\) is a \(K\)-linear map \(D \colon V \rightarrow V\) satisfying the product rule 
    \[
        D[Y,Z] = [DY, Z] + [Y, DZ]
    \]
    for \(Y,Z in V\).
\end{definition}
\begin{example}{}{}
    Let \(V\) be a Lie algebra over a field \(K\). For each \(X \in V\), define 
    \[
        \operatorname{ad}_X (Y) = [X,Y]    
    \]
\end{example}

\subsubsection{Pushforward of Vector Fields}

Let \(F \colon N \rightarrow M\) be a smooth map of manifolds and let \(F_* \colon T_p N \rightarrow T_{F(p)}M\) be its differential at a point \(p\) in \(N\).
If \(X_p \in T_p N\), we call \(F_* (X_p)\) the \newterm{pushforward} of the vector \(X_p\) at \(p\).
This notion doesn't extend in general to vector fields, since it \(X\) is a vector field on \(N\) and 
\[
    z = F(p) = F(q)    
\]
for two distinct points \(p,q \in N\), then \(X_p\) and \(X_q\) are both pushed forward to tangent vectors \(X_z \in T_z M\), but there is no reason why \(F_* (X_p)\) and \(F_*(X_q)\) should be equal.

\subsection{Lie Groups and Lie Algebras}

A \newterm{Lie group} is a manifold that is also a group such that the group operations are smooth.
A Lie group is a homogeneous space in the sense that left translation by a group element \(g\) is a diffeomorphism of the group onto itself that maps the identity element to itself.
Therefore, locally the group looks the same around any point in the group.
To study the local structure of a Lie group, it is enough to examine a neighborhood of the identity element.
The tangent space at the identity of a Lie group \(G\) turns out to have a canonical bracket operation \([\;,\;]\) that makes it into a Lie algebra.
The tangent space \(T_e G\) with the bracket is called the \newterm{Lie algebra} of the Lie group \(G\).
The Lie algebra of a Lie group encodes within it much information about the group.

The matrix exponential gives rise to curves in a matrix group with a given initial vector.
It is useful in computing the differential of a map on a matrix group.

\subsubsection{Lie Group}

\begin{definition}{Lie group}{}
    A \newterm{Lie group} is a \(\cinf\) manifold \(G\) that is also a group such that the two group operations, multiplication
    \[
        \mu \colon G \times G \rightarrow G \quad \mu(a,b) \coloneqq ab   
    \]
    and inverse 
    \[
        \iota \colon G \rightarrow G \quad \iota(a) = a^{-1}   
    \]
    are \(\cinf\).
    For \(a \in G\), denote by 
    \begin{splitenv}
        \ell_a \colon G \rightarrow G \\ 
        \ell_a(x) = \mu(a,x) = ax 
    \end{splitenv}
    the operation of \newterm{left multiplication by \(a\)} and similarly by \(r_a\) the operation of \newterm{right multiplication by \(a\)}.
    We also call these operations \newterm{left and right translations}.
\end{definition}

\begin{example}{Left multiplication}{}
    For an element \(a \in G\), prove that the left multiplication/translation \(\ell_a \colon G \rightarrow G\) is a diffeomorphism.
\end{example}
\begin{definition}{Lie group homomorphism}{}
    A map \(F \colon H \rightarrow G\) between two Lie groups \(H, G\) is a \newterm{Lie group homomorphism} if it is a \(\cinf\) map and a group homomorphism.
    The group homomorphism condition means that for all  \(h,x \in H\)
    \[
        F(hx) = F(h)F(x)    
    \]
    or rewritten 
    \[
        F \circ \ell_h = \ell_{F(h)} \circ F
    \]
    for all \(h \in H\).
    Note that a group homomorphism always maps the identity to the identity.
\end{definition}

\begin{definition}{Orthogonal group}{}
    Recall that the orthogonal group \(\operatorname{O}(n)\) is the subgroup of \(\gln\) consisting of all matrices \(A\) satisfying \(A^T A = I\).
    Thus, \(\operatorname{O}(n)\) is the inverse image of \(I\) under the map \(f(A) = A^T A\).
\end{definition}

\subsubsection{Matrix Exponential}

Recall computing the pushforward using a smooth curve 
\[
    F_{*,p} (X_p) = \evalat[\bigg]{\dv{t}}{0} (F \circ c)(t)    
\]

To compute the differential of a map on a subgroup of \(\operatorname{GL}(n ,\R)\), we need a curve of nonsingular matrices.
Because the matrix exponential is always nonsingular, it is uniquely suited for this purpose.
\begin{definition}{Norm}{}
    A \newterm{norm} on a vector \(V\) is a real-valued \(\abs{\cdot}\colon V \rightarrow \R\) satisfying the following three properties for all \(r \in \R, v,w \in V\)
    \begin{enumerate}
        \item \textbf{positive-definiteness}: \(\abs{v} \geq 0\) with equality iff \(v = 0\)
        \item \textbf{positive homogeneity}: \(\abs{rv} = \abs{r}\abs{v}\)
        \item \textbf{subadditivity}: \(\abs{v+w} \leq \abs{v} + \abs{w}\)
    \end{enumerate}
    A vector space \(V\) with a norm is called a \newterm{normed vector space}.
    For example, the vector space \(\R^{n \times n} \cong \R^{n^2}\) with the norm 
    \[
        \abs{X} = \sqrt{\sum_{ij} x_{ij}^2}  
    \]
\end{definition}
\begin{definition}{Matrix exponential}{}
    The \newterm{matrix exponential} \(e^X\) of a matrix \(X \in \R^{n\times n}\) is defined 
    \[
        e^X = I + X + \frac{1}{2!}X^2 + \frac{1}{3!}X^3 + \cdots    
    \]
    If \(A, B\) commute then 
    \[
        e^A e^B = e^{A+B}    
    \]
\end{definition}
\begin{proposition}{}{}
    For \(X \in \R^{n \times n}\)
    \[
        \dv{t} e^{tX} = X e^{tX} = e^{tX} X    
    \]
\end{proposition}

\subsubsection{Trace of a Matrix}

\begin{definition}{Trace of a Matrix}{}
    For a \(n \times n\) matrix \(X\)
    \[
        \operatorname{tr}(X) = \sum_{i=1}^n x_ii    
    \]
    i.e. the sum of the diagonal elements.
\end{definition}
\begin{lemma}{}{}
    \begin{enumerate}
        \item For any two matrices \(X,Y \in \R^{n \times n}\) \[
            \operatorname{tr}(XY) = \operatorname{tr}(YX)    
        \]
        \item For \(X \in \R^{n \times n}\) and \(A \in \gln\) \[
            \operatorname{tr}(AXA^{-1}) = \operatorname{X}    
        \]
    \end{enumerate}
\end{lemma}
\begin{proposition}{}{}
    The trace of a matrix, real or complex, is equal to the sum of its complex \newterm{eigenvalues} 
\end{proposition}
\begin{proof}
    Suppose \(X\) has complex eigenvalues \(\lambda_1, \dots, \lambda_n\).
    Then there exists a nonsingular matrix \(A \in \operatorname{GL}(n, \C)\) such that 
    \[
        AXA^{-1} = \begin{bmatrix}
            \lambda_1 & & * \\ 
            & \ddots & \\
            0 & & \lambda_n
        \end{bmatrix}
    \]
    and then 
    \[
        \operatorname{tr}(X) = \operatorname{tr} (AXA^{-1}) = \sum_i \lambda_i
    \]
\end{proof}
\begin{proposition}{}{}
    For any \(X \in \R^{n \times n}\) 
    \[
        \det (e^X) = e^{\operatorname{tr}(X)}   
    \]
\end{proposition}
\begin{proof}
    Case 1: Assume that \(X\) is upper triangular 
    \[
        X = \begin{bmatrix}
            \lambda_1 & & * \\ 
            & \ddots & \\
            0 & & \lambda_n
        \end{bmatrix}
    \]
    Then 
    \begin{splitenv}
         e^X &= \sum \frac{1}{k!}X^k \\
         &= \sum \frac{1}{k!} \begin{bmatrix}
            \lambda_1^k & & * \\ 
            & \ddots & \\
            0 & & \lambda_n^k
        \end{bmatrix} \\ 
        &= \begin{bmatrix}
            e^{\lambda_1} & & * \\ 
            & \ddots & \\
            0 & & e^{\lambda_n}
        \end{bmatrix}
    \end{splitenv}
    and hence \[\det e^X = \prod e^{\lambda_i} = e^{\sum \lambda_i} = e^{\operatorname{tr}X}\].
    Case 2: Given a general matrix \(X\), with eigenvalues \(\lambda_1, \dots, \lambda_n\), we can find a nonsingular matrix \(A\) such that 
    \[
        AXA^{-1} = \begin{bmatrix}
            \lambda_1 & & * \\ 
            & \ddots & \\
            0 & & \lambda_n
        \end{bmatrix}
    \]
    an upper triangular matrix. 
    Then 
    \begin{splitenv}
        e^{AXA^{-1}} &= I + AXA^{-1} + \frac{1}{2!} (AXA^{-1})^2 + \frac{1}{3!}(AXA^{-1})^3 + \cdots \\ 
        &= I + AXA^{-1} + A \left( \frac{1}{2!} X^2 \right) A^{-1} + A \left( \frac{1}{3!} X^3 \right) A^{-1} + \cdots \\ 
        &= A e^X A^{-1}
    \end{splitenv}
    and hence 
    \begin{splitenv}
        \det e^X &= \det (A e^X A^{-1}) \\ 
        &= \det e^{A X A^{-1}}  \\ 
        &= e^{\operatorname{tr}(AXA^{-1})} \\ 
        &= e^{\operatorname{tr}X}
    \end{splitenv}
\end{proof}
It follows that the matrix exponential \(e^X\) is always nonsingular, because \(\det(e^X) = e^{\tr X} \neq 0\).
This is one reason why the matrix exponential is so useful, for it allows us to write down explicitly a curve in \(\gln\) with a given initial point and a given initial velocity.
For example \(c(t) = e^{tX} \colon \R \rightarrow \gln\) is a curve in \(\gln\) with initial point \(I\) and initial velocity \(X\), since 
\[
    c(0) = e^{0 X} = e^0 = I    
\]
and 
\[
    c'(0) = \evalat[\bigg]{\dv{t} e^{tX}}{t=0} = \evalat[\bigg]{X e^{tX}}{t=0} = X
\]
Similarly, \(c(t) = A e^{tX}\) is a curve in \(\gln\) with initial point \(A\) and initial velocity \(AX\).

\subsubsection{The Differential of \(\det\) at the identity}

Let \(\det \colon \gln \rightarrow \R\) be the determinant map.
The tangent space \(T_I \gln\) at the identity matrix \(I\) is the vector space \(\R^{n \times n}\) and the tangent space \(T_1 \R\) to \(\R\) at 1 is \(\R\). 
So 
\[
    \operatorname{det}_{*, I} \colon \R^{n \times n} \rightarrow \R
\]
\begin{proposition}{}{}
    For any \(X \in \R^{n \times n}\) it is the case that \(\det_{*,I}(X) = \tr X\)
\end{proposition}
\begin{proof}
    We use a a curve at \(I\) to compute the differential. 
    As a curve \(c(t)\) with \(c(0)=I\) and \(c'(0) = X\), choose the matrix exponential \(c(t)=e^{tX}\).
    Then 
    \begin{splitenv}
        \operatorname{det}_{*,I}(X) &= \evalat[\bigg]{\dv{t} \det (e^{tX})}{t=0} \\ 
        &= \evalat[\bigg]{\dv{t} e^{t \tr X}}{t=0} \\
        &= \evalat[\bigg]{(\tr X) e^{t \tr X}}{t=0} \\
        &= \tr X
    \end{splitenv}
\end{proof}