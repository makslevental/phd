

% \subsubsection{Pushforwards and Pullbacks}\label{subsubsec:diffgeo}

\newcommand{\gln}{\operatorname{GL}(n, \R)}
\newcommand{\Rnn}{\R^{n \times n}}
\section{Smooth Manifolds}\label{sec:dg}
\localtableofcontents

\subsection{Directional Derivative}

Elements of the \newterm{tangent space} \(T_p (\mathbb{R}^n)\) anchored at a point \(p = (p^1, \dots, p^n) \in \mathbb{R}^n\) can be visualized as arrows emanating from \(p\).
%
These arrows are called \newterm{tangent vectors} and represented by column vectors:
%
\begin{equation}
    \bm{v}
    =
    \begin{bmatrix}
        v^1 \\ \vdots \\ v^n
    \end{bmatrix}
    % =
    % \begin{bmatrix}
    %     v^1, \dots, v^n    
    % \end{bmatrix}
\end{equation}
%
The line through a point \(p\) with direction \(\bm{v}\) has parameterization
%
\begin{equation}
    c(t) = \left( p^1 + t v^1, \dots, p^n + t v^n \right)
\end{equation}
%
If \(f \in C^\infty\) in a neighborhood of \(p\) and \(\bm{v}\) is a tangent vector at \(p\), the \newterm{directional derivative} of \(f\) in the direction of \(\bm{v}\) at \(p\) is defined
%
\begin{equation}
    D_{\bm{v}} f
    =
    \lim_{t\rightarrow 0}\, \frac{f(c(t)) - f(p)}{t}
    =
    \evalat[\bigg]{\dv{}{t} f(c(t))}{t=0}
\end{equation}
%
By the chain rule
%
\begin{align}
    D_{\bm{v}} f & = \sum_{i=1}^{n} \evalat[\bigg]{\pdv{f}{x^i}}{p} \evalat[\bigg]{\dv{c^i}{t}}{t=0} \\
                 & = \sum_{i=1}^{n} \evalat[\bigg]{\dv{c^i}{t}}{t=0} \evalat[\bigg]{\pdv{f}{x^i}}{p} \\
                 & = \sum_{i=1}^{n} v^i \evalat[\bigg]{\pdv{f}{x^i}}{p}\label{eqn:chainrule}         \\
\end{align}
%
The directional derivative operator at \(p\) is defined
%
\begin{equation}
    D_{\bm{v}} = \sum_{i=1}^{n} v^i \evalat[\bigg]{\pdv{}{x^i}}{p}
\end{equation}
%
The association \(\bm{v} \mapsto D_{\bm{v}}\) offers a way to \newterm{isomorphically} identify tangent vectors with operators on functions.
%
The following makes this rigorous.

\subsection{Derivations}

For each tangent vector \(\bm{v}\) at a point \(p \in \mathbb{R}^n\), the directional derivative at \(p\) gives a map of vector spaces
%
\begin{equation*}
    D_{\bm{v}} \colon C_p^\infty \rightarrow \mathbb{R}
\end{equation*}
%
\(D_{\bm{v}}\) is a linear map that satisfies the \newterm{Leibniz rule}
%
\begin{equation}
    D_{\bm{v}}(fg) = (D_{\bm{v}}f)g(p) + f(p) (D_{\bm{v}}g)
\end{equation}
%
because the partial derivative satisfy the product rule.
%
In general, any linear map \(L\colon C_p^\infty \rightarrow \mathbb{R}\) that satisfies the Leibniz rule is called a \newterm{derivation} at \(p\).
% or a \textit{point derivation} of \(C_p^\infty\). 
%
Denote the set of all derivations at \(p\) by \(\mathcal{D}_p(\mathbb{R}^n)\).
%
\textbf{This set is also a real vector space}.
%

So far we know directional derivatives \(D_{\bm{v}}\) at \(p\) are derivations at \(p\).
%
Thus, there is a map
\begin{align*}
    \phi\colon T_p(\mathbb{R}^n) & \rightarrow \mathcal{D}_p (\mathbb{R}^n) \\
    \bm{v}                       & \mapsto D_{\bm{v}}
\end{align*}
%
\begin{theorem}{}{}
    The linear map \(\phi\) is an isomorphism of vector spaces.
\end{theorem}
%
\noindent The implication is that we may identify tangent vectors at \(p\) with derivations at \(p\) (by way of directional derivatives against germs).
%
Under this isomorphism \(T_p(\mathbb{R}^n) \simeq \mathcal{D}_p(\mathbb{R}^n)\), the standard basis \(\left\{ e_1, \dots, e_n \right\}\) for \(T_p(\mathbb{R}^n)\) maps to
%
\begin{equation}
    \left\{\evalat[\bigg]{\pdv{}{x^1}}{p}, \dots, \evalat[\bigg]{\pdv{}{x^n}}{p}  \right\}\label{eqn:tangentbasis}
\end{equation}
%
Therefore from now on we write a tangent vector as
%
\begin{equation}
    \bm{v} = \sum_{i=1}^{n} v^i \evalat[\bigg]{\pdv{}{x^i}}{p}
\end{equation}
%
The point being that, while not as geometrically intuitive as arrows, \(\mathcal{D}_p (\mathbb{R}^n)\) generalizes to manifolds.

\subsection{Vector Fields}

A \newterm{vector field} \(X\) on an open \(U \subset \mathbb{R}^n\) is function that assigns to \(p \in U\) a tangent vector \(X_p \in T_p(\mathbb{R}^n)\).
%
Notice, carefully, that the vector field assigns at each point a vector in the tangent space anchored at that point.
%
Using the tangent basis (eqn.~\eqref{eqn:tangentbasis})
%
\begin{equation}
    X\colon p \mapsto \sum_i a^i(p) \evalat[\bigg]{\pdv{}{x^i}}{p}
\end{equation}
%
Note that both the coefficients \textbf{and} the partial derivatives are evaluated at \(p\).
%
Having said that, we often omit \(p\) in the specification of a vector field when it clear from context.
%
\begin{example}{}{}
    On \(\mathbb{R}^n - \{\bm{0}\}\), let \(p = (x,y)\). Then
    \begin{align*}
        X & = \frac{-y}{\sqrt{x^2+y^2}} \pdv{}{x} + \frac{x}{\sqrt{x^2+y^2}} \pdv{}{y} \\
          & = \begin{bmatrix}
            \frac{-y}{\sqrt{x^2+y^2}} \\ \frac{x}{\sqrt{x^2+y^2}}
        \end{bmatrix}                                               \\
          & = \begin{bmatrix}
            \frac{-y}{\sqrt{x^2+y^2}} & \frac{x}{\sqrt{x^2+y^2}}
        \end{bmatrix}^T
    \end{align*}
\end{example}
%
See figure~\ref{fig:vectorfields}
% \loadfig{vecfields}

In general we can identify vector fields with parameterized column vectors
%
\begin{equation}
    X = \sum_i a^i(p) \evalat[\bigg]{\pdv{}{x^i}}{p}
    \leftrightarrow
    \begin{bmatrix}
        a^1(p) \\ \vdots \\ a^n(p)
    \end{bmatrix}
\end{equation}

\subsection{Dual Space}

\newcommand{\pdx}[1]{\partial_{x_{#1}}}
\newcommand*{\vwedge}{V^\wedge }
\newcommand*{\vx}{X = \sum a^i \partial_{x_i}}

The \newterm{dual space} \(\vwedge\) of \(V\) is the set of all real-valued linear functions on \(V\) i.e. all \(f \colon V \rightarrow \R\).
%
Elements of \(\vwedge\) are called \newterm{covectors}.

Assume \(V\) is finite dimensional and let \(\{e_1, \dots, e_n\}\) be a basis \(V\).
%
Recall that \(e_i \coloneqq \partial_{x_i}\).
%
Then \(\vx\) for all \(X \in T_p\).
%
Let \(\alpha^i \colon V \rightarrow \mathbb{R}\) be the linear function that picks out the \(i\)th coordinate of a \textbf{vector}, i.e. \(\alpha^i(X) = a^i(p)\).
%
Note that
%
\begin{align}
    \alpha^i(\partial_j) & = \alpha^i(1\cdot \partial_j) \\
                         & = \begin{cases}
        1 \text{ if } i = j \\
        0 \text{ if } i \neq j
    \end{cases}  \\
                         & =\delta_j^i
\end{align}
%
Note that position of indices is important -- upper indices are for covectors.
%
\begin{proposition}{}{}
    \(\{\alpha^i\}\) form a basis for \(\vwedge\).
\end{proposition}
%
\begin{proof}
    %
    We first prove that \(\{\alpha^i\}\) span \(\vwedge\). If \(f \in V^\wedge\) and \(\vx \in V\), then
    %
    \begin{align}
        f(X) & = \sum a^i f(\pdx{i})          \\
             & = \sum \alpha^i(X) f(\pdx{i})  \\
             & = \sum f(\pdx{i}) \alpha^i (X)
    \end{align}
    %
    which shows that any \(f\) can be expanded as a linear sum of \(\alpha^i\).
    %
    To show linear independence, suppose \(\sum c_i \alpha^i = 0\) with at least one \(c_i\) non-zero. Applying this to an arbitrary \(\pdx{i}\) gives
    %
    \begin{equation}
        0 = \left(\sum_i c_i \alpha^i   \right)(\pdx{i}) = \sum_i c_i \alpha^i(\pdx{i}) = \sum_i c_i \delta_j^i = c_j
    \end{equation}
    %
    which is a contradiction. Hence \(\alpha^i\) are linearly independent.
    %
\end{proof}
%
This basis \(\{\alpha^i\}\) for \(\vwedge\) is said to be \textit{dual} to the basis \(\{\pdx{i}\}\) for \(V\).
%
\begin{example}{Coordinate functions}{}
    %
    With respect to a basis \(\{\pdx{i}\}\) for \(V\), every \(X \in V\) can be written uniquely as a linear combination \(\vx\) with \(a^i \in \R\). Let \(\{\alpha^i\}\) be the dual basis (i.e. the basis for \(\vwedge\)).
    %
    Then
    %
    \begin{align*}
        \alpha^i(X) & = \alpha^i \left( \sum_j a^j \pdx{j} \right) \\
                    & = \sum_j a^j \alpha^i(\pdx{j})               \\
                    & = \sum_j a^j \delta_j^i                      \\
                    & = a^i
    \end{align*}
    %
    Thus, the dual basis \(\{\alpha^i\}\) to \(\{\pdx{i}\}\) is the set of coordinate functions.
    %
    The sense here is that since tangent vectors are directional derivatives (i.e.\ operators on functions) and the dual space is a mapping from those operators to \(\R\), then a mapping from operators to scalars means hitting an operator with a function (or vice-versa). \textbf{And} the coordinate functions are constant with respect to each other coordinate (and hence partials wrt them are naturally zero).
\end{example}

\subsection{Differential Forms on \(\R^n\)}

A differential \(k\)-form assigns a \(k\)-covector from the dual space at each point \(p\).
%
The wedge product (alternation of tensor product) of differential forms is defined pointwise (as the wedge product of multi-covectors).
%
Differential forms exist on an open set (why?) there is a notion of differentiation (called exterior derivative).
%
Exterior derivative is coordinate independent and intrinsic to a manifold; it is the abstraction of gradient, curl, divergence to arbitrary manifolds.
%
Differential forms extend Grassmann's exterior algebra (graded algebra of multi-covectors) from the tangent space at a point globally, i.e. to the entire manifold (how? bundles?).

\subsubsection{Differential of a Function}

\newcommand{\cotsp}[1]{T_p^*(\R^{#1})}
\newcommand{\tsp}[1]{T_p(\R^{#1})}
\newcommand{\w}{\omega}

\begin{definition}{Cotangent Space}{}
    The \newterm{cotangent space} to \(\R^n\) at \(p\), denoted \(\cotsp{n}\), is defined to be the dual space \((\tsp{n})^\vee\) of the tangent space \(\tsp{n}\).
\end{definition}
%
Thus, an element of the cotangent space \(\cotsp{n}\) is a \textbf{covector of linear functional on tangent space}.
%
\begin{definition}{Differential 1-form}{}
    A \newterm{covector field} or a \newterm{differential 1-form} on an open subset \(U\) of \(\R^n\) is a function \(\w\) that assigns at each point \(p\) in \(U\) a covector \(\w_p \in \cotsp{n}\)
    %
    \begin{splitenv}
        \w \colon U &\rightarrow \bigcup_{p \in U} \cotsp{n} \\
        p &\mapsto \w_p \in \cotsp{n}
    \end{splitenv}
    We call a differential 1-form a \newterm{1-form} for short.
\end{definition}
%
\begin{definition}{Differential}{}
    From any \(C^\infty\) function \(f\colon U \rightarrow \R\), we can construct the 1-form \(\dif f\), called the \newterm{differential} of \(f\), as follows: for \(p \in U\) and \(X_p \in T_p(U)\)
    \begin{equation}
        (\dif f)_p (X_p) \coloneqq X_p f
    \end{equation}
    In words the differential of \(f\) is the application of \(X_p\) to \(f\) or \textbf{the directional derivative of \(f\) in the direction of the tangent vector defined by the coefficients of \(X_p\)}.
\end{definition}

Let \(x^1, \dots, x^n\) be the standard coordinates on \(\R\), \(\{(\dif x^1)_p, \dots, (\dif x^n)_p\}\) their differentials defined
\[
    (\dif x^i)_p (X_p) \coloneqq (X_p)(x^i)
\]
%
and
%
\[
    \left\{\evalat[\bigg]{\pdv{}{x^1}}{p}, \dots,  \evalat[\bigg]{\pdv{}{x^n}}{p}  \right\}
\]
%
be the standard basis for \(\tsp{n}\).
%
\begin{proposition}{}{dfbasis}
    \(\{(\dif x^1)_p, \dots, (\dif x^n)_p\}\) is the basis for \(\cotsp{n}\) dual to the coordinate basis for \(\tsp{n}\).
\end{proposition}
%
\begin{proof}
    By definition,
    \[
        (\dif x^i)_p \left( \evalat[\bigg]{\pdv{}{x^j}}{p} \right) = \evalat[\bigg]{\pdv{x^i}{x^j}}{p} = \delta_j^i
    \]
\end{proof}

If \(\w\) is a 1-form on \(U \in \R^n\) then by proposition~\eqref{prop:dfbasis}, at each point \(p \in U\)
%
\[
    \w_p = \sum a_i(p)(dx^i)_p
\]
%
Note the lower index on \(a_i(p)\) as opposed to the upper index on \(X_p = \sum a^i(p)\evalat[\big]{\partial_{x_i}}{p}\).
%
If \(x \coloneqq x^1,y\coloneqq x^2,z \coloneqq x^3\), then \(\dif x, \dif y, \dif z\).
%
\begin{proposition}{\(\dif f\) in terms of coordinates}{}
    If \(f\colon U \rightarrow \R\), then
    \begin{equation}
        \dif f = \sum \pdv{f}{x^i}\dif x^i
    \end{equation}
\end{proposition}
%
\begin{proof}
    \[(\dif f)_p = \sum a_i(p) (\dif x^i)_p\]
    %
    for some real numbers \(a_i(p)\) depending on \(p\). Thus
    %
    \begin{splitenv}
        \dif f \left(\pdv{}{x^j} \right) &= \sum_i a_i \dif x^i \left(\pdv{}{x^j} \right) \\
        &= \sum_i a_i \delta_j^i = a_j
    \end{splitenv}
    %
    On the other hand, by the definition of the differential
    %
    \begin{equation}
        \dif f =  \left(\pdv{}{x^j} \right) = \pdv{f}{x^j}
    \end{equation}
    %
    Therefore
    \begin{equation}
        a_j = \pdv{f}{x^j}
    \end{equation}
    and hence
    \[(\dif f)_p = \evalat[\bigg]{\pdv{f}{x^i}}{p} (\dif x^i)_p\]
\end{proof}

\subsubsection{Differential \(k\)-forms}

\newcommand{\twoform}[2]{\dif #1 \wedge \dif #2}
\newcommand{\threeform}[3]{\dif #1 \wedge \dif #2 \wedge \dif #3}
\newcommand{\cinf}{C^\infty}

\begin{definition}{Differential \(k\)-forms}{}
    More generally, a \newterm{differential form \(\w\) of degree \(k\)} is a function that at each point assigns an alternating \(k\)-linear function on \(\tsp{n}\), i.e. \(\w_p \in A^k(\tsp{n})\).
\end{definition}
%
A basis for \(A^k(\tsp{n})\) is
\begin{equation}
    (\dif x^I)_p \coloneqq (\dif x^{i_1})_p \wedge \cdots \wedge (\dif x^{i_k})_p
\end{equation}
%
where \(1 \leq i_1 < \cdots < i_k \leq n \).
%

\textbf{What is the nuance here?}

Therefore, at each point \(p \in U\), \(\w_p\) is a linear combination
%
\begin{splitenv}
    \w_p = \sum_I a_I(p) (\dif x^I)_p \\ 1 \leq i_1 < \cdots < i_k \leq n
\end{splitenv}
%
and a \(k\)-form \(\w\) on open \(U\) is a linear combination
%
\begin{equation}
    \w = \sum_I a_I \dif x^I
\end{equation}
%
with function coefficients \(a_I \colon U \rightarrow \R\).
%
We say that a \(k\)-form \(\w\) is \(C^\infty\) on \(U\) if all of the coefficients \(a_I\) are \(C^\infty\) functions on \(U\).
%
Denote \(\Omega^k(U)\) the vector space of \(k\)-forms on \(U\).
%
A 0-form on \(U\) assigns to each point \(p\) an element of \(A^0(\tsp{n}) \coloneqq \R\); thus, a 0-form on \(U\) is a constant function.
%
Note there are no nonzero differential forms of degree \(>n\) on \(U\) since if \(\deg \dif x^I > n\) then at least two of the component 1-forms of \(dx^I\) must be the same and therefore \(dx^I = 0\).

\begin{definition}{Wedge product of forms}{}
    The \newterm{wedge product of a \(k\)-form \(\w\) and \(\ell\)-form \(\tau\)} is defined pointwise
    %
    \begin{splitenv}
        (\w \wedge \tau)_p &\coloneqq \w_p \wedge \tau_p \\
        \w \wedge \tau &= \sum_{I,J}(a_I b_J) \dif x^I \wedge \dif x^J
    \end{splitenv}
    %
    where \(I \cap J = \emptyset\).
    %
\end{definition}
%
Hence the wedge product is bilinear
%
\begin{equation}
    \wedge \colon \Omega^k (U) \times \Omega^\ell \rightarrow \Omega^{k+\ell} (U)
\end{equation}
%
The wedge product of forms is also anticommutative and associate (owing to the associativity and anticommutativity of the wedge product on multi-covectors) as therefore induces a graded algebra on \(\Omega(U) \coloneqq \bigoplus_k \Omega^k(U)\).

\begin{example}{}{}
    In the case of
    %
    \[
        \wedge \colon \Omega^0(U) \times \Omega^\ell(U) \rightarrow \Omega^\ell
    \]
    %
    we have the pointwise multiplication of a \(C^\infty\) function and a \(C^\infty\) \(\ell\)-form
    %
    \[
        (f \wedge \w)_p = f(p) \wedge \w_p = f(p)\w_p
    \]
    %
    Let \(x,y,z\) be the coordinates on \(\R^3\). Then, the 1-forms are
    %
    \[
        f \dif x + g \dif y + h \dif z
    \]
    %
    the 2-forms are
    %
    \[
        f \dif y \wedge \dif z + g \dif x \wedge \dif z + h \dif x \wedge \dif y
    \]
    %
    and the 3-forms are
    %
    \[
        f \dif x \wedge \dif y \wedge \dif z
    \]
\end{example}

\subsubsection{Differential Forms as Multilinear Functions on Vector Fields}

If \(\w\) is a 1-form and \(X\) is a vector field then
%
\begin{splitenv}
    \evalat[]{\w(X)}{p} &\coloneqq \w_p (X_p) \\
    \w &\,= \sum a_i \dif x^i \quad X = \sum b^i \pdv{}{x^j} \\
    \w(X) &\,= \left( \sum a_i \dif x^i \right) \left( \sum b^j \pdv{}{x^j}\right) \\
    &\,= \sum a_i b^i
\end{splitenv}

\subsubsection{Exterior Derivative}

\begin{definition}{Exterior Derivative}{}
    The exterior derivative of a function \(f \in C^\infty(U)\) is defined to be its differential \(\dif f\)
    %
    \[
        \dif f = \sum \pdv{f}{x^i} \dif x^i
    \]
    %
    For \(k \geq 1\), if \(\w = \sum_I a_I \dif x^I\) is a \(k\)-form, then
    %
    \begin{splitenv}
        \dif \w &\coloneqq \sum_I \dif a_I \wedge \dif x^I \\
        &\,= \sum_I \left( \sum_j \pdv{a_I}{x^j} \dif x^j \right) \wedge \dif x^I
    \end{splitenv}
\end{definition}
%
\begin{example}
    Let \(\w\) be the 1-form \(f \dif x + g \dif y\) on \(R^2\). Then
    \begin{align}
        \dif \omega & = \dif f \wedge \dif x + \dif g \wedge \dif y                                              \\
                    & \,= \begin{multlined}[t]
            \left( \pdv{f}{x}\dif x + \pdv{f}{y}\dif y \right) \wedge \dif x \\
            + \left( \pdv{g}{x}\dif x + \pdv{g}{y}\dif y \right) \wedge \dif y
        \end{multlined}                                                             \\
                    & \,= \left(\pdv{g}{x} - \pdv{f}{y} \right)\dif x \wedge \dif y \label{exa:exteriordif1form}
    \end{align}
    where we use that \(\dif x \wedge \dif y = - \dif y \wedge \dif x\) and \(\dif x \wedge \dif x = 0\).
\end{example}

\begin{definition}{Antiderivation}
    %
    Let \(A = \bigoplus_k A^k\) be a graded algebra over a field \(K\). An \newterm{antiderivation of the graded algebra} A is a \(k\)-linear map \(D \colon A \rightarrow A\) such that for \(a \in A^k, b \in A^\ell\)
    %
    \begin{equation}
        D(ab) = (Da)b + (-1)^kaDb
    \end{equation}
    %
    If there is an integer \(m\) such that \(D\) sends \(A^k\) to \(A^{k+m}\) for all \(k\), then the antiderivation is of \textit{degree m}.
\end{definition}
%
\begin{proposition}{Properties of exterior differentiation}{exterioranti}
    \begin{enumerate}
        \item exterior differentiation is an antiderivation of degree 1:
              \[\dif\, (\w \wedge \tau) = (\dif \w) \wedge \tau + (-1)^{\deg \omega} \omega \wedge \dif \tau\]
        \item \(\dif^2 = 0\)
    \end{enumerate}
\end{proposition}
%
\begin{proposition}{Characterization of the exterior derivative}{}
    The properties of proposition~\eqref{prop:exterioranti} completely characterize exterior differentiation.
\end{proposition}

\subsubsection{Closed and Exact Forms}

A \(k\)-form \(\w\) is a \newterm{closed form} if \(\dif \w = 0\).
%
\(\w\) is an \newterm{exact form} if there is a \(k-1\)-form \(\tau\) such that \(\w = \dif \tau\).
%
Since \(\dif (\dif \tau) = 0\), every exact form is closed.

\begin{example}{A closed 1-form on the punctured plane}{}
    Define \(\w\) on the manifold \(\R^2-\{\bm{0}\}\) by
    \[
        \omega(x,y) = \frac{-y}{x^2+y^2}\dif x + \frac{x}{x^2+y^2}\dif y
    \]
    To show that \(\w\) is closed we take the exterior derivative using example~\eqref{exa:exteriordif1form}:
    \begin{splitenv}
        \dif \w &= \left( \frac{y^2-x^2}{\left(x^2+y^2\right)^2} - \frac{y^2-x^2}{\left(x^2+y^2\right)^2} \right) \dif x \wedge \dif y \\
        &= 0
    \end{splitenv}
\end{example}

\begin{definition}{Differential Complex}{}
    A collection of vector spaces \(\{V^0, V^1, \dots\}\) with linear maps \(d_k \colon V^k \rightarrow V^{k+1}\) such that \(d_{k+1} \circ d_k = 0\) is called a \newterm{differential complex} or a \newterm{cochain complex}. For any open subset \(U \subset \R^3\), the exterior derivative makes the vector space \(\Omega^*(U)\) of \(C^\infty\) forms on \(U\) into a cochain complex, called the \newterm{de Rham complex of \(U\)}:
    \[
        0 \rightarrow \Omega^0(U) \xrightarrow{\text{ d }} \Omega^1(U) \xrightarrow{\text{ d }} \Omega^2(U) \xrightarrow{\text{ d }} \cdots
    \]
    The closed forms are the elements of the kernel of d and the exact forms are the elements of the image of d.
\end{definition}

\subsubsection{Applications to Vector Calculus}

Recall the three operators grad, curl, div (\(\grad, \curl, \div\)) on scalar fields and vector fields (i.e. scalar valued functions and vector valued functions) over \(\R^3\):
\begin{gather}
    \begin{split}
        \grad{f} &=
        \begin{bmatrix}
            \pdv{f}{x} \\
            \pdv{f}{y} \\
            \pdv{f}{z} \\
        \end{bmatrix} \\
        \curl{\begin{bmatrix}
                P \\ Q \\ R
            \end{bmatrix}} &=
        \begin{bmatrix}
            \pdv{}{x} \\
            \pdv{}{y} \\
            \pdv{}{z} \\
        \end{bmatrix} \times
        \begin{bmatrix}
            P \\ Q \\ R
        \end{bmatrix}
        =
        \begin{bmatrix}
            \pdv{R}{y} - \pdv{Q}{z}                 \\
            -\left( \pdv{R}{x} - \pdv{P}{z} \right) \\
            \pdv{Q}{x} - \pdv{P}{y}                 \\
        \end{bmatrix} \\
        \div{\begin{bmatrix}
                P \\ Q \\ R
            \end{bmatrix}} &=
        \begin{bmatrix}
            \pdv{}{x} \\
            \pdv{}{y} \\
            \pdv{}{z} \\
        \end{bmatrix} \cdot
        \begin{bmatrix}
            P \\ Q \\ R
        \end{bmatrix}
        =
        \pdv{P}{x} + \pdv{Q}{y} + \pdv{R}{z}
    \end{split}
\end{gather}
%
Note we can identity 1-forms with vector fields:
\[
    P \dif x + Q \dif y + R \dif z \longleftrightarrow \begin{bmatrix}
        P \\ Q \\ R
    \end{bmatrix}
\]
%
Similarly 2-forms on \(\R^3\)
\[
    P \twoform{x}{y}  + Q \twoform{z}{x} + R \twoform{x}{y} \longleftrightarrow \begin{bmatrix}
        P \\ Q \\ R
    \end{bmatrix}
\]
%
and 3-forms on \(U\) can be identified with functions \(U\)
%
\[
    f \threeform{x}{y}{z} \longleftrightarrow f
\]
%
In terms of these identifications the exterior derivative of 0-form \(f\) is the 1-form \(\dif f\) or \(\grad{f}\):
\[
    \dif f = \pdv{f}{x} \dif x + \pdv{f}{y} \dif y  + \pdv{f}{z} \dif z \longleftrightarrow
    \begin{bmatrix}
        \pdv{f}{x} \\
        \pdv{f}{y} \\
        \pdv{f}{z} \\
    \end{bmatrix} = \grad{f}
\]
%
the exterior derivative of a vector field \(\irow{P\; Q\; R}^T\) (i.e. 1-form) is the 2-form \(\curl{\irow{P\; Q\; R}^T}\)
%
\begin{splitenv}
    \dif \left( P\dif x + Q \dif y + R \dif z \right) = \\
    + \left( \pdv{R}{y} - \pdv{Q}{z} \right) \twoform{y}{z} \\
    - \left( \pdv{R}{x} - \pdv{P}{z} \right) \twoform{z}{x} \\
    + \left( \pdv{Q}{x} - \pdv{P}{y} \right) \twoform{x}{y}  \\ \longleftrightarrow \\ \curl{\begin{bmatrix}
            P \\ Q \\ R
        \end{bmatrix}}
\end{splitenv}
%
and the exterior derivative of a 2-form is
%
\begin{splitenv}
    \dif \left( P \twoform{x}{y}  + Q \twoform{z}{x} + R \twoform{x}{y} \right) = \\
    \left( \pdv{P}{x} \dif x + \pdv{Q}{y} \dif y  + \pdv{R}{z} \dif z \right) \threeform{x}{y}{z} \\
    \longleftrightarrow \div{\begin{bmatrix}
            P \\ Q \\ R
        \end{bmatrix}}
\end{splitenv}
%
Thus, the exterior derivatives on 0-forms (functions) is the grad operator, on 1-forms is the curl operator, and on 2-forms is the divergence operator.
%
\[
    \begin{tikzcd}
        \Omega^0(U) \arrow{r}{\dif} \arrow[swap]{d}{\cong} & \Omega^1(U) \arrow{r}{\dif} \arrow[swap]{d}{\cong} & \Omega^2(U) \arrow{r}{\dif} \arrow[swap]{d}{\cong} & \Omega^3(U) \arrow[swap]{d}{\cong}  \\
        C^\infty(U) \arrow[swap]{r}{\grad} & \mathfrak{X}(U) \arrow[swap]{r}{\curl} & \mathfrak{X}(U) \arrow[swap]{r}{\div} & C^\infty(U)
    \end{tikzcd}
\]
%
where \(\mathfrak{X}(U)\) is the \newterm{Lie algebra} of \(C^\infty\) vector fields on \(U\).
%
\begin{proposition}{grad, curl, div properties}{}
    \begin{enumerate}
        \item\label{prop1} \( \curl{\grad{f}} = 0 \)
        \item\label{prop2} \(\div(\curl{\irow{P \; Q \; R}^T}) = 0\)
        \item\label{prop3} On \(\R^3\), a vector field \textbf{F} is the gradient of some scalar function iff \(\curl{\textbf{F}}=0\)
    \end{enumerate}
\end{proposition}
%
Properties~(\ref{prop1},\ref{prop2}) express that \(\operatorname{d}^2 = 0\)
%
Property~\eqref{prop3} expresses the fact that a 1-form on \(\R^3\) is exact iff it is closed; it need not be true on a region other than \(\R^3\).
%
It turns out that whether proposition~\eqref{prop3} is true depends on the topology of \(U\).
%
One measure of the failure of a closed \(k\)-form to be exact is the quotient vector space
%
\begin{equation}
    H^k(U) \coloneqq \frac{\{\text{closed \(k\)-forms on } U\}}{\{\text{exact \(k\)-forms on }U\}}
\end{equation}
%
called the \(k\)th \newterm{de Rham cohomolgy} of U.
%
The generalization of proposition~\eqref{prop3} to any differential on \(\R^n\) is called the \newterm{Poincare lemma}: for \(k \geq 1\), every closed \(k\)-form on \(\R^n\) is exact.
%
This is equivalent to the vanishing of the \(k\)th de Rham cohomology \(H^k(\R^n)\) for \(k \geq 1\).

\subsubsection{Convention on Subscripts and Superscripts}

Vector fields \(e_1, e_2, \dots\)have subscripts and differential forms \(\w^1, \w^2, \dots\) have superscripts.
%
Coordinate functions \(x^1, x^2, \dots\), being 0-forms, have superscripts.
%
Their differentials \(\dif x^i\) should also.
%
Coordinate vector fields \(\pdv{}{x^i}\) are considered to have subscripts because the index is in the denominator.
%
Coefficient functions have subscripts or subscripts depending on whether they're coefficients functions for vector fields or forms.
%
This allows for ``conservation of indices'': if \(X = \sum a^i \partial_{x^i}\) and \(\w = \sum b_j \dif x^j\) then
\[
    \w(X) = \left( \sum b_j \dif x^j \right) \left( \sum a^i \pdv{}{x^i} \right) = \sum b_i a^i
\]

\subsection{Manifolds}

\begin{definition}{Locally Euclidean}{}
    A topological space \(M\) is \newterm{locally Euclidean of dimension \(n\)} if for every \(p \in M\) there exists a neighborhood \(U\) such that there is a \newterm{homeomorphism}\tablefootnote{A homeomorphism is a continuous function between topological spaces that has a continuous inverse function.} \(\phi\) from \(U\) \textbf{onto} an opensubset of \(\R^n\).
    %
    The pair \(\left( U,\phi \colon U \rightarrow \R^n \right)\) is called a \newterm{chart}, with \(U\) being the \newterm{coordinate neighborhood} and \(\phi\) the \newterm{coordinate system}.
\end{definition}

\begin{definition}{Topological Manifold}{}
    A \newterm{topological manifold} is a \newterm{Hausdorff}\tablefootnote{A Hausdorff space, separated space space is a topological space where for any two distinct points there exists a neighbourhood of each which is disjoint from the neighbourhood of the other. }, \newterm{second countable}\tablefootnote{A topological space \(T\) is second-countable if there exists some countable collection ${\displaystyle {\mathcal {U}}=\{U_{i}\}_{i=1}^{\infty }}$ of open subsets of $T$ such that any open subset of $T$ can be written as a union of elements of some subfamily of ${\mathcal {U}}$.}, locally Euclidean space.
\end{definition}

\subsubsection{Compatible Charts}

Suppose \(\left( U,\phi \colon U \rightarrow \R^n \right)\) and \(\left( V,\psi \colon V \rightarrow \R^n \right)\) are two charts of a topological manifold; since \(U \cap V\) is open and \(\phi\) is a homeomorphism onto an open subset, the image \(\phi(U \cap V)\) is also an open subset (similarly \(\psi(U \cap V)\)).

\begin{definition}{Charts}{}
    Two charts \(\left( U,\phi \colon U \rightarrow \R^n \right)\) and \(\left( V,\psi \colon V \rightarrow \R^n \right)\) of a topological manifold are \newterm{\(C^\infty\)-compatible} if the two composed maps
    %
    \begin{splitenv}
        \phi \circ \psi^{-1}\colon \psi(U \cap V) \rightarrow \phi(U \cap V) \\
        \psi \circ \phi^{-1}\colon \phi(U \cap V) \rightarrow \psi(U \cap V)
    \end{splitenv}
    %
    See figure~\ref{fig:compatcoordcharts}.
    %
    These two maps \(\phi \circ \psi^{-1}\) and \(\psi \circ \phi^{-1}\) are called the \newterm{transition functions} between the charts;
    \begin{splitenv}
        \phi \circ \psi^{-1}\colon \R^n \rightarrow U \cap V \rightarrow \R^n \\
        \psi \circ \phi^{-1}\colon \R^n \rightarrow U \cap V \rightarrow \R^n
    \end{splitenv}
\end{definition}
% \loadfig{coordinatechart}
\begin{definition}{Atlas}{}
    A \(C^\infty\) \newterm{atlas} on a topological manifold \(M\) is a collection \(\mathfrak{U} \coloneqq \{(U_i, \phi_i)\}\) of pairwise \(C^\infty\)-compatible charts that \textit{cover} \(M\), i.e. such that \(M = \bigcup_i U_i\).
\end{definition}
\begin{example}{A \(C^\infty\) atlas on a circle}{}
    The unit circle \(S^1\) in the complex plane \(\mathbb{C}\) maybe described as
    \[
        \{e^\iu \in \C | 0 \leq t \leq 2\pi\}
    \]
    Let \(U_1, U_2\) be
    \begin{splitenv}
        U_1 &\coloneqq \{e^{\iu t} \in \C | -\pi < t < \pi\}    \\
        U_2 &\coloneqq \{e^{\iu t} \in \C | 0 < t < 2\pi\}
    \end{splitenv}
    and define
    \begin{splitenv}
        \phi_1(e^{\iu t}) &= t \quad -\pi < t < \pi \\
        \phi_2(e^{\iu t}) &= t \quad 0 < t < 2\pi \\
    \end{splitenv}
    See figure~\ref{fig:chartsoncircle}.
    %
    Both \(\phi_1, \phi_2\) are homemorphisms onto their respective images; thus, \(U_1, \phi_1\) and \(U_2, \phi_2\) are charts on \(S^1\).
    %
    The intersection \(U_1 \cap U_2\) consists of two disjoint connected components
    \begin{splitenv}
        A &\coloneqq \{e^{\iu t} \in \C | -\pi < t < 0\}    \\
        B &\coloneqq \{e^{\iu t} \in \C | 0 < t < \pi\}
    \end{splitenv}
    with
    \begin{splitenv}
        \phi_1(U_1 \cap U_2) &= \phi_1 (A \sqcup B) = \phi_1(A) \sqcup \phi_2(B) = (-\pi,0) \sqcup (0, \pi) \\
        \phi_2(U_1 \cap U_2) &= \phi_1 (B \sqcup A) = \phi_1(B) \sqcup \phi_2(A) = (0, \pi)\sqcup(\pi, 2\pi)\\
    \end{splitenv}
    where \(\sqcup\) means disjoint union.
    %
    The transition function
    \[
        \left( \phi_2 \circ \phi_1^{-1} \right)(t) = \begin{cases}
            t+2\pi & \text{ for } t\in (-\pi, 0) \\
            t      & \text{ for } t\in (0, \pi)
        \end{cases}
    \]
    and similarly
    \[
        \left( \phi_1 \circ \phi_2^{-1} \right)(t) = \begin{cases}
            t      & \text{ for } t\in (0, \pi)    \\
            t-2\pi & \text{ for } t\in (\pi, 2\pi)
        \end{cases}
    \]
    Therefore, since the transition functions are \(C^\infty\), the charts are \(C^\infty\) compatible and form an atlas on \(S^1\).
\end{example}
% \loadfig{circlatlas}

Although compatibility is reflexive and symmetric it is not transitive because we don't know anything about mutual intersections.
%
On the otherhand
%
\begin{lemma}{}{}
    Let \(\{(U_i, \phi_i)\}\) be an atlas for a topological manifold. If two other charts (not in the atlas) \((V, \psi), (U, \phi)\) are both compatible with the atlas (i.e. with all charts in the atlas), then they are mutually compatible.
\end{lemma}

\subsubsection{Smooth Manifolds}

An atlas \(\mathfrak{M}\) on a topological manifold is said to be \newterm{maximal} if it is not strictly contained in another atlas.
\begin{definition}{Smooth Manifold}{}
    A \newterm{smooth \(C^\infty\) manifold} is a topological manifold \(M\) together with a maximal atlas.
    %
    The maximal atlas is called a \newterm{differentiable structure} on \(M\).
    %
    \(M\) is said to have dimension \(n\) if all of its connected components have dimension \(n\).
    %
    A 1-dimensional manifold is called a \newterm{curve}, a 2-dimensional manifold is called a \newterm{surface}, and an \(n\)-dimensional manifold is called an \(n\)-manifold.
\end{definition}

In the context of manifolds, we denote the standard coordinates on \(\R^n\) by \(r^1, \dots, r^n\).
%
If \((U, \phi)\) is a chart of a manifold, we let \(x^i = r^i \circ \phi\) be the \(i\)th component of \(\phi\) and write \(\phi = (x^1, \dots, x^n)\).
%
Thus, \(x^i(p) \coloneqq (r^i \circ \phi)(p)\) is a point in \(\R^n\).
%
The functions \(x^i\) are called the \newterm{local coordinates on U}.
%
The sense here is that \(x^i\) tell you where you are on the manifold in a standardized way, given some intrinsic description of where you are on the manifold.
Think of how lat/lon tell you where you are on the globe given some intrinsic identification of where you are on the globe.
This understanding gives sense to the words chart and atlas.
%
Abusing notation, sometimes \((x^1, \dots, x^n)\) (sans \(p\)) stands for both the coordinates on \(U\) or for a point in \(\R^n\).

\subsubsection{Examples of Smooth Manifolds}

\begin{example}{Graph of a Smooth Function}{}
    For a subset \(A \subset \R^n\) and a function \(f \colon A \rightarrow \R^m\) the \newterm{graph of f} is defined
    \[
        \Gamma(f) = \{(x, f(x)) \in A \times \R^m\}
    \]
    If \(U\) is an open subset \(\R^n\) and \(f \colon U \rightarrow \R^n\) is \(C^\infty\), then the two maps
    \begin{align*}
        \phi \colon \Gamma(f) \rightarrow U \quad (x, f(x)) \mapsto x \\
        (1, f) \colon \rightarrow \Gamma(f) \quad x \mapsto (x, f(x))
    \end{align*}
    constitute a homemorphism. Hence, \(\Gamma(f)\) has an atlas with a single \((\Gamma(f), \phi)\) and is therefore a \(C^\infty\) manifold.
\end{example}

\begin{example}{General Linear group}{}
    Let \(\R^{m \times n}\) be the vector space of all \(m \times n\) matrices.
    Since \(\R^{m \times n}\) is isomorphic to \(\R^{mn}\), we give it the topology of \(\R^{mn}\).
    The \newterm{general linear group \(\gln\)} is defined
    \begin{splitenv}
        \gln &\coloneqq \{A \in \R^{n\times n} | \det(A) \neq 0\}  \\
        &\;= \operatorname{det}^{-1} (\R - \{0\})
    \end{splitenv}
    Since the determinant function \(\det \colon \R^{n\times n}\rightarrow \R\) is continuous, \(\gln\) is an open subset of \(\Rnn\cong \R^{n^2} \) is therefore a manifold.
\end{example}

\begin{example}{Unit circle in the \(xy\)-plane}
    Take \(S^1\) as the unit circle in the real plane \(\R^2\) defined by \(x^2+y^2=1\).
    We can cover \(S^1\) by four open sets: the upper and lower semicircles \(U_1, U_2\) and the left and right semicircles \(U_3, U_4\)
    (see figure~\ref{fig:xychartsoncircle}).
    On \(U_1, U_2\) the coordinate function \(x\) is a homeomorphism onto the open interval \((-1,1)\) on the \(x\)-axis.
    Thus, \(\phi_i(x,y) \coloneqq x\). Similarly, on \(U_3, U_4\), \(y\) is a homeomorphism onto the open interval \((-1,1)\) on the \(y\)-axis, and so \(\phi_i(x,y) \coloneqq y\).
    You can check that on \(U_i \cap U_j\), the transition function \(\phi_j \circ \phi_i^{-1}\) is \(C^\infty\).
    For example, on \(U_1 \cap U_3\)
    \[
        (\phi_3 \circ \phi_1^{-1})(x) = \phi_3 (x, \sqrt{1-x^2}) = \sqrt{1-x^2}
    \]
    while on \(U_2 \cap U_4\)
    \[
        (\phi_4 \circ \phi_2^{-1})(x) = \phi_4 (x, -\sqrt{1-x^2}) = -\sqrt{1-x^2}
    \]
    Thus, \(\{(U_i, \phi_i)\}_{i=1}^4\) is a \(C^\infty\) atlas on \(S^1\).
\end{example}
% \loadfig{chartsoncirc}

\begin{proposition}{An atlas for a product manifold}{}
    If \(\{(U_i, \phi_i)\}\) and \(\{(V_i, \psi_i)\}\) are \(C^\infty\) atlases for the manifolds \(M,N\) of dimensions, respectively, then the collection
    \begin{equation}
        \{ (U_i \times V_j, (\phi_i, \phi_j)) \colon U_i \times V_j \rightarrow \R^m \times \R^n \}
    \end{equation}
    is a \(C^\infty\) atlas on \(M \times N\). Therefore \(M \times N\) is a \(C^\infty\) manifold of dimension \(m+n\).
\end{proposition}

There \(n\)-dimensional torus \(S^1 \times \cdots \times S^1\) is a manifold.

\subsubsection{Smooths Maps on a Manifold}

\begin{definition}{Smooth at a point to \(\R\)}{}
    Let \(M\) be a smooth manifold of dimension \(n\). A function \(f\colon M \rightarrow \R\) is said to be \(C^\infty\) or \newterm{smooth a point p} in \(M\) if there is a chart \((U, \phi)\) containing \(p\) such that \(f \circ \phi^{-1}\), a function defined on the open subset \(\phi(U) \subset \R^n\), is \(C^\infty\) at \(\phi(p)\).
    To summarize \(f\) is \(C^\infty\) if
    \[
        f \circ \phi^{-1} \colon \phi(U) \rightarrow \R
    \]

    See figure~\ref{fig:smoothatapoint}.
\end{definition}
% \loadfig{smoothatapoint}
\begin{definition}{Pullback}{}
    Let \(F \colon N \rightarrow M\) be a map and \(h\) a function \(M\).
    The \newterm{pullback} of \(h\) by \(F\), denoted \(F^*h\), is the composite function \(h \circ F\).
\end{definition}

Thus, a function \(f\) on \(M\) is \(C^\infty\) on a chart \((U, \phi)\) iff \((\phi^{-1})^* f \equiv f \circ \phi^{-1}\) is \(C^\infty\) on \(\phi(U)\).

\begin{definition}{Smooth at a point}{}
    Let \(M,N\) be manifolds of dimension \(m,n\). A continuous map \(F\colon N \rightarrow M\) is \(C^\infty\) at a point \(p \in N\) if there are charts \((V, \psi), (U, \phi)\) about \(F(p) \in M\) and \(p \in N\) such that \(\psi \circ F \psi \phi^{-1}\) is \(C^\infty\) at \(\phi(p)\).
    To summarize \(F\) is \(C^\infty\) if
    \[
        \psi \circ F \circ \phi^{-1} \colon \phi(F^{-1}(V) \cap U) \subset \R^n \rightarrow \R^m
    \]
    See figure~\ref{fig:smoothf}.
\end{definition}

% \loadfig{smoothf}

\begin{proposition}{Composition of \(C^\infty\) maps}{}
    If \(F \colon N \rightarrow M\) and \(G \colon M \rightarrow P\) are both \(C^\infty\) maps of manifolds, then the composite \(G \circ F \colon N \rightarrow P\) is \(C^\infty\).
\end{proposition}

\begin{definition}{Diffeomorphism}{}
    A \newterm{diffeomorphism} of manifolds is a bjiective \(C^\infty\) map \(F \colon N \rightarrow M\) whose inverse \(F^{-1}\) is also \(C^\infty\).
\end{definition}

\begin{proposition}{}{}
    If \((U, \phi)\) is a chart on a manifold \(M\) of dimension \(n\), then the coordinate map \(\phi \colon U \rightarrow \phi(U)\) is a diffeomorphism.
\end{proposition}

\begin{definition}{Lie group}{}
    A \newterm{Lie group} is a \(C^\infty\) manifold \(G\) having a group structure such that the multiplication map
    \[
        \mu \colon G \times G \rightarrow G
    \]
    and the inverse map
    \[
        \iota \colon G \rightarrow G \quad \iota(x) \coloneqq x^{-1}
    \]
    are both \(C^\infty\).
    Similarly, a \newterm{topological group} is a topological space having a group structure such that multiplication and inverse maps are both continuous.
\end{definition}

\begin{example}
    Recall the definition of \(\gln\).
    As an open subset of \(\Rnn\), it is a manifold.
    Since the \((i,j)\)-entry of the product of two matrices \(A, B\) in \(\gln\)
    \[
        (AB)_{ij} = \sum_{k=1}^n a_{ik}b_{kj}
    \]
    is a polynomial in the coordinates of \(A\) and \(B\).
    Therefore matrix multiplication
    \[
        \mu \colon \gln \times \gln \rightarrow \gln
    \]
    is a \(C^\infty\) map.
    Furthermore, by Cramer's rule
    \[
        (A^{-1})_{ij} = \frac{(-1)^{i+j}}{\det A} ((j,i)-\text{minor of }A)
    \]
    which is a \(C^\infty\) function of the \(a_{ij}\)s provided \(\det A \neq 0\).
    Therefore, \(\gln\) is a Lie group.
\end{example}

\subsubsection{Partial Derivatives}

Let \((U, \phi)\) be a chart and \(f\) a \(\cinf\) function on the manifold.
As a function into \(\R^n\), \(\phi\) has \(n\) components \(x^1, \dots, x^n\).
Therefore, if \(r^1, \dots, r^n\) are the standard coordinates on \(\R^n\), then
\[
    x^i = r^i \circ \phi
\]
What this means is \(\phi\) maps to some point \((\phi^1(p), \dots, \phi^n(p))\) in \(R^n\). The projection to the \(i\)th standard coordinate on \(\R^n\) is \(r^i \circ \phi\), i.e. just pick out the component of \((\phi^1(p), \dots, \phi^n(p))\). This direct path from \(U\) to the \(i\)th standard coordinate of \(\R^n\) is called a local coordinate for \(U\) (since it's only valid in a small neighborhood of \(p\)). Then the collection \((x^1, \dots, x^n)\) are the local coordinates on \(U\) (but don't forget that the coordinates map from \(U \rightarrow \R^n\)).

\begin{definition}{Partial derivative}{}
    For \(p \in U\), we define the \newterm{partial derivative \( \frac{\partial f}{\partial x^i} \) of \(f\) with respect to \(x^i\) at \(p\)}
    \begin{splitenv}
        \evalat[\bigg]{\pdv{}{x^i}}{p} f &\coloneqq \evalat[\bigg]{\pdv{f}{x^i}}{p} \\
        &\coloneqq \evalat[\bigg]{\pdv{(f \circ \phi^{-1})}{r^i}}{\phi(p)}  \\
        &\coloneqq \evalat[\bigg]{\pdv{}{r^i}}{\phi(p)} (f \circ \phi^{-1})
    \end{splitenv}
    Thus, as functions on \(\phi(U)\) (and in terms of the local coordinates on \(U\))
    \begin{equation}
        \pdv{f}{x^i} \circ \phi^{-1} = \pdv{f \circ \phi^{-1}}{r^i}
    \end{equation}
    and therefore the partial derivative \(\partial f/ \partial x^i\) is \(\cinf\) on \(U\) because its pullback
    \[
        (\phi^{-1})^* \pdv{f}{x^i}
    \]
    is \(\cinf\).
\end{definition}

\begin{proposition}{Partial derivatives are dual}{}
    Suppose \(U, x^1, \dots, x^n\) (with local coordinates \(x^1, \dots, x^n\)) is a chart on a manifold. Then \(\partial x^i / \partial x^j = \delta_j^i\).
\end{proposition}

\begin{proof}
    At a point \(p \in U\), by the above definition of \(\evalat[\big]{\partial / \partial x^j}{p}\)
    \begin{splitenv}
        \evalat[\bigg]{\pdv{x^i}{x^j}}{p} &= \evalat[\bigg]{\pdv{x^i \circ \phi^{-1}}{r^j}}{\phi(p)} \\
        &= \evalat[\bigg]{\pdv{(r^i \circ \phi \circ \phi^{-1})}{r^j}}{\phi(p)} \\
        &= \evalat[\bigg]{\pdv{r^i}{r^j}}{\phi(p)} = \delta_j^i
    \end{splitenv}
\end{proof}

\begin{definition}{Jacobian}{}
    Let \(F \colon N \rightarrow M\) be a smooth map, and let \((U, \phi) \equiv (U, x^1, \dots, x^n)\) and \((V, \psi) \equiv (U, y^1, \dots, y^n)\) be charts on \(N, M\) respectively such that \(F(U) \subset V\).
    Denote by
    \[
        (F_i \coloneqq y^i \circ F \equiv r^i \circ \psi \circ F) \colon U \rightarrow \R
    \]
    the \(i\)th component of \(F\) in the chart \(V, \psi\).
    Then the matrix \(\left[ \pdv{F^i}{x^j} \right]\) is called the \newterm{Jacobian matrix of \(F\)} relative to the charts \(U, \phi\) and \((V, \psi)\).
\end{definition}

A diffeomorphism \(F \colon U \rightarrow F(U) \subset \R^n\) may be thought of as coordinate system on \(U\).
We say that a \(\cinf\) map \(F \colon N \rightarrow M\) is \newterm{locally invertible} or a \newterm{local diffeomorphism} at \(p \in N\) if \(p\) has a neighborhood \(U\) on which \(F\) is a diffeomorphism.
Given \(n\) smooth functions \(F^1, \dots, F^n\) in a neighborhood of \(p\) one would like to know whether they form a coordinate system.
This is equivalent to whether \(F = (F^1, \dots, F^n)\) is a local diffeomorphism at \(p\).
\begin{theorem}{Inverse function theorem \(\R^n\)}{}
    Let \(F \colon W \rightarrow \R^n\) be a \(\cinf\) map defined on an open subset \(W \subset \R^n\).
    For any point \(p \in W\), the map \(F\) is locally invertible iff the determinant of the Jacobian \[\det \left[ \evalat[\bigg]{\pdv{F^i}{r^j}}{p}   \right]\] is not zero.
\end{theorem}
\begin{theorem}{Inverse function theorem for manifolds}{}
    Let \(F \colon N \rightarrow M\) be a \(\cinf\) map between manifolds of the same dimension, and \(p \in N\).
    Suppose for some charts \((U, \phi) = (U, x^1, \dots, x^n)\), \((V, \psi) = (U, y^1, \dots, y^n)\) about \(p\) and \(F(p)\) respectively and \(F(U) \subset V\).
    Set \(F^i = y^i \circ F\).
    Then \(F\) is locally invertible at \(p\) iff
    \[\det \left[ \evalat[\bigg]{\pdv{F^i}{x^j}}{p}   \right]\]
    is not zero.
\end{theorem}
\begin{corollary}{}{}
    Let \(N\) be a manifold of dimension \(n\). A set of smooth functions \(F^1, \dots, F^n\) defined on a coordinate neighborhood \(U, x^1, \dots, x^n\) of a point \(p \in N\) forms a coordinate system about \(p\) iff the Jacobian determinant
    \[\det \left[ \evalat[\bigg]{\pdv{F^i}{x^j}}{p}   \right]\]
    is not zero.
\end{corollary}

\subsection{Tangent Space}

The tangent space to a manifold at a point is the vector space of derivations (germs/directional derivatives) at the point.
A smooth map of manifolds induces a linear map, called its differential, of tangent spaces at corresponding points.
In local coordinates, the differential is represented by the Jacobian.
In this sense, the differential of a map is the generalization of the derivative between Euclidean spaces.

A basic theme in manifold theory is linearization, according to which a manifold can be approximated by its tangent space and a smooth map can be approximated by the differential of that map.
The differential further categorizes maps as either immersions or submersions (depending on whether the differential is injective or surjective).

The collection of tangent spaces to a manifold can be given the structure of a \newterm{vector bundle}; it is thus called the \newterm{tangent bundle}.
Vector fields, which manifest themselves in the physical world as velocity, force, electricity, and magnetism, maybe viewed as sections of the tangent bundle.

\subsubsection{The Tangent Space at a Point}

\begin{definition}{Tangent vector}{}
    The germ of a \(\cinf\) function \(p \in M\) to be an equivalence class of \(\cinf\) functions defined in a neighborhood of \(p \in M\), with equivalence defined as agreement on a (possibly smaller) neighborhood of \(p\).
    The set of germs of \(\cinf\) real-valued functions is denoted \(\cinf_p(M)\).
    Addition and multiplication of functions induces a ring structure on \(\cinf_p(M)\); with scalar multiplication by real numbers \(\cinf_p(M)\) becomes an algebra over \(\R\).
    A derivation at a point in \(M\) is a linear map \(D \colon \cinf_p(M) \rightarrow \R\) such that
    \[
        D(fg) = (Df)g + f(p)Dg
    \]
    A tangent vector at a point \(p\) is a derivation at \(p\).
\end{definition}

Given a coordinate neighborhood \((U, \phi) = (U, x^1, \dots, x^n)\) and \((r^1, \dots, r^n)\) the standard coordinates on \(\R^n\) and
\[
    x^i = r^i \circ \phi \colon U \rightarrow \R
\]
If \(f\) is a smooth function in a neighborhood of \(p\)
\[
    \evalat[\bigg]{\pdv{}{x^i}}{p} f = \evalat[\bigg]{\pdv{}{r^i}}{\phi(p)} (f \circ \phi^{-1})
\]
The partial derivatives satisfy the derivation property and therefore qualify as tangent vectors.

\subsubsection{The Differential of a Map}

Let \(F \colon N \rightarrow M\) be a \(\cinf\) map between two manifolds.
At each point \(p \in N\), the map \(F\) induces a linear map of tangent spaces, called its \newterm{differential at \(p\)}
\[
    F_* \colon T_p N \rightarrow T_{F(p)}M
\]
defined as follows: if \(X_p \in T_p N\), then \(F_* (X_p)\) is the tangent vector in \(T_{F(p)}M\) according to
\[
    (F_* (X_p))f = X_p (f \circ F)
\]
for \(f \in \cinf_{F(p)}(M)\) a germ (or representative of the germ).
Vectors \newterm{pushforward} through \(F\).

\begin{example}{Differential of a map between Euclidean spaces}{}
    Suppose \(F \colon \R^n \rightarrow \R^m\) is smooth and \(p \in \R^n\).
    Let \(x^1, \dots, x^n\) be coordinates on \(\R^n\) and \(y^1, \dots, y^m\) be coordinates on \(\R^m\).
    Then
    \[
        \left\{ \evalat[\bigg]{\pdv{}{x^1}}{p}, \dots,  \evalat[\bigg]{\pdv{}{x^n}}{p}\right\}
    \]
    form a basis for the tangent space \(T_p(\R^n)\) and
    \[
        \left\{ \evalat[\bigg]{\pdv{}{y^1}}{F(p)}, \dots,  \evalat[\bigg]{\pdv{}{y^m}}{F(p)}\right\}
    \]
    form a basis for the tangent space \(T_{F(p)}(\R^m)\).
    The linear map
    \[
        F_* \colon T_p(\R^n) \rightarrow T_{F(p)}(\R^m)
    \]
    (the differential of \(F\)) is described by a matrix \(\left[ a_j^i \right]\) relative to these two bases:
    \[
        F_* \left( \evalat[\bigg]{\pdv{}{x^j}}{p} \right) = \sum_k a_j^k \evalat[\bigg]{\pdv{}{y^k}}{F(p)}
    \]
    Let \(F^i = y^ \circ F\) be the \(i\)th component of \(F\); we can find \(a_j^i\) by evaluating the right-hand side and left-hand side on \(y^i\)
    \begin{splitenv}
        \text{RHS} &= \sum_k a_j^k \evalat[\bigg]{\pdv{}{y^k}}{F(p)} y^i = \sum_k a_j^k \delta_k^i = a_j^i \\
        \text{LHS} &=  F_* \left( \evalat[\bigg]{\pdv{}{x^j}}{p} \right) y^i = \evalat[\bigg]{\pdv{}{x^j}}{p} (y^i \circ F) = \evalat[\bigg]{\pdv{F^i}{x^j}}{p}
    \end{splitenv}
    where we've used the fact that \(F^i = y^i \circ F\).
    Thus, \(F_*\) relative to the bases is the Jacobian
    \[
        \left[  \evalat[\bigg]{\pdv{F^i}{x^j}}{p}  \right]
    \]
    and hence the differential generalizes the derivative of a map between Euclidean spaces (because in this instance the Jacobian is the derivative and in abstract manifolds we use the same \(F_*\)).
    Note this means
    \[
        F_* \iff \text{Jacobian} \iff \text{differential} \iff \text{pushforward}
    \]
\end{example}

\begin{example}
    Define a diffeomorphism \(F\) such that
    \begin{equation}
        F\colon (r, \theta) \mapsto (r \cos \theta, r \sin \theta)
    \end{equation}
    The Jacobian of \(F\)
    \begin{equation}
        \operatorname{J}
        =
        \begin{bmatrix}
            \pdv{F_1}{r} & \pdv{F_1}{\theta} \\
            \pdv{F_2}{r} & \pdv{F_2}{\theta}
        \end{bmatrix}
        =
        \begin{bmatrix}
            \cos \theta & -r \sin \theta \\
            \sin \theta & r \cos \theta
        \end{bmatrix}
    \end{equation}
    where \((r, \theta) \equiv (x_1, x_2)\) and
    \[
        (x, y) \equiv (y_1, y_2) \equiv (F_1, F_2) \equiv (r \cos \theta, r \sin \theta)
    \]
    %
    Note that \(\det \operatorname{J} = r\) and so \(F\) is a diffeomorphism iff \(r \neq 0\).
    %
    Given a vector field
    %
    \begin{equation}
        X_p = a(r, \theta) \partial_r + b(r, \theta)\partial_\theta \coloneqq a(r, \theta) \pdv{}{r} + b(r, \theta)\pdv{}{\theta}
    \end{equation}
    %
    we can compute the pushforward \(F_*\) wrt the \(\partial_x, \partial_y\) basis
    \begin{equation}
        F_* (X_p)
        =
        \begin{bmatrix}
            \cos (\theta) & -r \sin (\theta) \\
            \sin (\theta) & r \cos (\theta)
        \end{bmatrix}
        \cdot
        \begin{pmatrix}
            a \\ b
        \end{pmatrix}
        =
        \begin{pmatrix}
            a \cos (\theta) - br \sin (\theta) \\
            a\sin (\theta) + br \cos (\theta)
        \end{pmatrix}
    \end{equation}
    Hence, explicitly
    \begin{equation}
        F_* (X_p) = (a \cos (\theta) - br \sin (\theta))\partial_x + (a\sin (\theta) + br \cos (\theta))\partial_y
    \end{equation}

    Since \(\operatorname{J}\) is invertible we can investigate which vector fields map to \(\partial_x\)
    %
    \begin{equation}
        F_* X_p = \partial_x  \iff X_p = F_{*}^{-1} \partial_x
    \end{equation}
    %
    Let \(X_p = a \partial_r + b \partial_\theta\).
    %
    Then
    \begin{equation}
        X_p
        =
        \begin{bmatrix}
            \cos (\theta)            & \sin (\theta)           \\
            -\frac{\sin (\theta)}{r} & \frac{\cos (\theta)}{r} \\
        \end{bmatrix}
        \cdot
        \begin{pmatrix}
            1 \\ 0
        \end{pmatrix} \\
        =
        \begin{pmatrix}
            \cos(\theta) \\ -\frac{\sin (\theta)}{r}
        \end{pmatrix}
    \end{equation}
    However we need to write \(r, \theta\) in terms of \(x, y\)
    \begin{equation}
        F_{*}^{-1} \partial_x = \frac{x}{\sqrt{x^2+y^2}}\partial_r + \frac{y}{x^2 + y^2} \partial_\theta
    \end{equation}
    %
    \(F_{*}^{-1}\) is called the pullback \(F^*\) of the vector field \(\partial_x\) along \(F\).
\end{example}

Let \(F \colon N \rightarrow M\) and \(G \colon M \rightarrow P\) be smooth maps of manifolds, and \(p \in N\).
The differentials of \(F\) at \(p\) and \(G\) at \(F(p)\) are linear maps
\[
    T_p N \xrightarrow{F_{*,p}} T_{F(p)} M \xrightarrow{G_{*, F(p)}} T_{G(F(p))}P
\]
\begin{theorem}{Chain rule}{}
    If \(F \colon N \rightarrow M\) and \(G \colon M \rightarrow P\) are smooth maps of and \(p \in N\), then
    \[
        (G \circ F)_{*, p} = G_{*, F(p)} \circ F_{*,p}
    \]
\end{theorem}
\begin{proof}
    Let \(X_p \in T_p N\) and let \(f\) be \(\cinf\) at \(G(F(p)) \in P\).
    Then
    \[
        ((G \circ F)_* X_p) f = X_p (f \circ G \circ F)
    \]
    and
    \begin{splitenv}
        ((G_* \circ F_*) X_p) f &= (G_* (F_* X_p)) f \\
        &= (F_* X_p)(f \circ G) \\
        &= X_p (f \circ G \circ F)
    \end{splitenv}
\end{proof}
\begin{example}{Chain rule in Calculus notation}{}
    Suppose \(w = G(x,y,z)\) is a \(\cinf\) function \(\R^3 \rightarrow \R\) and \((x,y,z) = F(t)\) is a \(\cinf\) function \(\R \rightarrow \R^3\).
    Under composition
    \[
        w = (G \circ F)(t) = G(x(t), y(t), z(t))
    \]
    becomes a \(\cinf\) function \(\R \rightarrow \R\).
    The differentials
    \begin{splitenv}
        F_* &= \begin{bmatrix}
            \dv{x}{t} \\ \dv{y}{t} \\ \dv{z}{t}
        \end{bmatrix} \\
        G_* &= \begin{bmatrix}
            \pdv{w}{x} \; \pdv{w}{y} \; \pdv{w}{z}
        \end{bmatrix} \\
        (G \circ F)_* &= \dv{w}{t}
    \end{splitenv}
    and since composition of linear maps is matrix multiplication
    \begin{splitenv}
        (G \circ F)_* &= G_* \circ F_*  \\
        &= \begin{bmatrix}
            \pdv{w}{x} \; \pdv{w}{y} \; \pdv{w}{z}
        \end{bmatrix} \cdot \begin{bmatrix}
            \dv{x}{t} \\ \dv{y}{t} \\ \dv{z}{t}
        \end{bmatrix} \\
        &= \pdv{w}{x}\dv{x}{t} + \pdv{w}{y}\dv{y}{t} + \pdv{w}{z}\dv{z}{t}
    \end{splitenv}
\end{example}

\begin{proposition}{}{}
    If \(F \colon N \rightarrow M\) is a diffeomorphism of manifolds then
    \[
        F_* \colon T_p N \rightarrow T_{F(p)} M
    \]
    is an isomorphism of vector spaces.
\end{proposition}

Recall \(r^i\) the standard coordinates on \(R^n\), \((U, \phi)\) a chart about \(p \in M\) (\(M\) dimension \(n\)), and \(x^i = r^i \circ \phi\).
Since \(\phi\) is a diffeomorphism onto its image, the differential (pushforward) \(\phi*\) is a vector space isomorphism and

\begin{proposition}{}{}
    Let \((U, \phi) = (U, x^1, \dots, x^n)\). Then
    \begin{equation}
        \phi_* \left( \evalat[\bigg]{\pdv{}{x^i}}{p} \right) = \evalat[\bigg]{\pdv{}{r^i}}{\phi(p)}
    \end{equation}
\end{proposition}
\begin{proposition}{}{}
    Let \((U, \phi) = (U, x^1, \dots, x^n)\). Then \(T_p M\) has basis
    \[
        \left\{ \evalat[\bigg]{\pdv{}{x^1}}{p}, \dots, \evalat[\bigg]{\pdv{}{x^n}}{p} \right\}
    \]
\end{proposition}
\begin{proposition}{Transition matrix for coordinate vectors}{}
    Suppose \((U, \phi) = (U, x^1, \dots, x^n)\) and \((V, \psi) = (U, y^1, \dots, y^n)\).
    Then
    \[
        \pdv{x^j} = \sum_{i=1}^n \pdv{y^i}{x^j}\pdv{y^i}
    \]
    on \(U \cap V\).
\end{proposition}

Given \(F \colon N \rightarrow M\) and \(G \colon M \rightarrow P\) are smooth maps of and \(p \in N, F(p) \in M\).
We will find a local expression for the differential
\[
    F_{*,p} \colon T_p N \rightarrow T_{F(p)} M
\]
relative to the two charts.
Using the local coordinate bases (induced by the charts) \(F_* \equiv F_{*,p}\), is completely determined by \(a_j^i\) such that
\begin{equation}
    F_* \left( \evalat[\bigg]{\pdv{x^j}}{p} \right) = \sum_{k=1}^m a_j^k \evalat[\bigg]{\pdv{y^k}}{F(p)}
\end{equation}
Applying \(y^i\), we find that
\begin{splitenv}
    a_j^i &= \left( \sum_{k=1}^m a_j^k \evalat[\bigg]{\pdv{y^k}}{F(p)} \right) y^i \\
    &= F_* \left( \evalat[\bigg]{\pdv{x^j}}{p} \right) y^i \\
    &= \evalat[\bigg]{\pdv{x^j}}{p} (y^i \circ F) \\
    &= \evalat[\bigg]{\pdv{F^i}{x^j}}{p}
\end{splitenv}
We restate as a proposition
\begin{proposition}{}{}
    Given \(F \colon N \rightarrow M\) and \(G \colon M \rightarrow P\) are smooth maps of and \(p \in N, F(p) \in M\).
    Relative to bases \(\evalat{\prt{}{x^j}}{p}\) for \(T_p N\) and \(\evalat{\prt{}{y^i}}{F(p)}\) for \(T_{F(p)} M\) the differential \(F_{*, p} \colon T_p \rightarrow T_{F(p)} M\) is represented by the matrix
    \begin{equation}
        \begin{bmatrix}
            \evalat[\bigg]{\pdv{F^1}{x^1}}{p} & \cdots & \evalat[\bigg]{\pdv{F^1}{x^n}}{p} \\
            \vdots                            & \ddots & \vdots                            \\
            \evalat[\bigg]{\pdv{F^m}{x^1}}{p} & \cdots & \evalat[\bigg]{\pdv{F^m}{x^n}}{p}
        \end{bmatrix}
    \end{equation}
\end{proposition}

\subsubsection{Curves in a Manifold}

A \newterm{smooth curve} is a smooth map \(c \colon (a,b) \rightarrow M\) with \(0 \in (a,b)\) and we say that \(c\) is a curve starting at \(p\) if \(c(0) = p\).
The \newterm{velocity vector} \(c'(t_0)\) at time \(t_0\) is
\[
    c'(t_0) \coloneqq c_* \left( \evalat[\bigg]{\dv{t}}{t_0} \right) \in T_{c(t_0)}M
\]
\begin{proposition}{Velocity of a curve in local coordinates}{}
    Let \(c \colon (a,b) \rightarrow M\) be a smooth curve and let \(U, x^1, \dots, x^n\) be a coordinate chart about \(c(t)\).
    Write \(c^i = x^i \circ c\) for the \(i\)th component of \(c\) in the chart.
    Then \(c'(t)\) is given by
    \[
        c'(t) = \sum_{i=1}^n \dot{c}^i(t) \evalat[\bigg]{\pdv{x^i}}{c(t)}
    \]
    where \(\dot{c}\) is the scalar deriviatve of the \(i\)th component.
    Thus, relative to the basis \(\{\evalat{\prt{}{x^j}}{p}\}\) for \(T_{c(t)}M\), the velocity \(c'(t)\) is represented by the column vector
    \[
        \begin{bmatrix}
            \dot{c}^1(t) \\
            \vdots       \\
            \dot{c}^n(t)
        \end{bmatrix}
    \]
\end{proposition}
Every smooth curve \(c\) at \(p\) in a manifold \(M\) gives rise to a tangent vector \(c'(0)\) in \(T_p M\).
Conversely, one can show that every tangent vector \(X_p \in T_p M\) is the velocity vector of some curve at \(p\)
\begin{proposition}{Existence of a curve with a given initial vector}{}
    For any point \(p\) in a manifold \(M\) and any tangent vector \(X_p \in T_p M\), there are \(\varepsilon > 0\) and a smooth curve \((-\varepsilon, \varepsilon) \rightarrow M\) such that \(c(0) = p\) and \(c'(0) = X_p\).
\end{proposition}
% \loadfig{curvevec}
\begin{proof}
    Let \((U, \phi) = (U, x^1, \dots, x^n)\) be a chart centered at \(p\) i.e. \(\phi(p) = \bm{0} \in \R^n\).
    Suppose \(X_p = \sum a^i \evalat[\big]{\prt{}{x^i}}{p}\) and let \(r^1, \dots, r^n\) be the standard coordinates on \(\R^n\), with \(x^i = r^i \circ \phi\).
    To find a curve \(c\) at \(p\) with \(c'(0)= X_p\), start with a curve \(\alpha \in \R^n\) with \(\alpha(0) = \bm{0}\) and \(\alpha'(0) = \sum a^i \evalat[\big]{\prt{}{r^i}}{\bm{0}}\).
    We then map \(\alpha\) to \(M\) via \(\phi^{-1}\) (see figure~\ref{fig:curvevec}).
    Let
    \[
        \alpha(t) \coloneqq (a^1 t, \dots, a^n t) \quad t \in (-\varepsilon, \varepsilon)
    \]
    with \(\varepsilon\) small enough such that \(\alpha(t) \in \phi(U)\).
    Then define \(c = \phi^{-1} \circ \alpha \colon (-\varepsilon, \varepsilon) \rightarrow M\).
    Then \(c(0) = \phi^{-1}(\alpha(0)) = \phi^{-1}(\bm{0}) = p\)
    and
    \begin{splitenv}
        c'(0) &= (\phi^{-1})_* \alpha_* \left( \evalat[\bigg]{\dv{t}}{t=0} \right) \\
        &= (\phi^{-1})_* \left( \sum_i a^i \evalat[\bigg]{\pdv{r^i}}{\bm{0}}  \right) \\
        &= \sum_i a^i \evalat[\bigg]{\pdv{x^i}}{p} = X_p
    \end{splitenv}
\end{proof}
This gives us a geometrical perspective on tangent vectors as directional derivatives
\begin{proposition}{Directional Derivatives}{}
    Suppose \(X_p\) is a tangent vector at a point \(p \in M\) and \(f \in C_p^\infty(M)\).
    If \(c \in (-\varepsilon, \varepsilon) \rightarrow M\) is a smooth curve starting at \(p\) with \(c'(0) = X_p\), then
    \[
        X_p f = \evalat[\bigg]{\dv{t}}{0} (f \circ c)
    \]
\end{proposition}

\begin{proposition}{}{}
    Let \(F \colon N \rightarrow M\) be a smooth map of manifolds, \(p \in N, X_p \in T_p N\).
    If \(c\) is a smooth curve starting at \(p \in N\) with velocity \(X_p\) at \(p\),
    \begin{equation}
        F_{*, p} (X_p) = \evalat[\bigg]{\dv{t}}{0} (F \circ c)(t)
    \end{equation}
\end{proposition}
\begin{example}{Differential of left multiplication}{}
    If \(g \in \gln\), let \(\ell_g \colon \gln \rightarrow \gln\) be left multiplication by \(g\) i.e. \(\ell_g (B) = g B\).
    Since \(\gln \subset \Rnn\) the tangent space \(T_g (\operatorname{GL}(n,\R))\) can be identified with \(\Rnn\).
    We show that with this identification the differential at the identity
    \[
        (\ell_g)_{*, \iota} \colon T_\iota (\gln) \rightarrow T_g (\gln)
    \]
    is also left multiplication by \(g\).

    Let \(X \in T_\iota (\gln) = \Rnn\).
    To compute \((\ell_g)_{*,\iota} (X)\), choose a curve \(c(t) \in \gln\) with \(c(0) = \iota\) and \(c'(0) = X\).
    Then \(\ell_g (c(t)) = g\cdot c(t)\) is simply matrix multiplication.
    Then
    \begin{splitenv}
        (\ell_g)_{*, \iota} (X) &= \evalat[\bigg]{\dv{t}}{t=0} \ell_g(c(t)) \\
        &= \evalat[\bigg]{\dv{t}}{t=0} g c(t) \\
        &= g c'(0) = gX
    \end{splitenv}
\end{example}

\subsection{Tangent Bundle}

A \newterm{smooth vector bundle} over a smooth manifold \(M\) is a smooth varying family of vector spaces, parameterized by \(M\), that locally looks like a product (of the manifold (base space) and the tangent spaces (fibers)).
The collection of tangent spaces to a manifold has the structure of a vector bundle, called the \newterm{tangent bundle}.
A smooth map between manifolds induces, via its differential at each point, a bundle map of the corresponding tangent bundles.
The tangent bundle is canonically associated to a manifold, hence invariants of the tangent bundle give rise to invariants of the manifold.
For example \newterm{Chern-Weil theory of characteristic classes} uses differential geometry to construct invariants for vector bundles; applied to the tangent bundle, characteristic classes lead to numerical diffeomorphism invariants of a manifold called \newterm{characteristic numbers} (which generalize the \newterm{Euler characteristic}).
A \newterm{section} of a vector bundle is a map that maps from each point of \(M\) into the \newterm{fiber} of the bundle over the point; both vector fields and differential forms on a manifold are sections of vector bundles.

\subsubsection{Topology of the Tangent Bundle}

Let \(M\) be a smooth manifold.
Recall that at each point \(p \in M\), the tangent space \(T_p M\) is the vector space of all point-derivations of \(\cinf_p (M)\) (itself the algebra of germs of \(\cinf\) functions at \(p\)).
The \newterm{tangent bundle} of \(M\) is the union of all the tangent spaces of \(M\)
\[
    TM \coloneqq \bigsqcup_{p \in M} T_p M
\]
There is a natural map (in the sense that it does not depend on choice of atlas or local coordinates) \(pi \colon TM \rightarrow M\) given by \(\pi(v) = p\) if \(v \in T_p M\).
As a matter of notation, we sometimes write a tangent vector \(v \in T_p M\) as a pair \((p, v)\).

As defined, \(TM\) is a set, with no topology or manifold structure.
We make it into a smooth manifold and show that it is a \(\cinf\) vector bundle over \(M\).
The first step is the topology.
If \((U, \phi) = (U, x^1, \dots, x^n)\) is a coordinate chart on \(M\), let
\[
    TU \coloneqq \bigsqcup_{p \in U} T_p U = \bigsqcup_{p \in U} T_p M
\]
where we've the fact that the algebra \(\cinf_p (U)\) of germs of \(\cinf\) functions in \(U\) at \(p\) is the same as \(\cinf_p (M)\) (since germ equivalence classes are determined by agreement in a neighborhood of \(p\)) and therefore \(T_p U = T_p M\).
At a point \(p \in U\) a tangent vector \(v \in T_p M\)
\[
    v = \sum_{i=1}^n c^i \evalat[\bigg]{\pdv{x^i}}{p}
\]
In this expression, \(c^i \equiv c^i(v)\) depend on \(v\) and so \textbf{therefore end up being functions on \(TU\)}.
%Let 
%\[ 
%    \bar{x}^i \coloneqq x^i \circ \pi \colon TM \rightarrow \R
%\]
% and 
Define \(\tilde{\phi} \colon TU \rightarrow \phi(U) \times \R^n\) by
\begin{gather}
    v \mapsto (x^1(p), \dots, x^n(p), c^1(v), \dots, c^n(v)) \\
    \iff \\
    \tilde{\phi}(v) = (\bar{x}^1 (v), \dots, \bar{x}^n(v), c^1(v), \dots, c^n (v)) \label{eqn:bundlechart}
\end{gather}
Then \(\bar{\phi}\) has an inverse (for a point \((x^1, \dots, x^n) = \phi(p)\))
\[
    \tilde{\phi}^{-1}(x^1(p), \dots, x^n(p), c^1(v), \dots, c^n(v)) = \sum c^i \evalat[\bigg]{\pdv{x^i}}{p}
\]
is therefore a bijection.
Therefore we use topology of \(\phi(U) \times \R^n\) to induce a topology on \(TU\): a set \(A \subset TU\) is open iff \(\tilde{\phi}(A)\) is open in \(\phi(U) \times \R^n\) (where \(\phi(U) \times \R^n\) has the standard topology as an open subset of \(\R^{2n}\)).
With this identification \(TU\) becomes homeomorphic to \(\phi(U) \times \R^n\).

\subsubsection{Manifold Structure on the Tangent Bundle}

Next we show that if \(\left\{ (U_i, \phi_i) \right\}\) is a \(\cinf\) atlas for \(M\), then \(\left\{  (TU_i, \tilde{\phi}_i) \right\}\) is a \(\cinf\) atlas for the tangent bundle \(TM\), where \(\tilde{\phi}_i\) is the map on \(TU_i\) induced by \(\phi_i\) as in~\eqref{eqn:bundlechart}.
It's immediately clear that \(TM = \bigcup_i TU_i\); remains to check that on \(TU_i \cap TU_j\), \(\tilde{\phi}_i, \tilde{\phi}_j\) are \(\cinf\) compatible.

Recall that if \((U, x^1, \dots, x^n), (V, y^1, \dots, y^n)\) are two charts on \(M\), then for any \(p \in U \cap V\) there are two bases and so any vector \(v \in T_p M\) has two representations
\[
    v = \sum_j a^j \evalat[\bigg]{\pdv{x^j}}{p} = \sum_i b^i \evalat[\bigg]{\pdv{y^i}}{p}
\]
Applying \(v\) to either of \(x^k, y^k\) we get that
\begin{equation}
    \begin{split}
        a^k &= \sum_i b^i \pdv{x^k}{y^i}  \\
        b^k &= \sum_j a^j \pdv{y^k}{x^j}
    \end{split}\label{eqn:twobases}
\end{equation}
Returning to the atlas \(\left\{ (U_i, \phi_i) \right\}\) and let \(\phi_\alpha = (x^1, \dots, x^n)\),  \(\phi_\beta = (y^1, \dots, y^n)\). Then
\[
    \tilde{\phi}_\beta \circ \tilde{\phi}_\alpha^{-1} \colon \phi_\alpha(U_\alpha \cap U_\beta) \times \R^n \rightarrow  \phi_\beta(U_\alpha \cap U_\beta) \times \R^n
\]
is given by (with \(\phi_\alpha(p) = (x^1(p), \dots, x^n(p))\))
\begin{splitenv}
    (\phi_\alpha(p), a^1(v), \dots, a^n(v)) &\mapsto \left( p, \sum_j a^j \evalat[\bigg]{\pdv{x^j}}{p} \right) \\
    &\mapsto ((\phi_\beta \circ \phi_\alpha^{-1})(\phi_\alpha(p)), b^1, \dots, b^n )
\end{splitenv}
where by~\eqref{eqn:twobases} and the Jacobian matrix of a transition map
\begin{splitenv}
    b^i &= \sum_j a^j \evalat[\bigg]{\pdv{y^i}{x^j}}{p}  \\ 
    &= \sum_j a^j \evalat[\bigg]{\pdv{(\phi_\beta \circ \phi_\alpha^{-1})}{r^j}}{\phi_\alpha(p)}
\end{splitenv}
By definition \(\phi_\beta \circ \phi_\alpha^{-1}\) is \(\cinf\) and therefore \(\tilde{\phi}_\beta \circ \tilde{\phi}_\alpha^{-1}\) is \(\cinf\) and thefore \(TM\) is a \(\cinf\) manifold, with \(\left\{ (TU_\alpha, \tilde{\phi}_\alpha) \right\}\) as a \(\cinf\) atlas.

\subsubsection{Vector Bundles}

On the tangent bundle \(TM\) of a smooth manifold \(M\), the natural projection map \(\pi \colon TM \rightarrow M\)
\[
    \pi(p, v)= p     
\]
makes \(TM\) into a \(\cinf\) \newterm{vector bundle} over \(M\) which we now define. 
Given any map \(\pi \colon E \rightarrow M\), where \(E\) is called the \newterm{total space} and \(M\)is called the \newterm{base space}, we call the inverse image \(\pi^{-1}(p) \coloneqq \pi^{-1}(\{p\})\) of a point \(p \in M\) the \newterm{fiber at \(p\)}.
The fiber at \(p\) is often written \(E_p\).
For any two maps 
\begin{splitenv}
    \pi &\colon E \rightarrow M  \\ 
    \pi' &\colon E' \rightarrow M 
\end{splitenv}
with the same target space \(M\), a map \(\phi \colon E \rightarrow E'\) is said to be \newterm{fiber-preserving} if \(\phi(E_p) \subset E_{p}'\) for all \(p \in M\).
\begin{example}{Fiber-preserving maps}{}
    Given two maps \(\pi, \pi'\), the map \(\phi\) is fiber-preserving iff the diagram
    \[
        \begin{tikzcd}
            E \arrow[swap]{rd}{\pi}\arrow{rr}{\phi} & & E' \arrow{ld}{\pi'} \\
            & M &
        \end{tikzcd}
    \]
    commutes.
\end{example}

\subsubsection{Smooth Sections}

A \newterm{section} of a vector bundle \(\pi \colon E \rightarrow M\) is a map \(s \colon M \rightarrow E\) such that \(\pi \circ s = \mathbf{1}_M\).
This just means that \(s\) maps \(p\) into the fiber \(E_p\) above \(p\) (see figure~\ref{fig:smoothsec}).
% \loadfig{smoothsec}

\begin{definition}{Vector field}{}
    A \newterm{vector field \(X\) on a manifold \(M\)} is a function that assigns a tangent vector \(X_p \in T_p M\) to each point \(p \in M\). In terms of the tangent bundle, a vector field on \(M\) is simply a section of the tangent bundle \(\pi \colon TM \rightarrow M\) and the vector field is smooth if it is a smooth as a map from \(M\) to \(TM\).
\end{definition}
% \loadfig{tangentbundle}
\begin{example}{}{}
    The formula
    \[
        X_{(x,y)} = \frac{1}{\sqrt{x^2+y^2}} \left( -y \pdv{x} + x \pdv{y} \right)  = \frac{1}{\sqrt{x^2+y^2}} \begin{bmatrix}
            -y \\ x
        \end{bmatrix}    
    \] 
    See figure~\ref{fig:vecfield}.
\end{example}
% \loadfig{vecfield}

\subsubsection{Smooth Frames}

A \newterm{frame} for a vector bundle \(\pi \colon E \rightarrow M\) over an open set \(U\) is a collection of sections \(s_1, \dots, s_r\) of \(E\) over \(U\) such that at each point \(p \in U\), the elements \(s_1(p), dots, s_r(p)\) form a basis for the fiber \(E_p \coloneqq \pi^{-1}(p)\).
A frame for the tangent bundle \(TM \rightarrow M\) over an open set \(U\) is simply called a \newterm{frame on \(U\)}.

\begin{example}{}{}
    The collection of vector fields \(\prt{}{x}, \prt{}{y}, \prt{}{z}\) is a smooth frame on \(\R^3\).
\end{example}

\begin{example}{}{}
    Let \(M\) be a manifold and \(e_1, \dots, e_r\) be the standard basis for \(\R^n\).
    Define \(\bar{e}_i \colon M \rightarrow M \times \R^r\) by \(\bar{e}_i (p) \coloneqq (p, e_i)\).
    Then \(\bar{e}_1, \dots \bar{e}_r\) is a \(\cinf\) frame for the product bundle \(M \times \R^r \rightarrow M\).
\end{example}

\subsection{Bump Functions and Partitions of Unity}

A partition of unity on a manifold is a collection of nonnegative functions that sum
to 1.

Usually one demands that the partition of unity should be \newterm{subordinate} to an open cover \(\{ U_\alpha \}_{\alpha \in A}\) i.e. the partition \(\{\rho_\alpha\}_{\alpha \in A}\) is indexed by the same set \(A\) and \(\rho_\alpha\) vanishes outside of \(U_\alpha\).

The existence of a \(\cinf\) partition of unity is one of the most important technical tools in the theory of \(\cinf\) manifolds.
It is the single feature that makes the behavior of \(\cinf\) manifolds so different from that of real-analytic or complex manifolds.
A partition of unity is used two ways:
\begin{enumerate}
    \item to decompose a global object on a manifold into a locally finite sum of local objects on the open sets \(U_\alpha\) of an open cover. 
    \item to patch together local objects on the open sets \(U_\alpha\) into a global object on the manifold.
\end{enumerate}

\subsubsection{\(\cinf\) Bump Functions}
\newcommand{\supp}{\operatorname{supp}}

The \newterm{support} of a real-valued function \(f\) on a manifold \(M\) is defined to be the closure in \(M\) of the subset on which \(f \neq 0\)
\begin{equation}
    \operatorname{supp} f = \operatorname{closure}\; \{ q \in M | f(q) \neq 0 \}
\end{equation}
Let \(q\) be a point in \(M\), and \(U\) a neighborhood of \(q\).
A \newterm{bump function at \(q\) supported in \(U\)} we mean any continuous nonnegative function \(\rho\) on \(M\) that is 1 in a neighborhood of \(q\) with \(\supp\; \rho \subset U\).
See figure~\ref{fig:bumpfunction}
% \loadfig{bumpfunction}

Define 
\begin{align}
    f(t) &= \begin{cases}
        e^{-1/t} &\text{for } t > 0 \\  
        0 &\text{for } t \leq 0 \\  
    \end{cases} \\
    g(t) &= \frac{f(t)}{f(t) + f(1-t)} \\ 
    h(x) &= g \left( \frac{x-a^2}{b^2 -a^2} \right) \\ 
    k(x) &= h(x^2) \\ 
    \rho(x) &= 1 - k(x)
\end{align}
See figure~\ref{fig:bumpfunction2}.
% \loadfig{bumpfunction2}
It is easy to extend the construction \(\rho(x)\) to a bump function from \(\R\) to \(R^n\): to get a \(\cinf\) bump function at \(\bm{0} \in \R^n\) that is 1 on the closed ball \(\bar{B}(\bm{0}, a)\) and has support in the closed ball \(\bar{B}(\bm{0}, b)\)
\begin{equation}
    \sigma(x) \coloneqq \rho(\abs{x}) = 1 - g \left( \abs{x} \frac{r^2 - a^2}{b^2 -a^2} \right)
\end{equation}

In general, a \(\cinf\) on an open subset \(U\) of a manifold cannot be extended to a \(\cinf\) function on \(M\); an example is the function \(\sec (x)\) on the open interval \((-\pi/2, \pi/2) \subset \R\).
However, if we require that the global function on \(M\) agree with the given function only on some neighborhood of a point in \(U\), then a \(\cinf\) extension is possible.

\begin{proposition}{\(\cinf\) extension of a function}{}
    Suppose \(f\) is a \(\cinf\) function defined on a neighborhood \(U\) of a point \(p\) in a manifold \(M\).
    Then there is a \(\cinf\) function \(\tilde{f}\) on \(M\) that agrees with \(f\) in some possibly smaller neighborhood of \(p\).
\end{proposition}
\begin{proof}
    Choose a \(\cinf\) bump function \(\rho \colon M \rightarrow \R\) supported in \(U\) that is identically 1 in a neighborhood \(V\) of \(p\).
    Define 
    \[
        \tilde{f}(q) = \begin{cases}
            \rho(q)f(q) & \text{for } q \in U \\ 
            0 & \text{for } q \notin U
        \end{cases}
    \]
    As the product of two \(\cinf\) functions on \(U\), \(\tilde{f}\) is \(\cinf\) on \(U\).
    If \(q \notin U\), then \(q \notin \supp \rho\), and so there is an open set containing \(q\) on which \(\tilde{f}\) is 0, since \(\supp \rho\) is closed.
    Therefore, \(\tilde{f}\) is also \(\cinf\) at every point \(q \notin U\).
    Finally, since \(\rho = 1\) on \(V\), the function \(\tilde{f}\) agrees with \(f\) on \(V\).
\end{proof}

\subsubsection{Partitions of Unity}
 If \(\{U_i\}_{i \in I}\) is a finite open cover of \(M\), a \newterm{\(\cinf\) partition of unity subordinate to \(\{U_i\}_{i \in I}\)} is a collection of nonnegative \(\cinf\) functions \(\{\rho_i \colon M \rightarrow \R\}_{i \in I}\) such that \(\supp \rho_i \subset U_i\) and 
 \[
    \sum_i \rho_i =    1
 \]
 When the index set \(I\) is an infinite set, for the sum to make sense, we impose and additional \newterm{local finiteness} condition: a collection \(\{A_i\}\) of subsets of a topological space \(S\) is said to be \newterm{locally finite} if every point \(q \in S\) has a neighborhood that meets only finitely many of the sets \(A_i\). In particular, every \(q \in S\) is contained in only finitely many of the \(A_i\).

 \begin{example}{An open cover that is not locally finite}{}
    Let \(U_{r,n}\) be the open interval \(\left( r - \frac{1}{n}, r + \frac{1}{n} \right)\).
    The open cover \(\{ U_{r,n} | r \in \mathbb{Q}, n \in \mathbb{Z}^+ \}\) of \(\R\) is not locally finite.
 \end{example}
 \begin{definition}{\(\cinf\) partition of unity}{}
    A \newterm{\(\cinf\) partition of unity on a manifold} is a collection of nonnegative \(\cinf\) functions \(\{\rho_i \colon M \rightarrow \R\}_{i \in I}\) such that 
    \begin{enumerate}
        \item the collection of supports is locally finite
        \item \(\sum \rho_i = 1\)
    \end{enumerate}
 \end{definition}

 Suppose \(\{f_i\}\) is a collection of \(\cinf\) functions on a manifold \(M\) such that the collection of its supports is locally finite.
 Then every point \(q \in M\) has a neighborhood \(W_q\) that intersects \(\supp f_i\) for only finitely many \(i\). 
 Thus, on \(W_q\) the sum \(\sum_i f_i\) is a finite sum.
 This shows that \(f = \sum _i f_i\) is well defined and \(\cinf\) on the manifold \(M\).
 Such a sum is called a locally finite sum.

 \begin{theorem}{Existence of a \(\cinf\) partition of unity}{}
    Let \(\{U_i\}\) be an open cover of a manifold \(M\).
    Then 
    \begin{enumerate}
        \item there is a \(\cinf\) partition of unity \(\{ \phi_k \}_{k=1}^\infty\) having compact support such that for each \(k, \supp \phi_k \subset U_i\) for some \(i\).
        \item if we do not require compact support, then there is a \(\cinf\) partition of unity \(\{ \rho_i \}\) subordinate to \( \{ U_i \} \).
    \end{enumerate}
 \end{theorem}

 \subsection{Vector Fields}

 A vector field \(X\) on a manifold \(M\) is the assignment of a tangent vector \(X_p \in T_p M\) to each point \(p \in M\) (a section of the tangent bundle \(TM\) of M).
 Every smooth vector field may be viewed locally as the velocity vector field of a fluid flow; the path traced out by a point under this flow is called an \newterm{integral curve} of the vector field.
 \textbf{Integral curves are curves whose velocity vector field is the restriction of the manifold's vector field, to the curve}; finding an equation of an integral curve is equivalent to solving a system of first-order ODEs.
 The set \(\mathfrak{X}(M)\) of all \(\cinf\) vector fields on a manifold \(M\) has the structure of a vector space; the \newterm{Lie Bracket} \([\;,\;]\) makes it into a \newterm{Lie algebra}.

 \subsubsection{Integral Curves}

\begin{definition}{Integral Curves}{}
    Let \(X\) be a \(\cinf\) vector field on a manifold \(M\), and \(p \in M\). 
    An \newterm{integral curve} \(c \colon (a,b) \rightarrow M\) such that \(c'(t) = X_{c(t)}\) for all \(t \in (a,b)\).
    To show the dependence of an integral curve on its initial point \(p\), we write \(c_t(p)\).
\end{definition}

\begin{example}{}{}
    Recall the vector field \(X_{(x,y)} = \langle -y,x \rangle\) on \(\R^2\).
    The condition for \(c(t) = (x(t), y(t))\) to be an integral curve is \(c'(t) = X_{c(t)}\) or 
    \[
        \begin{bmatrix}
            \dot{x}(t) \\ \dot{y}(t)
        \end{bmatrix} = \begin{bmatrix}
            -y(t) \\ x(t)
        \end{bmatrix}   
    \]
    Hence we need to solve the system of first-order ODEs 
    \begin{splitenv}
        \dot{x} &= -y \\ 
        \dot{y} &= x
    \end{splitenv}
    with initial condition \((x(0), y(0)) = (1,0)\).
    Making substitutions we get 
    \[
        \ddot{x} = -x
    \]
    which has the solution 
    \[
        x = A \cos t + B \sin t    
    \]
    and therefore 
    \[
        y = -\dot{x} = A \sin t - B \cos t
    \]
    The initial condition forces \(A=1,B=0\) and hence \(c(t) = (\cos t, \sin t)\), which parameterizes the unit circle.
    More generally, if the initial point of the integral curve, corresponding to \(t = 0\), is \(p = (x_0, y_0)\), then 
    \[
        A = x_0 \quad B = -y_0    
    \]
    and 
    \begin{splitenv}
        x &= x_0 \cos t - y_0 \sin t \\ 
        y &= x_0 \sin t + y_0 \cos t
    \end{splitenv}
    which can be written in matrix notation 
    \begin{splitenv}
        c(t) &= \begin{bmatrix}
            x(t) \\ y(t)
        \end{bmatrix} \\ 
        & = 
        \begin{bmatrix}
            \cos t & - \sin t \\ 
            \sin t & \cos t
        \end{bmatrix} \begin{bmatrix}
            x_0 \\ y_0
        \end{bmatrix} \\
        &= 
        \begin{bmatrix}
            \cos t & - \sin t \\ 
            \sin t & \cos t
        \end{bmatrix} p
    \end{splitenv}
    This show that the integral curve of \(X\) starting at point \(p\) can be obtained by rotating point \(p\) counterclockwise about the origin through an angle \(t\).
    Note that 
    \[
        c_s(c_t(p)) = c_{s+t} (p)   
    \]
    and also that for each \(t \in \R\), \(c_t \colon \R^2 \rightarrow \R^2\) is a diffeomorphism with inverse \(c_{-t}\).
    Let \(operatorname{Diff}(M)\) be the group of diffeomorphisms of a manifold \(M\) to itself, with the group operation being composition.
    A homomorphism \(c \colon \R \rightarrow \operatorname{Diff}(M)\) is called a \newterm{one-parameter group of diffeomorphisms} of \(M\).
    \textbf{In this example the integral curves of the vector field \(X_{(x,y)} = \langle -y,x \rangle\) on \(\R^2\) give rise to a one-parameter group of diffeomorphisms of \(R^2\)}.
\end{example}

\subsubsection{Local Flows}

In general, if \(X\) is a smooth vector field on a manifold \(M\), to find an integral curve \(c(t)\) of \(X\) starting at \(p\), we first choose a coordinate chart \((U, \phi) = (U, x^1, \dots, x^n)\) about \(p\).
In terms of the local coordinates 
\[
    X_{c(t)} = \sum a^i(c(t)) \evalat[\bigg]{\pdv{x^i}}{c(t)}
\]
or 
\[
    c'(t) = \sum \dot{c}^i (t) \evalat[\bigg]{\pdv{x^i}}{c(t)}    
\]
where \(c^i(t) = x^i \circ c(t)\) is the \(i\)th component of \(c(t)\) in the chart \((U, \phi)\).
The condition \(c'(t) = X_{c(t)}\) is equivalent to 
\[
    \dot{c}^i (t) = a^i(c(t))
\]
This is a system of ODEs; by \newterm{Picard–Lindelöf theorem} such a system has a unique solution in the following sense 
\begin{theorem}{}{}
    Let \(V\) be an open subset of \(\R^n\), \(p_0 \in V\), and \(f \colon V \rightarrow \R^n\) a \(\cinf\) function. 
    Then the differential equation 
    \[
        \dv{y}{t} = f(y)   \quad y(0) = p_0
    \]
    has a unique \(\cinf\) solution \(y \colon (a(p_0), b(p_0)) \rightarrow V\).
\end{theorem}

Suppose \(s,t\) in the interval \((-\varepsilon, \varepsilon)\) are such that both \(F_t(F_s(q))\) and \(F_{t+s}(q)\) are defined.
Then both \(F_t(F_s(q))\) and \(F_{t+s}(q)\), as functions of \(t\), are integral curves of \(X\) with initial point \(F_s(q)\).
By uniqueness of the integral curve starting at a point 
\[
    F_t(F_s(q)) = F_{t+s}(q)   
\]
The map \(F\) is called a \newterm{local flow generated by the vector field \(X\)}.
For each \(q \in U\), the function \(F_t(q)\) of \(t\) is called a \newterm{flow line} of the local flow.
See figure~\ref{fig:localflow}.
% \loadfig{localflow}
Each flow line is an integral curve of \(X\); if a local flow \(F\) defined on \(\R \times M\), then it is called a \newterm{global flow} (every smooth vector field has a local flow, but not necessarily a global flow).
A vector field having a global flow is called a \newterm{complete vector field}.
If \(F\) is a global flow, then for every \(t \in \R\)
\[
    F_t \circ F_{-t} = F_{-t} \circ F_t = F_0 = \bm{1}_M
\]
so \(F_t \colon M \rightarrow M\) is a diffeomorphism.
Thus, a global flow on \(M\) gives rise to a one-parameter group of diffeomorphisms on \(M\).

\begin{definition}{Local Flow}{}
    A \newterm{local flow} about a point \(p\) in an open set \(U\) of a manifold is a \(\cinf\) function 
    \[
         F \colon   (-\varepsilon, \varepsilon) \times W \rightarrow U
    \]
    where \(\varepsilon > 0\) and \(W\) is a neighborhood of \(p\) and \(W \subset U\), such that writing \(F_t(q)\coloneqq F(t,q)\), we have 
    \begin{enumerate}
        \item \(F_0(q) = q\) for all \(q \in W\)
        \item \(F_t(F_s(q)) = F_{t+s}(q)\) whenever both sides are defined
    \end{enumerate}
\end{definition}

If \(F_t(q)\) is a local flow of the vector field \(X\) on \(U\), then 
\begin{splitenv}
    F(0, q) &= q \\ 
    \evalat[\bigg]{\pdv{F}{t}}{0,q} &= X_{F(0,q)} \\ 
    &= X_q
\end{splitenv}
Thus, one can recover the vector field from its flow.
\begin{example}{}{}
    The function \(F \colon \R \times \R^2 \rightarrow \R^2\) 
    \[
        F \left( t, \begin{bmatrix}
            x \\ y
        \end{bmatrix} \right) =         \begin{bmatrix}
            \cos t & - \sin t \\ 
            \sin t & \cos t
        \end{bmatrix} \begin{bmatrix}
            x \\ y
        \end{bmatrix}    
    \]
    is the global flow on \(\R^2\) generated by the vector field 
    \begin{splitenv}
        X_{(x,y)} &= \evalat[\bigg]{\pdv{F(t,(x,y))}{t}}{t=0} \\ 
        &= \begin{bmatrix}
            \cos t & - \sin t \\ 
            \sin t & \cos t
        \end{bmatrix} \evalat[\bigg]{\begin{bmatrix}
            x \\ y
        \end{bmatrix} }{t=0} \\ 
        &= \begin{bmatrix}
            0 & -1  \\ 
            1 & 0
        \end{bmatrix} \begin{bmatrix}
            x \\ y
        \end{bmatrix} = \begin{bmatrix}
            -y \\ x
        \end{bmatrix} \\ 
        &= -y \pdv{x} + x \pdv{y}
    \end{splitenv}
\end{example}

\subsubsection{The Lie Bracket}

Suppose \(X,Y\) are smooth vector fields on an open subset \(U\) of a manifold \(M\).
We view \(X,Y\) as derivations on the set of \(\cinf\) functions.
For a \(\cinf\) function \(f\) on \(U\), the function \(Yf\) is \(\cinf\) on \(U\), and the function \((XY)f \coloneqq X(Yf)\) is also \(\cinf\) on \(U\).
Moreover, because \(X,Y\) are both \(\R\)-linear maps from \(\cinf(U)\) to \(\cinf(U)\), the map \(XY \colon \cinf(U) \rightarrow \cinf(U)\) is \(\R\)-linear.
However, \(XY\) does not satisfy the derivation property: if \(f,g \in \cinf(U)\), then 
\begin{splitenv}
    XY(fg) &= X \left( (Yf)g + f Y g \right)  \\ 
    &= (XYf)g + (Yf)(Xg) + (Xf)(Yg) + f(XYg)
\end{splitenv}
Looking more closely we see that the two extra terms \((Yf)(Xg)\) and \((Xf)(Yg)\) that make \(XY\) not a derivation, are symmetric in \(X,Y\).
Thus is we compute \(YX(fg)\) and subtract it from \(XY(fg)\), the extra terms will disappear, and \(XY-YX\) will be a derivation of \(\cinf(U)\).
\begin{definition}{Lie Bracket}{}
    Given two smooth vector fields \(X,Y\) on \(U\) and with \(p \in U\), we define their \newterm{Lie Bracket} \(\left[X,Y\right]\) at \(p\)
    \begin{equation}
        \left[X,Y\right]_p f = (X_p Y - Y_p X)f
    \end{equation}
    for any germ \(f\) of a \(\cinf\) function at \(p\).
\end{definition}
By the same calculation as above, but now evaluated at \(p\), it is easy to check that \([X,Y]_p\) is a derivation of \(\cinf_p (U)\) and is therefore a tangent vector at \(p\).
As \(p\) varies over \(U\), \([X,Y]\) becomes a vector field on \(U\).
\begin{proposition}{}
    If \(X,Y\) are smooth vector fields on \(M\), then the vector field \([X,Y]\) is also smooth on \(M\).
\end{proposition}
From this, we see that the Lie bracket provides a product operation on the vector space \(\mathfrak{X}(M)\) of all smooth vector fields on \(M\).
Clearly
\[
    [Y,X] = -[X,Y]    
\]
\begin{example}{Jacobi identity}{}
    The \newterm{Jacobi identity} holds for the Lie bracket 
    \[\sum_{\text{cyclic}} \left[ X, [Y,Z] \right] = 0\]
    where 
    \[
        \sum_{\text{cyclic}} \left[ X, [Y,Z] \right] = [X, [Y,Z]] + [Y, [Z,X]] + [Z,[X,Y]]
    \]
\end{example}
\begin{definition}{Lie Algebra}{}
    Let \(K\) be a field. 
    A \newterm{Lie algebra} over \(K\) is a vector space \(V\) over \(K\) together with a product
    \[
        [\;, \;]  \rightarrow V \times V \rightarrow V
    \]
    called the \newterm{bracket}, satisfying the following properties: for all \(a,b \in K\) and \(X,Y,Z \in V\)
    \begin{enumerate}
        \item \textbf{bilinearity}: \begin{splitenv}
            [aX + bY, Z] &= a [X,Z] + b [Y,Z] \\ 
            [Z, aX + bY] &= a [Z,X] + b[Z,Y]
        \end{splitenv}
        \item \textbf{anticommutativity}: \[[Y,X] = -[X,Y]\]
        \item \textbf{Jacobi identity}: \[\sum_{\text{cyclic}} \left[ X, [Y,Z] \right] = 0\]
    \end{enumerate}
\end{definition}

\begin{example}{Abelian Lie algebra}{}
    On any vector space \(V\), define \([X,Y]=0\) for all \(X,Y \in V\). With this bracket, \(V\) becomes a Lie algebra, called an \newterm{abelian Lie algebra}.
\end{example}
\textbf{An abelian Lie algebra is trivially associative, but in general the bracket of a
Lie algebra need not be associative. So despite its name, a Lie algebra is in general
not an algebra.}

\begin{example}{}{}
    If \(M\) is a manifold, then the vector space \(\mathfrak{X}(M)\) of \(\cinf\) vector fields on \(M\) is a real Lie algebra with the Lie bracket \([,]\) as the bracket.
\end{example}

\begin{example}{}{}
    Let \(K^{n \times n}\) be the vector space of all \(n \times n\) matrices over a field \(K\).
    Define
    \[
        [X,Y] = XY - YX    
    \]
    where \(XY\) is the matrix product of \(X\) and \(Y\).
    With this bracket, \(K^{n \times n}\) becomes a Lie algebra.
    More generally, if \(A\) is any algebra over a field \(K\), then the product 
    \[
        [x,y] = xy - yx    
    \]
    for \(x,y \in A\) makes \(A\) into a Lie algebra over \(K\).
\end{example}
\begin{definition}{derivation}{}
    A \newterm{derivation of a Lie algebra \(V\)} over a field \(K\) is a \(K\)-linear map \(D \colon V \rightarrow V\) satisfying the product rule 
    \[
        D[Y,Z] = [DY, Z] + [Y, DZ]
    \]
    for \(Y,Z in V\).
\end{definition}
\begin{example}{}{}
    Let \(V\) be a Lie algebra over a field \(K\). For each \(X \in V\), define 
    \[
        \operatorname{ad}_X (Y) = [X,Y]    
    \]
\end{example}

\subsubsection{Pushforward of Vector Fields}

Let \(F \colon N \rightarrow M\) be a smooth map of manifolds and let \(F_* \colon T_p N \rightarrow T_{F(p)}M\) be its differential at a point \(p\) in \(N\).
If \(X_p \in T_p N\), we call \(F_* (X_p)\) the \newterm{pushforward} of the vector \(X_p\) at \(p\).
This notion doesn't extend in general to vector fields, since it \(X\) is a vector field on \(N\) and 
\[
    z = F(p) = F(q)    
\]
for two distinct points \(p,q \in N\), then \(X_p\) and \(X_q\) are both pushed forward to tangent vectors \(X_z \in T_z M\), but there is no reason why \(F_* (X_p)\) and \(F_*(X_q)\) should be equal.

\subsection{Lie Groups and Lie Algebras}

A \newterm{Lie group} is a manifold that is also a group such that the group operations are smooth.
A Lie group is a homogeneous space in the sense that left translation by a group element \(g\) is a diffeomorphism of the group onto itself that maps the identity element to itself.
Therefore, locally the group looks the same around any point in the group.
To study the local structure of a Lie group, it is enough to examine a neighborhood of the identity element.
The tangent space at the identity of a Lie group \(G\) turns out to have a canonical bracket operation \([\;,\;]\) that makes it into a Lie algebra.
The tangent space \(T_e G\) with the bracket is called the \newterm{Lie algebra} of the Lie group \(G\).
The Lie algebra of a Lie group encodes within it much information about the group.

The matrix exponential gives rise to curves in a matrix group with a given initial vector.
It is useful in computing the differential of a map on a matrix group.

\subsubsection{Lie Group}

\begin{definition}{Lie group}{}
    A \newterm{Lie group} is a \(\cinf\) manifold \(G\) that is also a group such that the two group operations, multiplication
    \[
        \mu \colon G \times G \rightarrow G \quad \mu(a,b) \coloneqq ab   
    \]
    and inverse 
    \[
        \iota \colon G \rightarrow G \quad \iota(a) = a^{-1}   
    \]
    are \(\cinf\).
    For \(a \in G\), denote by 
    \begin{splitenv}
        \ell_a \colon G \rightarrow G \\ 
        \ell_a(x) = \mu(a,x) = ax 
    \end{splitenv}
    the operation of \newterm{left multiplication by \(a\)} and similarly by \(r_a\) the operation of \newterm{right multiplication by \(a\)}.
    We also call these operations \newterm{left and right translations}.
\end{definition}

\begin{example}{Left multiplication}{}
    For an element \(a \in G\), prove that the left multiplication/translation \(\ell_a \colon G \rightarrow G\) is a diffeomorphism.
\end{example}
\begin{definition}{Lie group homomorphism}{}
    A map \(F \colon H \rightarrow G\) between two Lie groups \(H, G\) is a \newterm{Lie group homomorphism} if it is a \(\cinf\) map and a group homomorphism.
    The group homomorphism condition means that for all  \(h,x \in H\)
    \[
        F(hx) = F(h)F(x)    
    \]
    or rewritten 
    \[
        F \circ \ell_h = \ell_{F(h)} \circ F
    \]
    for all \(h \in H\).
    Note that a group homomorphism always maps the identity to the identity.
\end{definition}

\begin{definition}{Orthogonal group}{}
    Recall that the orthogonal group \(\operatorname{O}(n)\) is the subgroup of \(\gln\) consisting of all matrices \(A\) satisfying \(A^T A = I\).
    Thus, \(\operatorname{O}(n)\) is the inverse image of \(I\) under the map \(f(A) = A^T A\).
\end{definition}

\subsubsection{Matrix Exponential}

Recall computing the pushforward using a smooth curve 
\[
    F_{*,p} (X_p) = \evalat[\bigg]{\dv{t}}{0} (F \circ c)(t)    
\]

To compute the differential of a map on a subgroup of \(\operatorname{GL}(n ,\R)\), we need a curve of nonsingular matrices.
Because the matrix exponential is always nonsingular, it is uniquely suited for this purpose.
\begin{definition}{Norm}{}
    A \newterm{norm} on a vector \(V\) is a real-valued \(\abs{\cdot}\colon V \rightarrow \R\) satisfying the following three properties for all \(r \in \R, v,w \in V\)
    \begin{enumerate}
        \item \textbf{positive-definiteness}: \(\abs{v} \geq 0\) with equality iff \(v = 0\)
        \item \textbf{positive homogeneity}: \(\abs{rv} = \abs{r}\abs{v}\)
        \item \textbf{subadditivity}: \(\abs{v+w} \leq \abs{v} + \abs{w}\)
    \end{enumerate}
    A vector space \(V\) with a norm is called a \newterm{normed vector space}.
    For example, the vector space \(\Rnn \cong \R^{n^2}\) with the norm 
    \[
        \abs{X} = \sqrt{\sum_{ij} x_{ij}^2}  
    \]
\end{definition}
\begin{definition}{Matrix exponential}{}
    The \newterm{matrix exponential} \(e^X\) of a matrix \(X \in \R^{n\times n}\) is defined 
    \[
        e^X = I + X + \frac{1}{2!}X^2 + \frac{1}{3!}X^3 + \cdots    
    \]
    If \(A, B\) commute then 
    \[
        e^A e^B = e^{A+B}    
    \]
\end{definition}
\begin{proposition}{}{}
    For \(X \in \Rnn\)
    \[
        \dv{t} e^{tX} = X e^{tX} = e^{tX} X    
    \]
\end{proposition}

\subsubsection{Trace of a Matrix}

\begin{definition}{Trace of a Matrix}{}
    For a \(n \times n\) matrix \(X\)
    \[
        \operatorname{tr}(X) = \sum_{i=1}^n x_ii    
    \]
    i.e. the sum of the diagonal elements.
\end{definition}
\begin{lemma}{}{}
    \begin{enumerate}
        \item For any two matrices \(X,Y \in \Rnn\) \[
            \operatorname{tr}(XY) = \operatorname{tr}(YX)    
        \]
        \item For \(X \in \Rnn\) and \(A \in \gln\) \[
            \operatorname{tr}(AXA^{-1}) = \operatorname{X}    
        \]
    \end{enumerate}
\end{lemma}
\begin{proposition}{}{}
    The trace of a matrix, real or complex, is equal to the sum of its complex \newterm{eigenvalues} 
\end{proposition}
\begin{proof}
    Suppose \(X\) has complex eigenvalues \(\lambda_1, \dots, \lambda_n\).
    Then there exists a nonsingular matrix \(A \in \operatorname{GL}(n, \C)\) such that 
    \[
        AXA^{-1} = \begin{bmatrix}
            \lambda_1 & & * \\ 
            & \ddots & \\
            0 & & \lambda_n
        \end{bmatrix}
    \]
    and then 
    \[
        \operatorname{tr}(X) = \operatorname{tr} (AXA^{-1}) = \sum_i \lambda_i
    \]
\end{proof}
\begin{proposition}{}{}
    For any \(X \in \Rnn\) 
    \[
        \det (e^X) = e^{\operatorname{tr}(X)}   
    \]
\end{proposition}
\begin{proof}
    Case 1: Assume that \(X\) is upper triangular 
    \[
        X = \begin{bmatrix}
            \lambda_1 & & * \\ 
            & \ddots & \\
            0 & & \lambda_n
        \end{bmatrix}
    \]
    Then 
    \begin{splitenv}
         e^X &= \sum \frac{1}{k!}X^k \\
         &= \sum \frac{1}{k!} \begin{bmatrix}
            \lambda_1^k & & * \\ 
            & \ddots & \\
            0 & & \lambda_n^k
        \end{bmatrix} \\ 
        &= \begin{bmatrix}
            e^{\lambda_1} & & * \\ 
            & \ddots & \\
            0 & & e^{\lambda_n}
        \end{bmatrix}
    \end{splitenv}
    and hence \[\det e^X = \prod e^{\lambda_i} = e^{\sum \lambda_i} = e^{\operatorname{tr}X}\].
    Case 2: Given a general matrix \(X\), with eigenvalues \(\lambda_1, \dots, \lambda_n\), we can find a nonsingular matrix \(A\) such that 
    \[
        AXA^{-1} = \begin{bmatrix}
            \lambda_1 & & * \\ 
            & \ddots & \\
            0 & & \lambda_n
        \end{bmatrix}
    \]
    an upper triangular matrix. 
    Then 
    \begin{splitenv}
        e^{AXA^{-1}} &= I + AXA^{-1} + \frac{1}{2!} (AXA^{-1})^2 + \frac{1}{3!}(AXA^{-1})^3 + \cdots \\ 
        &= I + AXA^{-1} + A \left( \frac{1}{2!} X^2 \right) A^{-1} + A \left( \frac{1}{3!} X^3 \right) A^{-1} + \cdots \\ 
        &= A e^X A^{-1}
    \end{splitenv}
    and hence 
    \begin{splitenv}
        \det e^X &= \det (A e^X A^{-1}) \\ 
        &= \det e^{A X A^{-1}}  \\ 
        &= e^{\operatorname{tr}(AXA^{-1})} \\ 
        &= e^{\operatorname{tr}X}
    \end{splitenv}
\end{proof}
It follows that the matrix exponential \(e^X\) is always nonsingular, because \(\det(e^X) = e^{\tr X} \neq 0\).
This is one reason why the matrix exponential is so useful, for it allows us to write down explicitly a curve in \(\gln\) with a given initial point and a given initial velocity.
For example \(c(t) = e^{tX} \colon \R \rightarrow \gln\) is a curve in \(\gln\) with initial point \(I\) and initial velocity \(X\), since 
\[
    c(0) = e^{0 X} = e^0 = I    
\]
and 
\[
    c'(0) = \evalat[\bigg]{\dv{t} e^{tX}}{t=0} = \evalat[\bigg]{X e^{tX}}{t=0} = X
\]
Similarly, \(c(t) = A e^{tX}\) is a curve in \(\gln\) with initial point \(A\) and initial velocity \(AX\).

\subsubsection{The Differential of \(\det\) at the identity}

Let \(\det \colon \gln \rightarrow \R\) be the determinant map.
The tangent space \(T_I \gln\) at the identity matrix \(I\) is the vector space \(\Rnn\) and the tangent space \(T_1 \R\) to \(\R\) at 1 is \(\R\). 
So 
\[
    \operatorname{det}_{*, I} \colon \Rnn \rightarrow \R
\]
\begin{proposition}{}{}
    For any \(X \in \Rnn\) it is the case that \(\det_{*,I}(X) = \tr X\)
\end{proposition}
\begin{proof}
    We use a a curve at \(I\) to compute the differential. 
    As a curve \(c(t)\) with \(c(0)=I\) and \(c'(0) = X\), choose the matrix exponential \(c(t)=e^{tX}\).
    Then 
    \begin{splitenv}
        \operatorname{det}_{*,I}(X) &= \evalat[\bigg]{\dv{t} \det (e^{tX})}{t=0} \\ 
        &= \evalat[\bigg]{\dv{t} e^{t \tr X}}{t=0} \\
        &= \evalat[\bigg]{(\tr X) e^{t \tr X}}{t=0} \\
        &= \tr X
    \end{splitenv}
\end{proof}

\subsubsection{Tangent Space at the identity of a Lie Group}

Left translation \(\ell_g \colon G \rightarrow G\) by an element \(g \in G\) is a diffeomorphism with inverse \(\ell_{g^{-1}}\).
This diffeomorphism takes the identity \(e\) to \(g\) and induces and isomorphism on tangent spaces 
\[
(\ell_g)_* \coloneqq (\ell_g)_{*,g} \colon T_e G \rightarrow T_g G
\]
Thus, if we can describe the tangent space at the identity, then pushing forward we can describe the tangent space at any point in \(G\).

\begin{example}{Tangent space to \(\gln\) at \(I\)}{}
    The tangent space at any point \(g \in \gln\) is \(\Rnn\).
    The isomorphism 
    \[
        (\ell_g)_* \colon T_I(\gln) \rightarrow T_g (\gln)
    \]
    is also identified as left multiplication by \(g\):
    \[
        g \colon X \mapsto gX    
    \]
    for \(X \in G\).
\end{example}
\newcommand{\sln}{\operatorname{SL}(n, \R)}
\begin{example}{Tangent space to \(\sln\)}
    We begin by finding a condition that a tangent vector \(X \in T_I (\sln)\) must satisfy.
    Using the curve velocity version of the tangent vector there is a curve \(c \colon (-\varepsilon, \varepsilon) \rightarrow \sln\) with \(c(0) = I\) and \(c'(0) = X\).
    Being in \(\sln\), this curve satisfies 
    \[
        \det c(t) = 1    
    \]
    for all \(t \ in (-\varepsilon, \varepsilon)\).
    Differentiating both sides and evaluating at \(t=0\)
    \begin{splitenv}
        \evalat[\bigg]{\dv{t} \det c(t)}{t=0} &= (\det \circ\, c)_* \left( \evalat[\bigg]{\dv{t}}{t=0} \right) \\ 
        &= \operatorname{det}_{*,I} \left( c_* \evalat[\bigg]{\dv{t}}{t=0} \right) \\ 
        &= \operatorname{det}_{*,I} \left(c'(0)\right) \\ 
        &= \operatorname{det}_{*,I} (X) \\ 
        &= \tr X
    \end{splitenv}
    Thus,
    \[
        \tr X = \evalat[\bigg]{\dv{t} 1}{t=0}   = 0
    \]
    and so the tangent space \(T_I (\sln)\) is contained in the subspace \(V\) of \(\Rnn\) defined by 
    \[
        V = \{ X \in \Rnn | \tr X = 0 \}    
    \]
    Since \(\dim V = n^2-1 = \dim T_I \sln\), the two spaces must be equal.
\end{example}
\begin{example}{The tangent space to \(\operatorname{O}(n)\) at \(I\)}{}
    Let \(X\) be a tangent vector to the orthogonal group \(\operatorname{O}(n)\) at the identity \(I\).
    Choose a curve \(c(t) \in \operatorname{O}(n)\) such that \(c(0) = I, c'(0) = X\).
    Since \(c(t) \in \operatorname{O}(n)\)
    \[
        c(t)^T c(t) = I    
    \]
    Differentiating both sides 
    \[
        c'(t)^T c(t) + c(t)^T c'(t) = 0    
    \]
    Evaluating at \(t = 0\) we get 
    \[
        X^T + X = 0    
    \]
    Thus, \(X\) is skew-symmetric.
    Let \(K_n\) be the space of all \(n \times n\) real skew-symmetric matrices; the diagonal entries of such matrices are all 0 and entries below the diagonal are determined by those above the diagonal.
    Therefore 
    \[
        \dim K_n = \frac{n^2 -\text{\# diagonal entries}}{2} = \frac{1}{2}(n^2-n)    
    \]
    Therefore 
    \[
        T_I (\operatorname{O}(n)) \subset K_n
    \]
    By an earlier computation 
    \[\dim T_I (\operatorname{O}(n)) = \dim \operatorname{O}(n) = \frac{n^2-n}{2}\]
    and therefore \(T_I (\operatorname{O}(n)) = K_n\)
\end{example}

\subsubsection{Left-Invariant Vector Fields on a Lie Group}

We say that the vector field \(X\) is \newterm{left-invariant} if 
\[
    \left(\ell_{g} \right)_* X = X
\]
for every \(g \in G\); this means that for any \(h \in G\)
\[
    \left(\ell_{g} \right)_* (X_h) = X_{gh}    
\]
i.e. the vector \(X_h\) (anchored at \(h\)) pushes forward (under the left-multiplication by \(g\) map \(\ell_g\)) to \(X_{gh}\).

A left-invariant vector field \(X\) is completely determined by its value \(X_e\) at the identity, since 
\[
    X_g = (\ell_g)_* (X_e)    
\]
Conversely, given a tangent vector \(A \in T_e (G)\) we can define a vector field \(\tilde{A}\) on \(G\)
\[
    \tilde{A}_g \coloneqq (\ell_g)_*
\]
So defined \(\tilde{A}\) is left-invariant
\begin{splitenv}
    (\ell_g)_* (\tilde{A}_h) &= (\ell_g)_* (\ell_h)_* A \\ 
    &= (\ell_g \circ \ell_h)_* A \\ 
    &= (\ell_{gh})_* A \\
    &= \tilde{A}_{gh}
\end{splitenv}

\(\tilde{A}\) is called the \newterm{left-invariant vector field on \(G\) generated by \(A \in T_e G\)}.
Let \(L(G)\) be the vector space of all left-invariant vector frields \(G\).
Then there is a one-to-one correspondence
\begin{splitenv}
    T_e (G) &\leftrightarrow L(G)  \\
    X_e &\mapsfrom X  \\
    A &\mapsto \tilde{A} 
\end{splitenv}

\begin{example}{Left-invariant vector fields on \(\gln\)}{}
    Since \(\gln\) is an open subset of \(\Rnn\), at any \(g \in \gln\) there is a canonical identification of the tangent space \(T_g (\gln)\) with \(\Rnn\), under which a tangent vector corresponds to an \(n \times n\) matrix 
    \[
        \sum a_{ij} \evalat[\bigg]{\pdv{}{x_{ij}}}{g} \leftrightarrow [a_{ij}]   
    \]
    We use the same letter \(B\) for the tangent vector and the matrix.
    Let 
    \[
        \sum b_{ij} \evalat[\bigg]{\pdv{}{x_{ij}}}{I} \in T_I (\gln)
    \]
    and let \(\tilde{B}\) be the left-invariant vector field on \(\gln\) generated by \(B\).
    Then 
    \[
        \tilde{B}_g = (\ell_g)_* B \leftrightarrow gB    
    \]
    and 
    \begin{splitenv}
        \tilde{B}_g &= \sum_{i,j} (gB)_{ij} \evalat[\bigg]{\pdv{}{x_{ij}}}{g}  \\ 
        &= \sum_{i,j} \left( \sum_k g_{ik}b_{kj} \right) \evalat[\bigg]{\pdv{}{x_{ij}}}{g}
    \end{splitenv}
\end{example}
\begin{proposition}{}{}
    If \(X,Y\) are left-invariant vector fields on \(G\), then so is \([X,Y]\).
\end{proposition}

\subsubsection{The Lie Algebra of a Lie Group}

The isomorphism \(\phi \colon T_e G \cong L(G)\) (the set of left-invariant vector spaces on \(G\)) enables us to define a Lie bracket on \(T_e G\) and to push forward left-invariant vector fields under a Lie group homomorphism.
We beging with the Lie bracket on \(T_e G\). 
Given \(A,B \in T_e G\), we first map them via \(\phi\) to the left-invariant vector fields \(\tilde{A}, \tilde{B}\), take the Lie bracket 
\[
    [\tilde{A}, \tilde{B}] = \tilde{A}\tilde{B} - \tilde{B}\tilde{A}
\]
and then map it back to \(T_e G\) via \(\phi^{-1}\).
Thus, the definition of the Lie bracket \([A,B] \in T_e G\) should be 
\[
    [A,B] = [\tilde{A}, \tilde{B}]_e
\]
\begin{proposition}{}{}
    If \(A,B \in T_e G\) and \(\tilde{A}, \tilde{B}\) are the left-invariant vector fields they generate, then 
    \[
        [\tilde{A}, \tilde{B}] = [A,B]^{\sim}
    \]
\end{proposition}

With the Lie bracket \([\;,\;]\), the tangent space \(T_e G\) becomes a Lie algebra, called the \newterm{Lie algebra of the Lie group \(G\)}.
As a Lie algebra, \(T_e G\) is usually denoted \(\mathfrak{g}\).

\subsection{Differential Forms}

Differential forms plays a crucial role in manifold theory.
First and foremost, they are intrinsic objects associated to any manifold, and so can be used to construct diffeomorphism invariants.
Differential forms have a richer algebraic structure; due to the existence of the wedge product, a grading, and the exterior derivative, the set of smooth forms on a manifold is both a graded algebra and a differential complex.
Such an algebraic structure is called a \newterm{differential graded algebra}.
Moreover, the differential copmlex of smooth forms on a manifold can be pulled back under a smooth map, making the complex \newterm{contravariant functor} called the \newterm{de Rham complex} of the manifold.
We will eventually construct the de Rham cohomology of a manifold of a manifold from the de Rham complex.

\subsubsection{Differential 1-Forms}

Let \(M\) be a smooth manifold and \(p \in M\).
The \newterm{cotangent space} of \(M\) at \(p\), denoted by \(T_p^* M\), is defined to be the dual space of the tangent space \(T_p M\)
\[
    T_p^* M = (T_p M)^{\vee} = \operatorname{Hom}(T_p M, \R)   
\]
An element of the cotangent space \(T_p^* M\) is called a \newterm{covector} at \(p\).
Thus, a covector \(\w_p \colon T_p M \rightarrow \R\)
A \newterm{covector field}, a \newterm{differential 1-form} is a function \(\w\) that assigns to each point \(p \in M\) a covector \(\w_p\) at p.

\begin{definition}{Differential}{}
    If \(f\) is a \(\cinf\) real-valued function on a manifold \(M\), its \newterm{differential} is defined to be the 1-form \(\dif f\) on \(M\) such that for any \(p \in M\) and \(X_p \in T_p M\)
    \[
        (\dif f)_p (X_p) = X_p f
    \]  
\end{definition}

\subsubsection{Local Expression for a Differential 1-Form}

Let \((U, \phi) = (U, x^1, \dots, x^n)\) be a coordinate chart on \(M\).
Then the differentials \(\dif x^1, \dots, \dif x^n\) are 1-forms on U.

\begin{proposition}{}{}
    At each point \(p \in U\), the covectors \(\dif x^1, \dots, \dif x^n\) form a basis for the cotangent space \(T_p^* M\), dual to the basis 
    \[
        \pdv{x^1}, \dots, \pdv{x^n}    
    \]
    of the tangent space \(T_p M\).
\end{proposition}

\subsubsection{The Cotangent Bundle}

The \newterm{cotangent bundle} \(T^* M\) of a manifold \(M\) is the union of the cotangent spaces at all points of \(M\)
\[
    T^* M \coloneqq \bigcup_{p \in M} T_p^* M
\]
There is a natural map \(\pi \colon T^* M \rightarrow M\) given by \(\pi(\alpha) = p\) if \(\alpha \in T_p^* M\).
Properly speaking, the \newterm{cotangent bundle} of a manifold \(M\) is the triple \((T^* M, M, \phi)\), while \(T^* M\) is the \newterm{total space} and \(M\) is the \newterm{base space} of the cotangent bundle, but by abuse of language it is customary to call \(T^* M\) the cotangent bundle of \(M\).
In terms of the cotangent bundle, a 1-form on \(M\) is simply a section of the cotangent bundle \(T^* M\) i.e. it is a map \(\w \colon M \rightarrow T^*M\) such that \(\pi \circ \w = 1_M\)

\begin{example}{Liouville form on the cotangent bundle}{}
    If a manifold \(M\) has dimension \(n\), then the total space \(T^* M\) of its cotangent bundle \(\pi \colon T^* M \rightarrow M\) is a manifold of dimension \(2n\) (chart and coefficients). 
    Remarkably, on \(T^* M\) there is a 1-form \(\lambda\), called the \newterm{Liouville form}, or \newterm{Poincare form}, defined independently of charts as follows.
    A point in \(T^* M\) is a covector \(\w_p \in T_p^* M\) at some point \(p \in M\).
    If \(X_{\w_p}\) is a tangent vector to \(T^* M\) at \(\w_p\), then the pushforward \(\pi_* (X_{\w_p})\) is a tangent vector to \(M\) at \(p\).
    Therefore, one can pair up \(\w_p\) and \(\pi_* (X_{\w_p})\) to obtain a real number \(\w_p (\pi_* (X_{\w_p}))\)
    \[
        \lambda_{\w_p} (X_{\w_p}) = \w_p (\pi_* (X_{\w_p}))
    \]
    The cotangent bundle and the Liouville form on it play an important role in classical mathematics.
\end{example}

\subsubsection{Pullback of 1-Forms}

If \(F \colon N \rightarrow M\) is a \(\cinf\) map of manifolds, then at each point \(p \in N\) the differential
\[
    F_{*,p} \colon T_p N \rightarrow T_{F(p)} M
\]
is a linear map that pushes forward vectors at \(p\) from \(N\) to \(M\).
The \newterm{codifferential} i.e. the dual of the differential
\[
    F^* \coloneqq (F_{*,p})^\vee \colon T_{F(p)}^* M \rightarrow T_p^* N   
\]
pulls back a covector at \(F(p)\) from \(M\) to \(N\).
By the definition of the dual, if \(\w_{F(p)} \in T_{F(p)}^* M\) is a covector at \(F(p)\) and \(X_p \in T_p N\) then 
\[
    F^* (\w_{F(p)}) (X_p) = \w_{F(p)} (F_{*,p} X_p)  
\]
We call \(F^* (\w_{F(p)})\) is the \newterm{pullback} of the covector \(\w_{F(p)}\) by \(F\).

Unlike vector fields, which in general cannot be pushed forward under a \(\cinf\) map, every covector field can be pulled back by a \(\cinf\) map.
If \(\w\) is a 1-form on \(M\), its \newterm{pullback \(F^* \w\)} is the 1-form on \(N\) defined pointwise by 
\[
    (F^* \w)_p \coloneqq F^* (\w_{F(p)})    
\]
This means that 
\[
    (F^* \w)_p (X_p) = \w_{F(p)} (F_* (X_p))
\]
i.e. pushforward the vector to \(M\) and then apply \(\w\) to it.
\begin{proposition}{Pullback rules}
    Let \(F \colon N \rightarrow M\) be a \(\cinf\) map of manifolds.
    For any \(g,h \in \cinf(M)\), \(\w ,\tau \in \Omega^1(M)\)
    \begin{enumerate}
        \item \(F^* (\dif h) = \dif (F^* h)\)
        \item \(F^*(\w + \tau) = F^* \w + F^* \tau\)
        \item \(F^* (g \w) = (F^* g) (F^* \w)\)
    \end{enumerate}
\end{proposition}
\begin{example}{Liouville form on the cotangent bundle}{}
    Let \(M\) be a manifold.
    In terms of the pullback, the Liouville form \(\lambda\) on the cotangent bundle \(T^* M\) can be expressed as 
    \[
        \lambda_{\w_p} = \pi^* (\w_p)    
    \]
\end{example}

\subsubsection{Differential \(k\)-forms}

We now generalize from 1-forms on a manifold to \(k\)-forms. 
In parallel with the construction of the tangent and cotangent bundles on a manifold, we construct the \(k\)th exterior power \(\bigwedge^k T^* M\) of the cotangent bundle; a differential \(k\)-form is seen as a section of this bundle.
The pullback and the wedge product of differential forms are defined pointwise.

Recall that a \newterm{\(k\)-tensor} on a vector space \(V\) is a \(k\)-linear function
\[
    f \colon \underbrace{ V \times \cdots \times V}_k \rightarrow \R    
\]
\(f\) is alternating if for any permutation \(\sigma \in S_k\)
\[
    f \left( v_{\sigma(1)}, \dots, v_{\sigma(k)} \right) = (\operatorname{sgn}(\sigma)) f (v_1, \dots, v_k)   
\]
An alternating \(k\)-tensor on \(V\) is also called a \newterm{\(k\)-covector} on \(V\).

\begin{definition}{\(A_k(V)\)}{}
    For any vector space \(V\), denote by \(A_k(V)\) the vector space of alternating \(k\)-tensors on \(V\). 
    Another common notation is \(\bigwedge^k (V^\vee)\), where \(V^\vee\) is the dual space to \(V\).
    Thus, 
    \begin{splitenv}
        \bigwedge^0 (V^\vee) &\equiv A_0 (V) = \R \\ 
        \bigwedge^1 (V^\vee) &\equiv A_1 (V) = V^\vee \\ 
        \bigwedge^2 (V^\vee) &\equiv A_2 (V) = V^\vee 
    \end{splitenv}
    where we use the fact that all 1-tensors are alternating and so \(A_1(V)\equiv V^\vee\).
    In fact, there is a purely algebraic construction \(\bigwedge^k (V^\vee)\), called the \newterm{exterior power} of the vector space \(V\), with the property that \(\bigwedge^k (V^\vee) \cong A_k(V)\) but we take this for granted.
\end{definition}

\(A_k()\) is a \newterm{functor}; applying it to \(T_p M\) we get the vector space \(A_k(T_p M)\), usually denoted \(\bigwedge^k (T_p^* M)\), the space of all alternating \(k\)-tensors on the tangent space \(T_p M\).
A \newterm{\(k\)-covector field} on \(M\) is a function \(\w\) that assigns at each point \(p \in M\) a \(k\)-covector \(\w_p \in \bigwedge^k (T_p^* M)\).
A \(k\)-covector field is also called a \newterm{differential \(k\)-form}, \newterm{differential form of degree \(k\)}, or simply a \newterm{\(k\)-form}.
A \newterm{top form} on a manifold is a differential form whose degree is the dimension of the manifold.

If \(\w \in \bigwedge^k(T_p^* M)\) on a manifold \(M\) and \(X_1, \dots, X_k \) are vector fields on \(M\), then \(\w(X_1, \dots, X_k)\) is the function on \(M\) defined 
\[
    (\w (X_1, \dots, X_k))(p) \coloneqq \w_p ((X_1)_p, \dots, (X_k)_p)   
\]
\begin{proposition}{Multilinearity of a form over functions}{}
    Let \(\w\) be a \(k\)-form on a manifold \(M\). For any vector fields \(X_1, \dots, X_k\) and any function \(h\) on M
    \[
        \w(X_1, \dots, h X_i, \dots, X_k) = h \w (X_1, \dots, X_i, \dots, X_k)   
    \]
\end{proposition}
\begin{example}{}{}
    Let \((U, x^1, \dots, x^n)\) be a coordinate chart on a manifold.
    At each point \(p \in U\), a basis for the tangent space \(T_p U\) is 
    \[
        \evalat[\bigg]{\pdv{x^1}}{p}, \dots, \evalat[\bigg]{\pdv{x^n}}{p}
    \]
    A dual basis for the cotangent space is \(T_p^* U\) is 
    \[
       (\dif x^1)_p, \dots, (\dif x^n)_p
    \]
    and a basis for \(\bigwedge^k (T_p^* U)\) is 
    \[
        (\dif x^{i_1})_p \wedge \dots \wedge (\dif x^{i_k})_p     
    \]
    If \(\w\) is a \(k\)-form on \(\R^n\), then at each point \(p \in \R^n\), \(\w_p\) is a linear combination 
    \[
        \w_p = \sum a_{i_1 \cdots i_k}(p) (\dif x^{i_1})_p \wedge \dots \wedge (\dif x^{i_k})_p   
    \]
    Omitting the point \(p\) we write 
    \[
        \w_p = \sum a_{i_1 \cdots i_k} \dif x^{i_1} \wedge \dots \wedge \dif x^{i_k}
    \]
    \textbf{where \(a_{i_1 \cdots i_k}\) are functions on \(U\) because they vary with the point \(p\)}.
    To simplify the notation, let 
    \[
        \mathcal{J}_{k,n} \coloneqq \left\{ I = (i_1, \dots, i_k) | 1 \leq i_1 < \cdots < i_k \leq n \right\}
    \]
    be the set of all strictly ascending multi-indices between 1 and \(n\) of length \(k\). 
    Then 
    \[
        \w \equiv \sum_{I\in \mathcal{J}_{k,n}} a_I \dif x^I    
    \]
    where 
    \[
        \dif x^I \coloneqq \dif x^{i_1} \wedge \cdots \wedge \dif x^{i_k}    
    \]
\end{example}

Note that for \(U\) and \(I,J \in \mathcal{J}_{k,n}\)
\[
    \dif x^I (\partial_J) = \delta_J^I \coloneqq \begin{cases}
        1 & \text{for } I = J \\  
        0 & \text{for } I \neq J 
    \end{cases}
\]
where 
\[
    \partial_J \coloneqq \left( \pdv{x^{j_1}}, \dots, \pdv{x^{j_k}} \right)
\]
\begin{proposition}{A wedge of differentials in local coordinates}{}
    Let \(U, x^1, \dots, x^n\)  be a chart on a manifold and \(f^1, \dots, f^k\) be smooth functions on \(U\).
    Then 
    \[
        \dif f^1 \wedge \cdots \wedge \dif f^k = \sum_{I \in \mathcal{J}_{k,n}} \pdv{(f^1, \dots, f^k)}{(x^{i_1}, \dots, x^{i_k})} \dif x^{i_1} \wedge \dots \wedge \dif x^{i_k}  
    \]
    where 
    \[
        \pdv{(f^1, \dots, f^k)}{(x^{i_1}, \dots, x^{i_k})} \coloneqq \det \left[ \pdv{f^i}{x^{i_j}} \right]  
    \]
\end{proposition}
\begin{corollary}{Transition differential}{}
    \[
    \dif y^I = \sum_{J} \pdv{(y^{i_1}, \dots, y^{i_k})}{(x^{j_1}, \dots, x^{j_k})} \dif x^J
    \]
    In particular 
    \begin{enumerate}
        \item \[
            \dif f = sum \pdv{f}{x^i} \dif x^i    
        \]
        \item \[
            \dif f^1 \wedge \cdots \wedge \dif f^n = \det \left[  \pdv{f^j}{x^i} \right] \dif x^1 \wedge \dots \wedge \dif x^n
        \]
    \end{enumerate}
\end{corollary}

\subsubsection{The Bundle Point of View}

Let \(M\) be a manifold of dimension \(n\).
Then 
\[
    \bigwedge^k (T^* M) \coloneqq \bigcup_{p \in U} \bigwedge^k (T_p^* M) = \bigcup_{p \in M} A_k(T_p M)
\]
where \(A_k (T_p M)\) is the vector space of alternating \(k\)-tensors.
\(\bigwedge^k (T^* M)\) is called the \newterm{\(k\)-th exterior power} of the cotangent bundle; there is a projection map \(\pi \colon \bigwedge^k (T^* M) \rightarrow M\) given by 
\[
    \pi(\alpha) = p    
\]
if \(\alpha \in \bigwedge^k (T_p^*M)\).

If \(U, \phi\) is a coordinate chart on \(M\), then there is a \textbf{bijection}
\begin{splitenv}
    \bigwedge^k (T^*U) \coloneqq \bigcup_{p \in U} \bigwedge^k (T_p^* U) &\cong \phi(U) \times \R^{n \choose k} \\ 
    \alpha \in \bigwedge^k (T_p^* U) &\mapsto (\phi(p), c_I (\alpha))
\end{splitenv}
where \(\alpha = \sum c_I (\alpha) \dif x^I \in \bigwedge^k (T_p^* U)\).
This bijection induces a topology and differentiable structure on \(\bigwedge^k (T^* M)\).
This structure then turns the projection map 
\[
    \pi \colon \bigwedge^k (T^* M)  \rightarrow M
\]
into a \(\cinf\) vector bundle of rank \(n \choose k\) and a differential \(k\)-form into, simply, a section of this bundle.

Note that if \(E \rightarrow M\) is a \(\cinf\) vector bundle, then the vector space of \(\cinf\) sections of \(E\) is denoted \(\Gamma(E)\) or \(\Gamma(M,E)\).
The vector spaces of all \(\cinf\) \(k\)-forms on \(M\) is usually denoted by \(\Omega^k(M)\).
Thus,
\[
    \Omega^k(M) \equiv \Gamma(\bigwedge^k (T^* M)) \equiv \Gamma(M, \bigwedge^k (T^* M))   
\]

\subsubsection{Pullback of \(k\)-forms}

For a \(\cinf\) 0-form on \(M\) under a \(\cinf\) map \(F \colon N \rightarrow M\) (i.e. a \(\cinf\) function \(f \colon M \rightarrow \R\)) the pullback \(F^* f\) is simpliy the composition
\[
    F^* f = f \circ F \in \Omega^0 (N)    
\]
Generalizing to \(k\)-forms, we first recall the pullback of \(k\)-covectors: a linear map \(L \colon V \rightarrow W\) of vector spaces induces a pullback map \(L^* \colon A_k(W) \rightarrow A_k(V)\) by 
\[
    (L^* \alpha) (v_1, \dots, v_k) = \alpha(L(v_1), \dots, L(v_k))   
\]
for \(\alpha \in A_k (W)\) and \(v_1, \dots, v_k \in V\).
Now suppose \(F \colon N \rightarrow M\); at each point the differential (pushforward)
\[
    F_{*,p} \colon T_p N \rightarrow T_{F(p)} M
\]
is a linear map of tangent spaces and so there is a corresponding pullback map on \(k\)-forms:
\[
    (F_{*,p})^* \colon A_k(T_{F(p)}M) \rightarrow A_k (T_p N)
\]
Thus, if \(\w_{F(p)}\) is a \(k\)-form at \(F(p)\) in M, then its \newterm{pullback} \(F^*(\w_{F(p)})\) is the \(k\)-form 
\[
    (F^*(\w_{F(p)}))(v_1, \dots, v_k) \coloneqq \w_{F(p)} (F_{*,p}v_1, \dots, F_{*,p}v_k)
\]
for \(v_i \in T_p N\).
\begin{proposition}{Linearity of the pullback}{}
    Let \(F \colon N \rightarrow M\) be a \(\cinf\) map. 
    If \(\w, \tau\) are \(k\)-forms on \(M\) and \(a\) is a real number, then 
    \begin{enumerate}
        \item \(F^* (\w + \tau) = F^* \w + F^* \tau \) \\ 
        \item \(F^* (a \w) = a F^* \w \)
    \end{enumerate}
\end{proposition}

\subsubsection{The Wedge Product}

If \(\alpha, \beta\) are alternating tensors of degree \(k, \ell\) on a vector space \(V\), then their wedge product \(\alpha \wedge \beta\) is the alternating \((k+\ell)\)-tensor on \(V\) defined 
\begin{multline}
    (\alpha \wedge \beta)(v_1, \dots, v_{k+\ell}) = \\ \sum \operatorname{sgn}(\sigma) \alpha(v_{\sigma(1)}, \dots, v_{\sigma(k)})\beta(v_{\sigma(k+1)}, \dots, v_{\sigma(k+\ell)})   
\end{multline}
where \(v_i \in V\) and \(\sigma\) runs over all \((k, \ell)\)-shuffles of \(1, \dots, k+\ell\).
For example if \(\alpha, \beta\) are 1-covectors, then 
\[
    (\alpha \wedge \beta)(v_1, v_2) = \alpha(v_1)\beta(v_2) - \alpha(v_2)\beta(v_1)   
\]
For a \(k\)-form \(\w\) and an \(\ell\)-form \(\tau\) on \(M\) define their \newterm{wedge product} \(\w \wedge \tau\) to be the \(k+\ell\)-form on \(M\)
\[
    (\w \wedge \tau)_p \coloneqq \w_p \wedge \tau_p
\]

\begin{proposition}{Pullback of a wedge product}{}
    If \(F \colon N \rightarrow M\) is a \(\cinf\) map of manifolds and \(\w, \tau\) are differential forms on \(M\), then 
    \[
        F^* (\w \wedge \tau) = F^* \w \wedge F^* \tau   
    \]
\end{proposition}
\begin{definition}{Differential Graded Algebra}{}
    Define the vector space \(\Omega^* (M)\) of \(\cinf\) differential forms on a manifold \(M\) of dimension \(n\) to be the direct sum 
    \[
        \Omega^*(M) \coloneqq \bigoplus_{k=0}^n \Omega^k (M)     
    \]
    which means that each element in \(\Omega^* (M)\) is uniquely a sum \(\sum_{k=0}^n \w_k\), where \(\w_k \in \Omega^k (M)\).
    With the wedge product on forms, \(\Omega^* (M)\) becomes a graded algebra, the grading being the degree of differential forms.
\end{definition}

\subsection{The Exterior Derivative}

Recall that an \newterm{antiderivation} on a graded algebra \(A = \bigoplus_{k=0}^\infty A^k\) is an \(\R\)-linear map \(D \colon A \rightarrow A\) such that 
\[
    D(\w \cdot \tau) = (D \w) \cdot \tau + (-1)^k \w \cdot (D\tau)    
\]
where \(\w \in A^k\) and \(\tau \in A^\ell\).
In the graded algebra \(A\) is called a \newterm{homogeneous element} of degree \(k\) if only comes from \(A^k\).
An \newterm{antiderivation of degree \(m\)} is such that 
\[
    \deg D\w = \deg \w + m   
\]
On the graded algebra \(\Omega^* (M)\) there is a uniquely and intrinsically defined antiderivation called the \newterm{exterior derivative}, the application of which is called \newterm{exterior differentiation}
\begin{definition}{Exterior derivative}{}
    An \newterm{exterior derivative} on a manifold \(M\) is an \(\R\)-linear map
    \[
        D \colon \Omega^*(M)    \rightarrow \Omega^*(M)
    \]
    such that 
    \begin{enumerate}
        \item \(D\) is an antiderivation of degree 1
        \item \(D \circ D = 0\)
        \item if \(f\) is a \(\cinf\) function and \(X\) a \(\cinf\) vector field on \(M\), then 
        \[ (Df)(X) = Xf \]
    \end{enumerate}
    Condition 3 says that on 0-forms an exterior derivatives agrees with the differential \(\dif f\).
\end{definition}

\subsubsection{Exterior Derivative on a Coordinate Chart}

Let \(U, x^1, \dots, x^n\) be a coordinate chart on a manifold \(M\).
Then for any \(k\)-form \(\w\) on \(U\), the exterior derivative \(D\) is 
\begin{splitenv}
    D\w &= \sum_I (D a_I) \wedge \dif x^I + \sum_I a_I (D \dif x^I) \\ 
    &= \sum_I (D a_I) \wedge \dif x^I \\ 
    &= \sum_I \sum_j \pdv{a_I}{x^j} \dif x^j \wedge \dif x^I
\end{splitenv}
Like the derivative of a function on \(\R^n\), an antiderivation \(D\) on \(\Omega^* (M)\) has the property that for a \(k\)-form \(\w\), the value of \(D\w\) at a point \(p\) depends only on the values of \(\w\) in a neighborhood of \(p\). 
To make this precise we define \newterm{local operators}.

An \newterm{endomorphism} of a vector space \(W\) is often called an \newterm{operator} on \(W\).
For example if \(W = \cinf(\R)\) is the vector space of \(\cinf\) functions on \(\R\), then the derivative \(\dv{x}\) is an operator on \(W\):
\[
    \dv{x} f(x) = f'(x)
\]
The derivative has the property that the value of \(f'(x)\) at a point \(p\) depends only on the values of \(f\) in a small neighborhood of \(p\); i.e. if \(f = g\) on an open set \(U \subset \R\), then \(f' = g'\) on \(U\). 
In this sense the derivative is a \newterm{local operator} on \(\cinf(\R)\).

\begin{definition}{Local operator}{}
    An operator \(D \colon \Omega^*(M) \rightarrow \Omega^* (M)\) is said to be \textit{local} if for all \(k \geq 0\), whenever a \(k\)-form \(\w \in \Omega^k(M)\) restricts to 0 on an open set \(U\) in \(M\), then \(D\w \equiv 0\) on \(U\).
    Equivalently \(D\) is local if for all \(k \geq 0 \), whenever two \(k\)-forms \(\w, \tau \in \Omega^k(M)\) agree on an open set \(U\), then \(D \w \equiv D \tau\) on \(U\).
\end{definition}
\begin{example}{Integral operator}{}
    Define the integral operator 
    \[
        I \colon \cinf ([a,b]) \rightarrow \cinf ([a,b])
    \] 
    by 
    \[
        I(f) \coloneqq \int\limits_a^b f(t) \dif t   
    \]
    \(I\) is not a local operator, since the value of \(I(f)\) at any point \(p\) depends on the values of \(f\) over the entire interval \([a,b]\).
\end{example}

\begin{proposition}{}{}
    Any antiderivation \(D\) on \(\Omega^*(M)\) is a local operator.
\end{proposition}
\begin{proof}
    Suppose \(\w \in \Omega^k(M)\) and \(\w \equiv 0\) on an open subset \(U\).
    It suffices to prove that \((D\w)_p = 0\).
    Choose a \(\cinf\) bump function \(f\) at \(p\) supported in \(U\).
    In particular, \(f \equiv 1\) in a neighborhood of \(p \in U\).
    Then \(f \w \equiv 0\) on \(M\) (since \(q \in U\), then \(\w_q \equiv 0\) and if \(q \notin U\) then \(f(q) = 0\)).
    Applying the antiderivation property of \(D\) to \(f\w\)
    \[
        0 = D(0) = D(f\w) = (Df) \wedge \w + (-1)^0 f \wedge (D \w)    
    \]
    Evaluating the right-hand side at \(p\), noting that \(\w_p =0\) and \(f(p) =1\), gives \(0 = (D\w)_p\).
\end{proof}

\subsubsection{Existence of an Exterior Derivative on a Manifold}

Define on a chart \(U, x^1, \dots, x^n\)
\[
    \dif_U \w = \sum \dif a_I \wedge \dif x^I    
\]
Then define 
\[
    (\dif \w)_p \coloneqq (\dif_U \w)_p   
\]
and we can prove that \((\dif \w)_p\) is independent of the chart (using transition functions).
As \(p\) varies over all points of \(M\), this defines an operator 
\[
    \dif \colon \Omega^* (M)    \rightarrow \Omega^* (M)
\]

\subsubsection{Exterior Differentiation Under a Pullback}

The pullback of differential forms commutes with the exterior derivative.
This fact, and the preservation of the wedge product by the pullback, is a cornerstone of a calculations involving the pullback.

\begin{proposition}{Commutation of the pullback with \(\dif\)}{}
    Let \(F \colon N \rightarrow M\) be a smooth map of manifolds.
    If \(\w \in \Omega^k(M)\), then \(\dif F^* \w = F^* \dif \w\).
\end{proposition}
\begin{corollary}{}{}
    If \(U\) is an open subset of a manifold \(M\) and \(\w \in \Omega^k(M)\), then
    \[
        \evalat[\big]{\dif \w}{U} = \dif \left( \evalat[\big]{\w}{U} \right)
    \]
\end{corollary}
\begin{example}{}{}
    Let \(U\) be the open set \((0, \infty) \times (0 , 2 \pi)\) in the \((r, \theta)\)-plane \(\R^2\).
    Define \(F \colon U \subset \R^2 \rightarrow \R^2\) by 
    \[
        F(r, \theta) = (r \cos \theta, r \sin \theta)    
    \]
    If \((x,y)\) are the standard coordinates on the target \(\R^2\), compute the pullback \(F^* (\dif x \wedge \dif y)\):
    \begin{splitenv}
        F^* &= \dif F^* x \\ 
        &= \dif (x \circ F)  \\ 
        &= \dif (r \cos \theta) \\ 
        &= (\cos \theta) \dif r - r \sin \theta \dif \theta
    \end{splitenv}
    and similarly 
    \[
        F^* \dif y = (\sin \theta) \dif r + r \cos \theta \dif \theta
    \]
    Then since the pullback commutes with the wedge product 
    \begin{splitenv}
        F^* (\dif x \wedge \dif y) &= (F^* \dif x) \wedge (F^* \dif y) \\ 
        &= \left[ (\cos \theta) \dif r - r \sin \theta \dif \theta \right] \wedge \left[ (\sin \theta) \dif r + r \cos \theta \dif \theta \right] \\ 
        &= \left( r \cos^2 \theta + r \sin^2 \theta \right) \dif r \wedge \dif \theta \\ 
        &= r \dif r \wedge \dif \theta
    \end{splitenv}
\end{example}

\begin{proposition}{}{}
    If \(F \colon N \rightarrow M\) is a \(\cinf\) map of manifolds and \(\w\) is a \(\cinf\) \(k\)-form on \(M\), then \(F^* \w\) is a \(\cinf\) \(k\)-form on \(N\).
\end{proposition}

In summary, if \(F \colon N \rightarrow M\) is a \(\cinf\) map of manifolds, then the pullback map \(F^* \colon \Omega^*(M) \rightarrow \Omega^*(N)\) is a \newterm{morphism of differential graded algebras}, i.e. a degree-preserving algebra homomorphism that commutes with the differential.

\subsection{The Lie Derivative and Interior Multiplication}

\subsubsection{The Lie Derivative of a Vector Field}

The problem with generalizing the derivative 
\[
    f'(p) = \lim_{t \rightarrow 0} \frac{f(p+t) - f(p)}{t}
\]
to the derivative of a vector field \(Y\) on a manifold \(M\) is that at two nearby points \(p,q\) the tangent vectors \(Y_p, Y_q\) are in different vector spaces \(T_p M, T_q M\) (and so it is not possible to compare them by subtracting one from the other).
\textbf{One way to get around this difficulty is to use the local flow of another vector field \(X\) to transport \(Y_q\) to the tangent space \(T_p M\) at \(p\)}.
This leads to the definition of the \newterm{Lie derivative of a vector field}.

Recall that for any smooth vector field \(X\) on \(M\) and point \(p \in M\), there is a neighborhood \(U\) of \(p\) on which the vector field has a \newterm{local flow} (integrate the ODE in the neighborhood); 
\[
    \phi \colon (-\varepsilon, \varepsilon) \times U \rightarrow M     
\]
such that \(\phi_t (q) \coloneqq \phi(t,q)\).
Then 
\begin{splitenv}
    \pdv{t} \phi_t (q) &= X_{\phi_t(q)} \\ 
    \phi_0(q) &= q
\end{splitenv}
In other words, for each \(q \in U\), the curve \(\phi_t(q)\) is an integral curve of \(X\) with initial point \(q\).
The local flow satisfies the property 
\[
    \phi_s \circ \phi_t = \phi_{s+t}    
\]
Consequently, for each \(t\) the map \(\phi_t \colon U \rightarrow \phi_t (U)\) is a diffeomorphism onto its image, with a \(\cinf\) inverse \(\phi_{-t}\):
\begin{splitenv}
    \phi_{-t} \circ \phi_t &= \phi_0 = 1 \\ 
    \phi_t \circ \phi_{-t} &= phi_0 = 1
\end{splitenv}

Let \(Y\) be a \(\cinf\) vector field on \(M\).
To compare the values of \(Y\) at \(\phi_t(q)\) and at \(p\), we use the diffeomorphism 
\[
    \phi_{-t} \colon \phi_t(U) \rightarrow U
\]
to push \(Y_{\phi_t(p)}\) back to \(T_p M\).
\loadfig{liederivative}
\begin{definition}{Lie derivative}{}
    For \(X,Y \in \mathfrak{X}(M)\) (vector space of vector fields on \(M\)) and \(p \in M\), let 
    \[
        \phi \colon (-\varepsilon, \varepsilon) \times U \rightarrow M  
    \]
    be a local flow of \(X\) on a neighborhood \(U\) of \(p\).
    Define the \newterm{Lie derivative \(\mathcal{L}_X Y\) of \(Y\)} with respect to \(X\) at \(p\) to be the vector 
    \begin{splitenv}
        (\mathcal{L}_X Y)_p &\coloneqq \lim_{t \rightarrow 0} \frac{(\phi_{-t})_*(Y_{\phi_t(p)}) - Y_p}{t} \\ 
        & = \lim_{t \rightarrow 0} \frac{((\phi_{-t})_* Y)_p - Y_p}{t} \\
        &= \evalat[\bigg]{\dv{t}}{t=0} ((\phi_{-t})_* Y)_p
    \end{splitenv}
    where \((\phi_{-t})_*(Y_{\phi_t(p)})\) is the pushforward of \(Y_{\phi_t(p)}\) by \(\phi_{-t}\) i.e. transport \(Y_{\phi_t(p)}\) back to \(p\) by \(\phi_{-t}\).
    See figure~\ref{fig:liederivative}.
\end{definition}
In this definition the limit is taken in the finite dimensional vector space \(T_p M\).
For the derivative to exist, it suffices that \(\{ (\phi_{-t})_* Y \}\)) be a smooth family of vector fields on \(M\).

Let \(\phi_t^i\) \(\phi^i\) be the \(i\)th components of \(\phi_t\) and \(\phi\) respectively.
Then 
\[
    \phi_t^i (p) = \phi^i (t,p) = (x^i \circ \phi) (t,p)
\]
Relative to the frame
\[
    \left\{ \pdv{}{x^j} \right\}    
\]
the differential \(\phi_{*,t}\) at \(p\) is represented by the Jacobian matrix 
\[
    \left[ \evalat[\bigg]{\pdv{\phi_t^i}{x^j}}{p} \right] = \left[ \evalat[\bigg]{\pdv{\phi^i}{x^j}}{t,p} \right]
\]
This means that 
\[
    \phi_{t, *} \left( \evalat[\bigg]{\pdv{}{x^j}}{p}  \right) = \sum_i \evalat[\bigg]{\pdv{\phi^i}{x^j}}{t,p} \evalat[\bigg]{\pdv{}{x^i}}{\phi_t(p)}  
\]
Thus, if \(Y = \sum b^j \prt{}{x^j}\), then 
\begin{splitenv}
    (\phi_{-t})_* \left( Y_{\phi_t(p)}  \right) &= \sum_j b^j \phi_t(p) (\phi_{-t})_*  \left( \evalat[\bigg]{\pdv{}{x^j}}{\phi_t(p)}  \right) \\ 
    &= \sum_{i,j} b^j \phi_t(p) \evalat[\bigg]{\pdv{\phi^i}{x^j}}{-t, p} \evalat[\bigg]{\pdv{}{x^i}}{p}
\end{splitenv}
When \(X,Y\) are \(\cinf\) vector fields on \(M\), both \(\phi^i, b^j\) are \(\cinf\) functions.
The above shows that \( \{ (\phi_{-t})_* Y \} \) is a smooth family of vector fields on \(M\).
It follows that the Lie derivative \(\mathcal{L}_X Y\) exists and is given in local coordinates by 
\begin{splitenv}
    (\mathcal{L}_X Y)_p &= \evalat[\bigg]{\dv{t}}{t=0} (\phi_{-t})_* \left( Y_{\phi_t(p)} \right) \\
    &= \sum_{i,j} \evalat[\bigg]{\pdv{t}}{t=0} \left( b^j(\phi_t(p)) \evalat[\bigg]{\pdv{\phi^i}{x^j}}{-t,p} \right) \evalat[\bigg]{\pdv{x^i}}{p}
\end{splitenv}
but in fact the Lie derivative of a vector field is nothing new:
\begin{proposition}{}{}
    If \(X,Y\) are \(\cinf\) vector fields on a manifold \(M\), then the Lie derivative \(\mathcal{L}_X Y\) coincides with the Lie bracket \([X,Y]\).
\end{proposition}

\subsubsection{The Lie Derivative of a Differential Form}

Let \(X\) be a smooth vector field and \(\w\) a smooth \(k\)-form on a manifold \(M\).
Fix a point \(p \in M\) and let \(\phi_t \colon U \rightarrow M\) be a flow generated by \(X\) in a neighborhood \(U\) of \(p\).
The Lie derivative of a differential form is similar to that of the Lie derivative of a vector field.
The difference is, instead of pushing a vector at \(\phi_t(p)\) to \(p\) via \((\phi_{-t})_*\), we now pull \(\w_{\phi_t(p)}\) back to \(p\) via \(\phi_t^*\).

\begin{definition}{Lie derivative of a differential form}{}
    For \(X\) a smooth vector field and \(\w\) a smooth \(k\)-form on a manifold \(M\), the \newterm{Lie derivative \(\mathcal{L}_X \w\)} at \(p \in M\) is
    \begin{splitenv}
        (\mathcal{L}_X \w)_p &\coloneqq \lim_{t\rightarrow 0} \frac{\phi_t^* (\w_{\phi_t(p)}) -\w_p}{t} \\ 
        &= \lim_{t\rightarrow 0} \frac{(\phi_t^* \w)_p -\w_p}{t} \\ 
        &= \evalat[\bigg]{\dv{t}}{t=0} (\phi_t^* \w)_p 
    \end{splitenv}
\end{definition}
\begin{proposition}{}{}
    If \(f\) is a \(\cinf\) function and \(X\) a \(\cinf\) vector field on \(M\), then \(\mathcal{L}_X f = X f\).
\end{proposition}

\subsubsection{Interior Multpilication}

\begin{definition}{Interior Multiplication/Contraction}{}
    If \(\beta\) is a \(k\)-covector on a vector space \(V\) and \(v \in V\), for \(k \geq 2\)
    the \newterm{interior multiplication} or \newterm{contraction} of \(\beta\) with \(v\) is the \(k-1\)-covector \(\iota_v \beta\) defined by 
    \[
        (\iota_v \beta) (v_2, \dots, v_k) = \beta(v, v_2, \dots, v_k)  
    \]
    i.e. plug \(v\) into the first \(\beta\) slot.
\end{definition}
\begin{proposition}{}{}
    For 1-covectors \(\alpha^1, \dots, \alpha^k\) on a vector space \(V\) and \(v \in V\)
    \begin{multline}
        \iota_v (\alpha^1 \wedge \cdots \wedge \alpha^k) = \\ \sum_{i=1}^k (-1)^{i-1} \alpha^i (v) \alpha^1 \wedge \cdots \wedge \widehat{\alpha^i} \wedge \cdots \wedge \alpha^k  
    \end{multline}
    where \(\widehat{\alpha^i}\) means that \(\alpha^i\) is omitted from the wedge product.
\end{proposition}
\begin{proposition}{}{}
    For \(v \in V\), let 
    \[
        \iota_v \colon \bigwedge^* (V^\vee) \rightarrow \bigwedge^{*-1} (V^\vee)
    \]
    be interior multiplication by \(v\).
    Then
    \begin{enumerate}
        \item \(\iota_v \circ \iota_v = 0\)
        \item for \(\beta \in \bigwedge^k (V^\vee)\) and \(\gamma \in \bigwedge^\ell (V^\vee)\)
        \[
            \iota_v (\beta \wedge \gamma) = (\iota_v \beta) \wedge \gamma + (-1)^k \beta \wedge \iota_v \gamma    
        \]
    \end{enumerate}
    In other words, \(\iota_v\) is an antiderivation of degree -1 whose square is zero.
\end{proposition}

Let \(\mathcal{F}\) be the ring \(\cinf(M)\) of \(\cinf\) functions on the manifold \(M\).
Because \(\iota_v \w\) is a point operator --- that is, it's value at \(p\) depends only on \(X_p\) and \(\w_p\) --- it is \(\mathcal{F}\)-linear in either argument. 
This means that \(\iota_X \w\) is additive in each argument and moreover, for \(f \in \mathcal{F}\)
\begin{enumerate}
    \item \(\iota_{f X} \w = f \iota_X \w\)  
    \item \(\iota_X (f \w) = f \iota_X \w\)
\end{enumerate}

\subsubsection{Properties of the Lie Derivative}

\begin{theorem}{}{}
    \begin{enumerate}
        \item The Lie derivative \(\mathcal{L}_X \colon \Omega^*(M) \rightarrow \Omega^*(M)\) is a derivation.
        \item The Lie derivative commutes with the exterior derivative \(\dif\).
        \item \textbf{Cartan homotopy formula}: \(\mathcal{L}_X = \dif \circ \iota_X + \iota_X \circ \dif\).
        \item \textbf{``Product'' formula}: For \(\w \in \Omega^k(M)\) and \(Y_1, \dots, Y_k \in \mathfrak{X}(M)\) 
        \begin{multline}
            \mathcal{L}_X(\w (Y_1, \dots, Y_k)) = (\mathcal{L}_X \w)(Y_1, \dots, Y_k) \\ 
            + \sum_{i=1}^k \w(Y_1, \dots, \mathcal{L}_X Y_i, \dots, Y_k)  
        \end{multline}
    \end{enumerate}
\end{theorem}
\begin{theorem}{Global formula for the Lie derivative}{}
    For a smooth \(k\)-form \(\w\) and smooth vector fields \(X,Y_1, \dots, Y_k\) on a manifold \(M\)
    \begin{multline}
        \mathcal{L}_X(Y_1, \dots, Y_k) = X(\w(Y_1, \dots, Y_k)) \\ 
        -  \sum_{i=1}^k \w(Y_1, \dots, [X,Y_i], \dots, Y_k)  
    \end{multline}
\end{theorem}
\begin{proposition}{}{}
    If \(\w\) is a \(\cinf\) 1-form and \(X,Y\) are \(\cinf\) vector fields on a manifold \(M\), then 
    \[
        (\dif \w)(X,Y) = X \w(X) - \w ([X,Y])
    \]
\end{proposition}
\begin{theorem}{Global formula for the exterior derivative}{}
    Assume \(k \geq 1\). 
    For a smooth \(k\)-form \(\w\) and smooth vector fields \(Y_0, Y_1, \dots, Y_k\) on a manifold \(M\)
    \begin{multline*}
        (\dif \w)(Y_0, \dots, Y_k) = \sum_{i=0}^k (-1)^i Y_i \w(Y_0, \dots, \widehat{Y_i}, \dots, Y_k) \\ 
        + \sum_{0 \leq i < j \leq k} (-1)^{i+j} \w([Y_i, Y_j], Y_0, \dots, \widehat{Y_i}, \dots, \widehat{Y_j}, \dots, Y_k)
    \end{multline*}
\end{theorem}

\subsection{Integration}